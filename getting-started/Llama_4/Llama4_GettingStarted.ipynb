{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe31ab76-7369-4204-8ad4-0e25799a8fcf",
   "metadata": {},
   "source": [
    "# Deploying Llama 4 on SageMaker JumpStart: Long context window use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b3a10-dec3-4c73-a006-d88d7237f43d",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use Llama 4 on AWS by deploying on SageMaker JumpStart. We will cover the deployment process, basic invocations to run inference, and important use cases that can be used with Llama 4 Scout's 10 million token window.\n",
    "\n",
    "## Llama 4\n",
    "\n",
    "Llama 4 represents Metaâ€™s most advanced multimodal models to date, featuring a mixture of experts (MoE) architecture and context window support up to 10 million tokens. With native multimodality and early fusion technology, Meta states that these new models demonstrate unprecedented performance across text and vision tasks while maintaining efficient compute requirements. With a dramatic increase on supported context length from 128K in Llama 3, Llama 4 is now suitable for multi-document summarization, parsing extensive user activity for personalized tasks, and reasoning over extensive codebases. \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "In order to run the following cells to deploy, you must:\n",
    "- Have AWS credentials with AWS Access Key and AWS Secret Access key\n",
    "- IAM execution role for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b43c43-6fe6-41c4-afae-55a6a564f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 19:56:46] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 19:56:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=143428;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=292051;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a6dd3f-973c-428f-a7ae-07d755067436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id, model_version = \"meta-vlm-llama-4-scout-17b-16e-instruct\", \"*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39d5c2-4536-45cb-b4c3-f5edb6cc9265",
   "metadata": {},
   "source": [
    "In order to run the gated model, please change the accept_eula = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57817b3-ceb5-4daa-89b7-6cf063b6477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_eula = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db5cf5-9682-494c-9cce-936200ecbf63",
   "metadata": {},
   "source": [
    "## Deploy model\n",
    "Using the model ID, define your model as a JumpStart model. You can deploy the model on other instance types by passing instance_type to JumpStartModel. See Deploy publicly available foundation models with the JumpStartModel class for more configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb2be6f-fa21-4a3b-b9ad-883e49c7d859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 20:01:07] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 20:01:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=645284;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=737722;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-vlm-llama-4-scout-17b-16e-instruct' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama4Eula.txt for terms of use.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Model <span style=\"color: #008700; text-decoration-color: #008700\">'meta-vlm-llama-4-scout-17b-16e-instruct'</span> requires accepting        <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py#597\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">597</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         end-user license agreement <span style=\"font-weight: bold\">(</span>EULA<span style=\"font-weight: bold\">)</span>. See                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMeta</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">data/eula/llama4Eula.txt</span> for terms of use.                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Model \u001b[38;2;0;135;0m'meta-vlm-llama-4-scout-17b-16e-instruct'\u001b[0m requires accepting        \u001b]8;id=148574;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=825233;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py#597\u001b\\\u001b[2m597\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         end-user license agreement \u001b[1m(\u001b[0mEULA\u001b[1m)\u001b[0m. See                                    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMeta\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mdata/eula/llama4Eula.txt\u001b[0m for terms of use.                                \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-vlm-llama-4-scout-17b-16e-instruct' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Using model <span style=\"color: #008700; text-decoration-color: #008700\">'meta-vlm-llama-4-scout-17b-16e-instruct'</span> with wildcard       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py#624\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">624</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version identifier <span style=\"color: #008700; text-decoration-color: #008700\">'*'</span>. You can pin to version <span style=\"color: #008700; text-decoration-color: #008700\">'1.0.0'</span> for more stable    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         results. Note that models may have different input/output signatures      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         after a major version upgrade.                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Using model \u001b[38;2;0;135;0m'meta-vlm-llama-4-scout-17b-16e-instruct'\u001b[0m with wildcard       \u001b]8;id=697312;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py\u001b\\\u001b[2mcache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=496815;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py#624\u001b\\\u001b[2m624\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version identifier \u001b[38;2;0;135;0m'*'\u001b[0m. You can pin to version \u001b[38;2;0;135;0m'1.0.0'\u001b[0m for more stable    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         results. Note that models may have different input/output signatures      \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         after a major version upgrade.                                            \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No instance type selected for inference hosting endpoint. Defaulting to ml.p5.48xlarge.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> No instance type selected for inference hosting endpoint. Defaulting to   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ml.p5.48xlarge.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m No instance type selected for inference hosting endpoint. Defaulting to   \u001b]8;id=272311;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=824826;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ml.p5.48xlarge.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = JumpStartModel(model_id=model_id, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da79df0c-293e-4a6f-b7db-0909d0c54a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 20:01:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-vlm-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-14-20-01-07-727        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 20:01:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=907619;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=282321;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-vlm-llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-instruct-\u001b[1;36m2025\u001b[0m-04-14-20-01-07-727        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 20:01:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-vlm-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-14-20-01-24-485        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 20:01:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=695230;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=181631;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-vlm-llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-instruct-\u001b[1;36m2025\u001b[0m-04-14-20-01-24-485        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-vlm-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-14-20-01-24-485        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=704943;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=38924;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-vlm-llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-instruct-\u001b[1;36m2025\u001b[0m-04-14-20-01-24-485        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(accept_eula=accept_eula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77469975-5e24-4e85-b101-d2144de7829b",
   "metadata": {},
   "source": [
    "## Run Inference\n",
    "\n",
    "Now that our Llama 4 model is deployed, we can run inference. The following cell will show an example of all the various use cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fe4f93-ec92-4919-8686-6a7b5af3538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_payloads = model.retrieve_all_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf6ae76b-17a7-46ae-afad-13e5312f8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " {'messages': [{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Hello, how can you help me today?'}]}], 'temperature': 0.7, 'max_tokens': 150}\n",
      "\n",
      "Output:\n",
      " Hello! I'm here to help with any questions or tasks you may have. I can assist with a wide range of topics, such as:\n",
      "\n",
      "* Answering questions on various subjects (e.g., science, history, technology, health, etc.)\n",
      "* Generating text or writing assistance (e.g., proofreading, summarizing, or creating content)\n",
      "* Providing definitions or explanations for specific terms or concepts\n",
      "* Offering suggestions or ideas for projects or problems you're facing\n",
      "* Chatting and conversation (if you just want to talk!)\n",
      "\n",
      "What brings you here today? Is there something specific you'd like help with, or do you want to explore and see where our conversation takes us?\n",
      "\n",
      "\n",
      "Input:\n",
      " {'messages': [{'role': 'system', 'content': 'You are an expert programming assistant specializing in Python'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Write a simple example'}]}], 'temperature': 0.2, 'max_tokens': 300}\n",
      "\n",
      "Output:\n",
      " **Simple Example: Hello World in Python**\n",
      "```python\n",
      "# Define a main function\n",
      "def main():\n",
      "    # Print \"Hello, World!\" to the console\n",
      "    print(\"Hello, World!\")\n",
      "\n",
      "# Call the main function\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "**Explanation:**\n",
      "\n",
      "* This is a simple Python program that prints \"Hello, World!\" to the console.\n",
      "* The `main` function is defined to encapsulate the program's entry point.\n",
      "* The `print` function is used to output the string \"Hello, World!\".\n",
      "* The `if __name__ == \"__main__\":` block is used to ensure the `main` function is called when the script is run directly.\n",
      "\n",
      "**Running the Example:**\n",
      "\n",
      "1. Save this code in a file with a `.py` extension (e.g., `hello.py`).\n",
      "2. Open a terminal or command prompt and navigate to the directory containing the file.\n",
      "3. Run the program using Python (e.g., `python hello.py`).\n",
      "4. You should see \"Hello, World!\" printed to the console.\n",
      "\n",
      "\n",
      "Input:\n",
      " {'messages': [{'role': 'system', 'content': 'You are a creative writing assistant'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Help me write a story'}]}], 'temperature': 0.9, 'top_p': 0.95, 'max_tokens': 500}\n",
      "\n",
      "Output:\n",
      " I'd be happy to help you write a story. Do you have any ideas already, or do you want to brainstorm together to come up with a concept?\n",
      "\n",
      "To get started, can you tell me:\n",
      "\n",
      "1. What genre are you interested in writing in (e.g. fantasy, sci-fi, romance, mystery, etc.)?\n",
      "2. Do you have any specific characters or settings in mind?\n",
      "3. Is there a particular theme or tone you're aiming for (e.g. light-hearted, serious, humorous, etc.)?\n",
      "\n",
      "Feel free to share as much or as little as you'd like, and we can go from there!\n",
      "\n",
      "\n",
      "Input:\n",
      " {'messages': [{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Describe image in two sentences'}, {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,$s3_b64<inference-notebook-assets/lake_view.jpg>'}}]}], 'temperature': 0.4, 'max_tokens': 250}\n",
      "\n",
      "Output:\n",
      " The image shows a long wooden dock extending into a lake, with mountains and trees in the background. The dock is made of light-colored wood planks and extends from the bottom center of the image out onto the calm water, which reflects the sky above it. In the background, there are evergreen trees lining the shore of the lake, and beyond them, there are mountains covered in greenery and patches of snow. The sky is overcast, with clouds covering most of it. The overall atmosphere suggests a peaceful and serene setting, possibly during the daytime.\n",
      "\n",
      "\n",
      "Input:\n",
      " {'messages': [{'role': 'system', 'content': 'You are a technical documentation reviewer'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Review this technical document'}]}], 'temperature': 0.3, 'top_p': 0.8, 'max_tokens': 400}\n",
      "\n",
      "Output:\n",
      " I'd be happy to review a technical document. However, I don't see a document provided. Please share the document you'd like me to review, and I'll do my best to provide a thorough and constructive review.\n",
      "\n",
      "You can share the document in several ways:\n",
      "\n",
      "1. **Paste the text**: If the document is short, you can paste the text into this chat window.\n",
      "2. **Share a link**: If the document is publicly accessible, you can share a link to it.\n",
      "3. **Upload a file**: If the document is a file, you can upload it to a file-sharing platform like Google Drive or Dropbox and share the link with me.\n",
      "\n",
      "Please provide the document, and I'll review it based on factors such as:\n",
      "\n",
      "* Clarity and concision\n",
      "* Technical accuracy\n",
      "* Completeness\n",
      "* Consistency\n",
      "* Organization and structure\n",
      "* Grammar, spelling, and punctuation\n",
      "\n",
      "Let me know when you're ready to share the document!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for payload in example_payloads:\n",
    "    response = predictor.predict(payload)\n",
    "    response = response[0] if isinstance(response, list) else response\n",
    "    print(\"Input:\\n\", payload.body, end=\"\\n\\n\")\n",
    "    if \"generated_text\" in response:\n",
    "        print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")\n",
    "    else:\n",
    "        print(\"Output:\\n\", response[\"choices\"][0][\"message\"][\"content\"], end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b3b312-d252-4248-996d-342792615c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your prompt using the OpenAI Chat Completions format\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful AI assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are three key benefits of large language models for businesses?\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9acfb88-27d1-4177-a84b-ccb75889010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to model...\n",
      "Input:\n",
      " {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant.'}, {'role': 'user', 'content': 'What are three key benefits of large language models for businesses?'}], 'max_tokens': 2048, 'temperature': 0.7, 'top_p': 0.9} \n",
      "\n",
      "Output:\n",
      " Large language models (LLMs) have numerous benefits for businesses, and here are three key advantages:\n",
      "\n",
      "1. **Enhanced Customer Experience through Automation**: LLMs can be integrated with chatbots and virtual assistants to provide 24/7 customer support, automating routine inquiries, and freeing up human customer support agents to focus on more complex issues. This leads to faster response times, improved customer satisfaction, and reduced support costs. Additionally, LLMs can analyze customer interactions to identify patterns and preferences, enabling businesses to personalize their services and improve overall customer experience.\n",
      "2. **Increased Efficiency in Content Generation and Analysis**: LLMs can generate high-quality content, such as blog posts, social media posts, and product descriptions, at a much faster pace than humans. This enables businesses to produce large volumes of content, reducing the time and effort required for content creation. Moreover, LLMs can analyze vast amounts of text data, extracting insights, sentiment, and meaning, which can inform business decisions, improve marketing strategies, and optimize operations.\n",
      "3. **Improved Decision-Making with Data-Driven Insights**: LLMs can process and analyze vast amounts of unstructured data, such as text from social media, reviews, and feedback forms. By extracting insights from this data, businesses can gain a deeper understanding of their customers, markets, and competitors. This enables informed decision-making, improved forecasting, and more effective strategic planning. LLMs can also help identify trends, patterns, and anomalies, allowing businesses to respond quickly to changes in the market or customer behavior.\n",
      "\n",
      "These benefits can have a significant impact on a business's operations, customer engagement, and bottom line, making large language models a valuable tool for companies looking to stay competitive in today's fast-paced digital landscape. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "print(\"Sending request to model...\")\n",
    "response = predictor.predict(payload)\n",
    "response = response[0] if isinstance(response, list) else response\n",
    "\n",
    "# Print the output\n",
    "print(\"Input:\\n\", payload, \"\\n\")\n",
    "if \"generated_text\" in response:\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), \"\\n\\n\")\n",
    "elif \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "    print(\"Output:\\n\", response[\"choices\"][0][\"message\"][\"content\"], \"\\n\\n\")\n",
    "else:\n",
    "    print(\"Raw response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2f803-7185-47e1-b625-f00fa612463d",
   "metadata": {},
   "source": [
    "# Image / Multi-Image Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce961b2e-8bf9-4661-be68-7eeebee3b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base64 string prefix: data:image/png;base64,iVBORw0K...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "region = 'us-east-1'\n",
    "\n",
    "s3_bucket = f\"jumpstart-cache-prod-{region}\"\n",
    "key_prefix = \"inference-notebook-assets\"\n",
    "\n",
    "def download_from_s3(key_filenames):\n",
    "    for key_filename in key_filenames:\n",
    "        s3.download_file(s3_bucket, f\"{key_prefix}/{key_filename}\", key_filename)\n",
    "\n",
    "# Define image names\n",
    "heat_map = \"heatmap_semantic_similarity_search.png\"\n",
    "\n",
    "# Download and display the heatmap image\n",
    "# download_from_s3(key_filenames=[heat_map])\n",
    "\n",
    "def img_to_base64(image_path):\n",
    "    \"\"\"Convert image to base64 with proper MIME type prefix\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img = f.read()\n",
    "    \n",
    "    # Determine MIME type based on file extension\n",
    "    mime_type = \"image/png\"  # Default to PNG\n",
    "    if image_path.lower().endswith('.jpg') or image_path.lower().endswith('.jpeg'):\n",
    "        mime_type = \"image/jpeg\"\n",
    "    \n",
    "    # Encode image and add proper prefix\n",
    "    enc_img = base64.b64encode(img).decode('utf-8')\n",
    "    return f\"data:{mime_type};base64,{enc_img}\"\n",
    "\n",
    "# Convert image to base64 with proper format\n",
    "b64_img = img_to_base64(heat_map)\n",
    "\n",
    "# Verify the base64 string starts correctly\n",
    "print(f\"Base64 string prefix: {b64_img[:30]}...\")\n",
    "\n",
    "def url_to_base64(image_url):\n",
    "    \"\"\"Download an image from URL and convert to base64\"\"\"\n",
    "    # Download the image\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to download image from {image_url}, status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Determine MIME type based on Content-Type header or URL extension\n",
    "    mime_type = \"image/jpeg\"  # Default\n",
    "    content_type = response.headers.get('Content-Type', '')\n",
    "    if content_type.startswith('image/'):\n",
    "        mime_type = content_type\n",
    "    elif image_url.lower().endswith('.png'):\n",
    "        mime_type = \"image/png\"\n",
    "    \n",
    "    # Encode the image content to base64\n",
    "    image_base64 = base64.b64encode(response.content).decode('utf-8')\n",
    "    return f\"data:{mime_type};base64,{image_base64}\"\n",
    "\n",
    "# Define image names for S3 download\n",
    "image1_name = \"heatmap_semantic_similarity_search.png\"\n",
    "# Define URL for second image\n",
    "image2_url = \"https://raw.githubusercontent.com/mathvision-cuhk/MATH-V/refs/heads/main/images/13.jpg\"\n",
    "\n",
    "# Download the first image from S3\n",
    "print(\"Downloading first image from S3...\")\n",
    "download_from_s3(key_filenames=[image1_name])\n",
    "\n",
    "# Convert first image to base64\n",
    "print(\"Converting first image to base64...\")\n",
    "b64_img1 = img_to_base64(image1_name)\n",
    "\n",
    "# Download and convert second image from URL\n",
    "print(\"Downloading and converting second image...\")\n",
    "b64_img2 = url_to_base64(image2_url)\n",
    "\n",
    "# Verify the base64 strings start correctly\n",
    "print(f\"Base64 string 1 prefix: {b64_img1[:30]}...\")\n",
    "print(f\"Base64 string 2 prefix: {b64_img2[:30]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d12ff0a-cbc6-4c25-a763-8ce75cf9c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the payload as a Python dictionary\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What is in this image?\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": b64_img\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_tokens\": 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e710c5-092e-420b-b519-18c9f4d5a86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to model...\n",
      "Input: [Image with prompt 'What is in this image?']\n",
      "Output:\n",
      " The image presents a heatmap illustrating the semantic textual similarity between sentences. The heatmap is divided into two axes, with the x-axis listing seven sentences and the y-axis listing the same sentences in reverse order.\n",
      "\n",
      "**Sentences:**\n",
      "\n",
      "* Your dog is so cute.\n",
      "* How cute your dog is!\n",
      "* You have such a cute dog!\n",
      "* New York City is the place where I work.\n",
      "* I work in New York City.\n",
      "* What color do you like the most?\n",
      "* What is your favourite color?\n",
      "\n",
      "**Heatmap:**\n",
      "\n",
      "The heatmap displays a range of colors, from dark red (indicating high similarity) to light beige (indicating low similarity). The color scale on the right side of the heatmap provides a visual representation of the similarity scores, ranging from 1.0 (dark red) to -0.4 (light beige).\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "* The three sentences related to dogs (\"Your dog is so cute.\", \"How cute your dog is!\", and \"You have such a cute dog!\") exhibit high similarity scores with each other, as indicated by the dark red and orange colors.\n",
      "* The two sentences related to New York City (\"New York City is the place where I work.\" and \"I work in New York City.\") also show high similarity scores with each other.\n",
      "* The two sentences related to colors (\"What color do you like the most?\" and \"What is your favourite color?\") display high similarity scores with each other.\n",
      "* The sentences from different categories (dogs, New York City, and colors) generally show lower similarity scores with each other, as indicated by the lighter beige colors.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The heatmap effectively illustrates the semantic textual similarity between sentences, highlighting the relationships between sentences with similar meanings and topics. The color scale provides a clear visual representation of the similarity scores, allowing for easy interpretation of the results. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "print(\"Sending request to model...\")\n",
    "response = predictor.predict(data)  # Pass the dictionary directly\n",
    "response = response[0] if isinstance(response, list) else response\n",
    "\n",
    "# Print the output\n",
    "print(\"Input: [Image with prompt 'What is in this image?']\")\n",
    "if \"generated_text\" in response:\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), \"\\n\\n\")\n",
    "elif \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "    print(\"Output:\\n\", response[\"choices\"][0][\"message\"][\"content\"], \"\\n\\n\")\n",
    "else:\n",
    "    print(\"Raw response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b993c6af-6ce7-4b1f-8601-fd0a712759f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading first image from S3...\n",
      "Converting first image to base64...\n",
      "Downloading and converting second image...\n",
      "Base64 string 1 prefix: data:image/png;base64,iVBORw0K...\n",
      "Base64 string 2 prefix: data:image/jpeg;base64,/9j/4AA...\n"
     ]
    }
   ],
   "source": [
    "# Create the payload with two images\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"There are two images. Describe each one and why they are related\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": b64_img1,\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": b64_img2,\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_tokens\": 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4d25035-160a-45c8-9daa-941bab34446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to model...\n",
      "Input: [Image with prompt 'What is in this image?']\n",
      "Output:\n",
      " The image presents two distinct visual representations, each conveying different information.\n",
      "\n",
      "**Image 1: Semantic Textual Similarity Between Sentences**\n",
      "\n",
      "This image is a heatmap illustrating the semantic textual similarity between various sentences. The heatmap is a square matrix with a color gradient ranging from dark red (high similarity) to light beige (low similarity). The sentences being compared are:\n",
      "\n",
      "* Your dog is so cute.\n",
      "* How cute your dog is!\n",
      "* You have such a cute dog!\n",
      "* New York City is the place where I work.\n",
      "* I work in New York City.\n",
      "* What color do you like the most?\n",
      "* What is your favourite color?\n",
      "\n",
      "The heatmap reveals that:\n",
      "\n",
      "* Sentences about the dog's cuteness have high similarity scores (dark red), indicating they convey similar meanings.\n",
      "* Sentences about working in New York City also show high similarity scores.\n",
      "* Sentences about favorite colors have high similarity scores.\n",
      "* Sentences across different topics (dog, work location, and favorite color) have low similarity scores (light beige), indicating they convey distinct meanings.\n",
      "\n",
      "**Image 2: Stick Figures**\n",
      "\n",
      "This image features five stick figures labeled A, B, C, D, and E, each representing a person. The figures are simple drawings composed of basic shapes, including circles for heads, squares for bodies, and lines for arms and legs. The figures are depicted wearing skirts or shorts, with some variations in their design.\n",
      "\n",
      "The stick figures appear to be simple illustrations, possibly used for demonstration or educational purposes. They do not seem to be directly related to the heatmap, but both images are presented together in the context of AI-generated content.\n",
      "\n",
      "**Relationship Between Images**\n",
      "\n",
      "The two images appear to be unrelated in terms of their content. The heatmap focuses on semantic textual similarity, while the stick figures are simple illustrations of people. However, both images may be part of a larger presentation or educational material showcasing various types of data visualization and representation. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "print(\"Sending request to model...\")\n",
    "response = predictor.predict(data)  # Pass the dictionary directly\n",
    "response = response[0] if isinstance(response, list) else response\n",
    "\n",
    "# Print the output\n",
    "print(\"Input: [Image with prompt 'What is in this image?']\")\n",
    "if \"generated_text\" in response:\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), \"\\n\\n\")\n",
    "elif \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "    print(\"Output:\\n\", response[\"choices\"][0][\"message\"][\"content\"], \"\\n\\n\")\n",
    "else:\n",
    "    print(\"Raw response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41673588-19b5-4915-90a6-33f7262c4237",
   "metadata": {},
   "source": [
    "# Codebase Analysis \n",
    "\n",
    "Using Llama 4 Scoutâ€™s industry-leading context window, this section showcases its ability to deeply analyze expansive codebases. The example extracts and contextualizes the buildspec-1-10-2.yml file from the AWS Deep Learning Containers GitHub repository, illustrating how the model synthesizes information across an entire repository. We used a tool to ingest the whole repository into plaintext that we provided to the model as context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34a5a20-e2b9-45c4-921a-9be735a8572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/17/25 00:46:37] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/17/25 00:46:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=353098;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=107346;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "def read_markdown_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the content of a markdown file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the markdown file to be read\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the file as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        raise\n",
    "\n",
    "def summarize_text(text, predictor, max_length=2000):\n",
    "    \"\"\"\n",
    "    Summarize the provided text using a SageMaker JumpStart model predictor.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to summarize\n",
    "        predictor: JumpStart model predictor\n",
    "        max_length (int): Maximum length of text to send (to avoid token limits)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (Summarized text, Latency metrics)\n",
    "    \"\"\"\n",
    "    # Truncate text if necessary to avoid exceeding token limits\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length] + \"... [Content truncated due to length]\"\n",
    "    \n",
    "    # Create the payload using OpenAI Chat Completions format\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a helpful AI assistant that summarizes codebases to me to help me understand \n",
    "                            how to analyze code by synthesizing through the entire codebase before responding.\n",
    "\n",
    "                            Be thorough in your search as the file may be nested within a markdown code block or within a directory listing.\n",
    "                            \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Can you explain to me the buildspec-1-10-2.yml file and how it relates to the rest of the huggingface directory? Use this information :\\n\\n{text} as reference.\"\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "    \n",
    "    # Start measuring preprocessing time\n",
    "    preprocess_start = time.time()\n",
    "    \n",
    "    # Measure payload size\n",
    "    payload_size = len(json.dumps(payload).encode('utf-8'))\n",
    "    \n",
    "    preprocess_end = time.time()\n",
    "    preprocess_time = preprocess_end - preprocess_start\n",
    "    \n",
    "    # Invoke the predictor and measure latency\n",
    "    api_start = time.time()\n",
    "    response = predictor.predict(payload)\n",
    "    api_end = time.time()\n",
    "    api_latency = api_end - api_start\n",
    "    \n",
    "    # Process response based on JumpStart model output format\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    \n",
    "    # Start measuring postprocessing time\n",
    "    postprocess_start = time.time()\n",
    "    \n",
    "    # Extract the summary from the response based on format\n",
    "    if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "        summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    elif \"generated_text\" in response:\n",
    "        summary = response[\"generated_text\"].strip()\n",
    "    else:\n",
    "        summary = str(response)\n",
    "    \n",
    "    # Calculate output size\n",
    "    output_size = len(summary.encode('utf-8'))\n",
    "    \n",
    "    postprocess_end = time.time()\n",
    "    postprocess_time = postprocess_end - postprocess_start\n",
    "    \n",
    "    # Collect metrics\n",
    "    metrics = {\n",
    "        'api_latency': api_latency,\n",
    "        'preprocess_time': preprocess_time,\n",
    "        'postprocess_time': postprocess_time,\n",
    "        'total_latency': preprocess_time + api_latency + postprocess_time,\n",
    "        'payload_size_bytes': payload_size,\n",
    "        'output_size_bytes': output_size,\n",
    "        'payload_tokens': len(text) / 4,  # rough approximation of tokens\n",
    "    }\n",
    "    \n",
    "    return summary, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927e8101-0168-4ab6-af04-d673166e85d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading markdown file from /home/ec2-user/SageMaker/repomix-output.md...\n",
      "File read time: 0.1799 seconds\n",
      "Generating summary...\n",
      "\n",
      "--- LATENCY METRICS ---\n",
      "API call latency: 41.5058 seconds\n",
      "Preprocessing time: 0.0000 seconds\n",
      "Postprocessing time: 0.0000 seconds\n",
      "Total latency: 41.5059 seconds\n",
      "Payload size: 2.69 KB\n",
      "Output size: 3.22 KB\n",
      "Approximate input tokens: 509\n",
      "\n",
      "--- SUMMARY ---\n",
      "\n",
      "## Overview of the buildspec-1-10-2.yml File\n",
      "\n",
      "The provided information doesn't directly reference a `buildspec-1-10-2.yml` file. However, based on the context of the Hugging Face repository and common practices in software development, I can infer that this file likely relates to a build specification, possibly for a Continuous Integration/Continuous Deployment (CI/CD) pipeline.\n",
      "\n",
      "## Understanding the File's Purpose\n",
      "\n",
      "Typically, a `buildspec.yml` file is used in CI/CD pipelines to define the build, test, and deployment process for a project. The version number (`1-10-2`) might indicate a specific configuration or a version of the build specification.\n",
      "\n",
      "## Relation to the Hugging Face Directory\n",
      "\n",
      "Without the direct content of the `buildspec-1-10-2.yml` file, we can only speculate on its exact role within the Hugging Face repository. However, given that this repository seems to be related to AutoGluon and Hugging Face models, the build specification could be crucial for:\n",
      "\n",
      "1. **Defining Build and Test Environments:** It might specify the environments (e.g., Docker images) needed for building and testing the project, including dependencies and versions.\n",
      "\n",
      "2. **Configuring CI/CD Pipelines:** The file could configure automated workflows for building, testing, and deploying models or software components within the repository.\n",
      "\n",
      "3. **Integration with Hugging Face Models:** Given the presence of model-related directories and files, the build specification might include steps for downloading, preparing, or fine-tuning models provided by Hugging Face.\n",
      "\n",
      "## Insights from the Provided Directory Structure\n",
      "\n",
      "The directory structure hints at a complex project involving multiple frameworks (e.g., PyTorch, TensorFlow, MXNet) and configurations for different types of models and deployments. The presence of:\n",
      "\n",
      "- `.github/workflows/` suggests that GitHub Actions are used for CI/CD pipelines.\n",
      "- `autogluon/` directory implies involvement with AutoGluon, a library for automated machine learning.\n",
      "- Various `release_images.yml` files under `.release_templates/` indicate templates for releasing models or software with different frameworks.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The `buildspec-1-10-2.yml` file likely plays a critical role in automating the build, test, and deployment process for the Hugging Face related projects within this repository. Its exact configuration would detail how different components of the project are assembled, tested, and deployed, potentially leveraging CI/CD pipelines and specific build environments tailored for machine learning model development and deployment.\n",
      "\n",
      "## Recommendations for Analysis\n",
      "\n",
      "- **Locate the File:** Find the actual `buildspec-1-10-2.yml` file within the repository to analyze its contents directly.\n",
      "- **Compare with Workflows:** Compare its configuration with the GitHub Actions workflows (`.github/workflows/`) to understand how build specifications are translated into automated pipeline steps.\n",
      "- **Review Dependencies:** Examine how dependencies and environments are specified and managed within the build specification and related configuration files.\n",
      "\n",
      "This approach will provide a comprehensive understanding of how the `buildspec-1-10-2.yml` file integrates with the rest of the Hugging Face directory and its role in the project's CI/CD process.\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "file_path = '/home/ec2-user/SageMaker/repomix-output.md'  # Update with actual markdown file\n",
    "\n",
    "# Read the markdown file\n",
    "print(f\"Reading markdown file from {file_path}...\")\n",
    "read_start = time.time()\n",
    "markdown_content = read_markdown_file(file_path)\n",
    "read_end = time.time()\n",
    "read_time = read_end - read_start\n",
    "print(f\"File read time: {read_time:.4f} seconds\")\n",
    "\n",
    "# Summarize the content\n",
    "print(\"Generating summary...\")\n",
    "summary, latency_metrics = summarize_text(markdown_content, predictor)\n",
    "\n",
    "# Print the latency metrics\n",
    "print(\"\\n--- LATENCY METRICS ---\")\n",
    "print(f\"API call latency: {latency_metrics['api_latency']:.4f} seconds\")\n",
    "print(f\"Preprocessing time: {latency_metrics['preprocess_time']:.4f} seconds\")\n",
    "print(f\"Postprocessing time: {latency_metrics['postprocess_time']:.4f} seconds\")\n",
    "print(f\"Total latency: {latency_metrics['total_latency']:.4f} seconds\")\n",
    "print(f\"Payload size: {latency_metrics['payload_size_bytes'] / 1024:.2f} KB\")\n",
    "print(f\"Output size: {latency_metrics['output_size_bytes'] / 1024:.2f} KB\")\n",
    "print(f\"Approximate input tokens: {int(latency_metrics['payload_tokens'])}\")\n",
    "\n",
    "# Print the summary\n",
    "print(\"\\n--- SUMMARY ---\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e914832-54d1-4b55-8544-5a49d23643ff",
   "metadata": {},
   "source": [
    "# Multi-Doc Processing\n",
    "With Llama 4 Scout's 10million token context window - Llama 4 Scout excels in multi-document processing. In this example, the model extracts key financial metrics from Amazon 10-K reports (2017-2024), demonstrating its capability to integrate and analyze data spanning multiple yearsâ€”all without the need for additional processing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "707e39a9-105c-4e99-acd3-17e220276d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: pyPDF2\n",
      "Successfully installed pyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f00c977-d197-45d7-98af-dea0f4659723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import PyPDF2\n",
    "import os\n",
    "import glob\n",
    "import sagemaker\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbdcdf3b-6fad-47d7-9456-c46f937d931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            print(f\"PDF has {len(pdf_reader.pages)} pages\")\n",
    "            # Extract text from first 100 pages (adjust as needed)\n",
    "            for page_num in range(min(100, len(pdf_reader.pages))):\n",
    "                print(f\"Processing page {page_num+1}/{len(pdf_reader.pages)}...\")\n",
    "                text += pdf_reader.pages[page_num].extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_key_data_from_pdfs(pdf_files, predictor):\n",
    "    \"\"\"Extract and summarize key data from each PDF file using JumpStart model.\"\"\"\n",
    "    pdf_summaries = {}\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        file_name = os.path.basename(pdf_file)\n",
    "        print(f\"\\n--- Extracting key data from {file_name} ---\")\n",
    "        \n",
    "        pdf_text = extract_text_from_pdf(pdf_file)\n",
    "        if not pdf_text:\n",
    "            print(f\"Failed to extract text from {file_name}\")\n",
    "            continue\n",
    "            \n",
    "        # Create a payload using the OpenAI Chat Completions format\n",
    "        payload = {\n",
    "            \"model\": \"meta-vlm-llama-4-scout-17b-16e-instruct\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a financial analyst. Extract key financial data from this 10-K report.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"Extract the following information from this Amazon 10-K report:\n",
    "1. What year is this report for?\n",
    "2. Total revenue for the year\n",
    "3. Net income\n",
    "4. Key business segments and their performance\n",
    "5. Important trends mentioned\n",
    "\n",
    "Here's the 10-K text:\n",
    "{pdf_text[:25000]}\n",
    "\n",
    "Format your response as a JSON object with these fields: year, revenue, net_income, segments, trends.\n",
    "\"\"\"\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 2048,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"Extracting key data from {file_name}...\")\n",
    "            # Use the JumpStart predictor\n",
    "            response = predictor.predict(payload)\n",
    "            \n",
    "            # Handle response format\n",
    "            if isinstance(response, list):\n",
    "                response = response[0]\n",
    "                \n",
    "            # Extract content based on response format\n",
    "            if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "                summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                pdf_summaries[file_name] = summary\n",
    "                print(f\"Successfully extracted key data from {file_name}\")\n",
    "            elif \"generated_text\" in response:\n",
    "                summary = response[\"generated_text\"].strip()\n",
    "                pdf_summaries[file_name] = summary\n",
    "                print(f\"Successfully extracted key data from {file_name}\")\n",
    "            else:\n",
    "                print(f\"Failed to extract key data from {file_name}: Unexpected response format\")\n",
    "                print(f\"Response: {response}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "    \n",
    "    return pdf_summaries\n",
    "\n",
    "def find_pdf_files(directory):\n",
    "    \"\"\"Find all PDF files in the specified directory.\"\"\"\n",
    "    pdf_files = []\n",
    "    try:\n",
    "        # Look for all PDF files in the directory\n",
    "        pdf_pattern = os.path.join(directory, \"*.pdf\")\n",
    "        pdf_files = glob.glob(pdf_pattern)\n",
    "        \n",
    "        if pdf_files:\n",
    "            print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "            for pdf in pdf_files:\n",
    "                print(f\"  - {os.path.basename(pdf)}\")\n",
    "        else:\n",
    "            print(f\"No PDF files found in {directory}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding PDF files: {e}\")\n",
    "    \n",
    "    return pdf_files\n",
    "\n",
    "def synthesize_and_answer_question(pdf_summaries, question, predictor):\n",
    "    \"\"\"Synthesize information from all PDFs and answer a specific question.\"\"\"\n",
    "    # Combine all summaries\n",
    "    combined_context = \"\"\n",
    "    for pdf_name, summary in pdf_summaries.items():\n",
    "        combined_context += f\"--- Data from {pdf_name} ---\\n{summary}\\n\\n\"\n",
    "    \n",
    "    # Create the system prompt\n",
    "    system_prompt = \"\"\"You are an expert financial analyst comparing Amazon's 10-K reports across multiple years.\n",
    "Your task is to synthesize information from these reports and answer questions accurately.\n",
    "Make sure to compare data across years when relevant and highlight significant changes or trends.\"\"\"\n",
    "    \n",
    "    # Create the user prompt with combined context\n",
    "    user_content = f\"\"\"I've analyzed multiple Amazon 10-K reports and extracted the key information from each:\n",
    "\n",
    "{combined_context}\n",
    "\n",
    "Based on this information from all the reports, please answer the following question:\n",
    "{question}\n",
    "\n",
    "Provide a comprehensive answer that compares information across all available years.\"\"\"\n",
    "    \n",
    "    # Create the payload\n",
    "    payload = {\n",
    "        \"model\": \"meta-vlm-llama-4-scout-17b-16e-instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nSynthesizing information and answering question...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = predictor.predict(payload)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        if isinstance(response, list):\n",
    "            response = response[0]\n",
    "            \n",
    "        print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        elif \"generated_text\" in response:\n",
    "            return response[\"generated_text\"].strip()\n",
    "        else:\n",
    "            print(\"Unexpected response format:\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error synthesizing information: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b83e9eb-2e96-4a7b-a6eb-2cb90319ea1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to existing endpoint: meta-vlm-llama-4-scout-17b-16e-instruct-2025-04-14-20-01-24-485\n",
      "Successfully connected to the endpoint\n",
      "Found 10 PDF files:\n",
      "  - amazon10k_2022.pdf\n",
      "  - amazon_10k_2020.pdf\n",
      "  - amazon_10k_2015.pdf\n",
      "  - amazon_10k_2016.pdf\n",
      "  - amazon_10k_2018.pdf\n",
      "  - amazon_10k_2021.pdf\n",
      "  - amazon_10k_2024.pdf\n",
      "  - amazon_10k_2019.pdf\n",
      "  - amazon_10k_2017.pdf\n",
      "  - amazon_10k_2023.pdf\n",
      "\n",
      "Extracting key data from all PDFs...\n",
      "\n",
      "--- Extracting key data from amazon10k_2022.pdf ---\n",
      "PDF has 194 pages\n",
      "Processing page 1/194...\n",
      "Processing page 2/194...\n",
      "Processing page 3/194...\n",
      "Processing page 4/194...\n",
      "Processing page 5/194...\n",
      "Processing page 6/194...\n",
      "Processing page 7/194...\n",
      "Processing page 8/194...\n",
      "Processing page 9/194...\n",
      "Processing page 10/194...\n",
      "Processing page 11/194...\n",
      "Processing page 12/194...\n",
      "Processing page 13/194...\n",
      "Processing page 14/194...\n",
      "Processing page 15/194...\n",
      "Processing page 16/194...\n",
      "Processing page 17/194...\n",
      "Processing page 18/194...\n",
      "Processing page 19/194...\n",
      "Processing page 20/194...\n",
      "Processing page 21/194...\n",
      "Processing page 22/194...\n",
      "Processing page 23/194...\n",
      "Processing page 24/194...\n",
      "Processing page 25/194...\n",
      "Processing page 26/194...\n",
      "Processing page 27/194...\n",
      "Processing page 28/194...\n",
      "Processing page 29/194...\n",
      "Processing page 30/194...\n",
      "Processing page 31/194...\n",
      "Processing page 32/194...\n",
      "Processing page 33/194...\n",
      "Processing page 34/194...\n",
      "Processing page 35/194...\n",
      "Processing page 36/194...\n",
      "Processing page 37/194...\n",
      "Processing page 38/194...\n",
      "Processing page 39/194...\n",
      "Processing page 40/194...\n",
      "Processing page 41/194...\n",
      "Processing page 42/194...\n",
      "Processing page 43/194...\n",
      "Processing page 44/194...\n",
      "Processing page 45/194...\n",
      "Processing page 46/194...\n",
      "Processing page 47/194...\n",
      "Processing page 48/194...\n",
      "Processing page 49/194...\n",
      "Processing page 50/194...\n",
      "Processing page 51/194...\n",
      "Processing page 52/194...\n",
      "Processing page 53/194...\n",
      "Processing page 54/194...\n",
      "Processing page 55/194...\n",
      "Processing page 56/194...\n",
      "Processing page 57/194...\n",
      "Processing page 58/194...\n",
      "Processing page 59/194...\n",
      "Processing page 60/194...\n",
      "Processing page 61/194...\n",
      "Processing page 62/194...\n",
      "Processing page 63/194...\n",
      "Processing page 64/194...\n",
      "Processing page 65/194...\n",
      "Processing page 66/194...\n",
      "Processing page 67/194...\n",
      "Processing page 68/194...\n",
      "Processing page 69/194...\n",
      "Processing page 70/194...\n",
      "Processing page 71/194...\n",
      "Processing page 72/194...\n",
      "Processing page 73/194...\n",
      "Processing page 74/194...\n",
      "Processing page 75/194...\n",
      "Processing page 76/194...\n",
      "Processing page 77/194...\n",
      "Processing page 78/194...\n",
      "Processing page 79/194...\n",
      "Processing page 80/194...\n",
      "Processing page 81/194...\n",
      "Processing page 82/194...\n",
      "Processing page 83/194...\n",
      "Processing page 84/194...\n",
      "Processing page 85/194...\n",
      "Processing page 86/194...\n",
      "Processing page 87/194...\n",
      "Processing page 88/194...\n",
      "Processing page 89/194...\n",
      "Processing page 90/194...\n",
      "Processing page 91/194...\n",
      "Processing page 92/194...\n",
      "Processing page 93/194...\n",
      "Processing page 94/194...\n",
      "Processing page 95/194...\n",
      "Processing page 96/194...\n",
      "Processing page 97/194...\n",
      "Processing page 98/194...\n",
      "Processing page 99/194...\n",
      "Processing page 100/194...\n",
      "Extracting key data from amazon10k_2022.pdf...\n",
      "Successfully extracted key data from amazon10k_2022.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2020.pdf ---\n",
      "PDF has 83 pages\n",
      "Processing page 1/83...\n",
      "Processing page 2/83...\n",
      "Processing page 3/83...\n",
      "Processing page 4/83...\n",
      "Processing page 5/83...\n",
      "Processing page 6/83...\n",
      "Processing page 7/83...\n",
      "Processing page 8/83...\n",
      "Processing page 9/83...\n",
      "Processing page 10/83...\n",
      "Processing page 11/83...\n",
      "Processing page 12/83...\n",
      "Processing page 13/83...\n",
      "Processing page 14/83...\n",
      "Processing page 15/83...\n",
      "Processing page 16/83...\n",
      "Processing page 17/83...\n",
      "Processing page 18/83...\n",
      "Processing page 19/83...\n",
      "Processing page 20/83...\n",
      "Processing page 21/83...\n",
      "Processing page 22/83...\n",
      "Processing page 23/83...\n",
      "Processing page 24/83...\n",
      "Processing page 25/83...\n",
      "Processing page 26/83...\n",
      "Processing page 27/83...\n",
      "Processing page 28/83...\n",
      "Processing page 29/83...\n",
      "Processing page 30/83...\n",
      "Processing page 31/83...\n",
      "Processing page 32/83...\n",
      "Processing page 33/83...\n",
      "Processing page 34/83...\n",
      "Processing page 35/83...\n",
      "Processing page 36/83...\n",
      "Processing page 37/83...\n",
      "Processing page 38/83...\n",
      "Processing page 39/83...\n",
      "Processing page 40/83...\n",
      "Processing page 41/83...\n",
      "Processing page 42/83...\n",
      "Processing page 43/83...\n",
      "Processing page 44/83...\n",
      "Processing page 45/83...\n",
      "Processing page 46/83...\n",
      "Processing page 47/83...\n",
      "Processing page 48/83...\n",
      "Processing page 49/83...\n",
      "Processing page 50/83...\n",
      "Processing page 51/83...\n",
      "Processing page 52/83...\n",
      "Processing page 53/83...\n",
      "Processing page 54/83...\n",
      "Processing page 55/83...\n",
      "Processing page 56/83...\n",
      "Processing page 57/83...\n",
      "Processing page 58/83...\n",
      "Processing page 59/83...\n",
      "Processing page 60/83...\n",
      "Processing page 61/83...\n",
      "Processing page 62/83...\n",
      "Processing page 63/83...\n",
      "Processing page 64/83...\n",
      "Processing page 65/83...\n",
      "Processing page 66/83...\n",
      "Processing page 67/83...\n",
      "Processing page 68/83...\n",
      "Processing page 69/83...\n",
      "Processing page 70/83...\n",
      "Processing page 71/83...\n",
      "Processing page 72/83...\n",
      "Processing page 73/83...\n",
      "Processing page 74/83...\n",
      "Processing page 75/83...\n",
      "Processing page 76/83...\n",
      "Processing page 77/83...\n",
      "Processing page 78/83...\n",
      "Processing page 79/83...\n",
      "Processing page 80/83...\n",
      "Processing page 81/83...\n",
      "Processing page 82/83...\n",
      "Processing page 83/83...\n",
      "Extracting key data from amazon_10k_2020.pdf...\n",
      "Successfully extracted key data from amazon_10k_2020.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2015.pdf ---\n",
      "PDF has 90 pages\n",
      "Processing page 1/90...\n",
      "Processing page 2/90...\n",
      "Processing page 3/90...\n",
      "Processing page 4/90...\n",
      "Processing page 5/90...\n",
      "Processing page 6/90...\n",
      "Processing page 7/90...\n",
      "Processing page 8/90...\n",
      "Processing page 9/90...\n",
      "Processing page 10/90...\n",
      "Processing page 11/90...\n",
      "Processing page 12/90...\n",
      "Processing page 13/90...\n",
      "Processing page 14/90...\n",
      "Processing page 15/90...\n",
      "Processing page 16/90...\n",
      "Processing page 17/90...\n",
      "Processing page 18/90...\n",
      "Processing page 19/90...\n",
      "Processing page 20/90...\n",
      "Processing page 21/90...\n",
      "Processing page 22/90...\n",
      "Processing page 23/90...\n",
      "Processing page 24/90...\n",
      "Processing page 25/90...\n",
      "Processing page 26/90...\n",
      "Processing page 27/90...\n",
      "Processing page 28/90...\n",
      "Processing page 29/90...\n",
      "Processing page 30/90...\n",
      "Processing page 31/90...\n",
      "Processing page 32/90...\n",
      "Processing page 33/90...\n",
      "Processing page 34/90...\n",
      "Processing page 35/90...\n",
      "Processing page 36/90...\n",
      "Processing page 37/90...\n",
      "Processing page 38/90...\n",
      "Processing page 39/90...\n",
      "Processing page 40/90...\n",
      "Processing page 41/90...\n",
      "Processing page 42/90...\n",
      "Processing page 43/90...\n",
      "Processing page 44/90...\n",
      "Processing page 45/90...\n",
      "Processing page 46/90...\n",
      "Processing page 47/90...\n",
      "Processing page 48/90...\n",
      "Processing page 49/90...\n",
      "Processing page 50/90...\n",
      "Processing page 51/90...\n",
      "Processing page 52/90...\n",
      "Processing page 53/90...\n",
      "Processing page 54/90...\n",
      "Processing page 55/90...\n",
      "Processing page 56/90...\n",
      "Processing page 57/90...\n",
      "Processing page 58/90...\n",
      "Processing page 59/90...\n",
      "Processing page 60/90...\n",
      "Processing page 61/90...\n",
      "Processing page 62/90...\n",
      "Processing page 63/90...\n",
      "Processing page 64/90...\n",
      "Processing page 65/90...\n",
      "Processing page 66/90...\n",
      "Processing page 67/90...\n",
      "Processing page 68/90...\n",
      "Processing page 69/90...\n",
      "Processing page 70/90...\n",
      "Processing page 71/90...\n",
      "Processing page 72/90...\n",
      "Processing page 73/90...\n",
      "Processing page 74/90...\n",
      "Processing page 75/90...\n",
      "Processing page 76/90...\n",
      "Processing page 77/90...\n",
      "Processing page 78/90...\n",
      "Processing page 79/90...\n",
      "Processing page 80/90...\n",
      "Processing page 81/90...\n",
      "Processing page 82/90...\n",
      "Processing page 83/90...\n",
      "Processing page 84/90...\n",
      "Processing page 85/90...\n",
      "Processing page 86/90...\n",
      "Processing page 87/90...\n",
      "Processing page 88/90...\n",
      "Processing page 89/90...\n",
      "Processing page 90/90...\n",
      "Extracting key data from amazon_10k_2015.pdf...\n",
      "Successfully extracted key data from amazon_10k_2015.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2016.pdf ---\n",
      "PDF has 85 pages\n",
      "Processing page 1/85...\n",
      "Processing page 2/85...\n",
      "Processing page 3/85...\n",
      "Processing page 4/85...\n",
      "Processing page 5/85...\n",
      "Processing page 6/85...\n",
      "Processing page 7/85...\n",
      "Processing page 8/85...\n",
      "Processing page 9/85...\n",
      "Processing page 10/85...\n",
      "Processing page 11/85...\n",
      "Processing page 12/85...\n",
      "Processing page 13/85...\n",
      "Processing page 14/85...\n",
      "Processing page 15/85...\n",
      "Processing page 16/85...\n",
      "Processing page 17/85...\n",
      "Processing page 18/85...\n",
      "Processing page 19/85...\n",
      "Processing page 20/85...\n",
      "Processing page 21/85...\n",
      "Processing page 22/85...\n",
      "Processing page 23/85...\n",
      "Processing page 24/85...\n",
      "Processing page 25/85...\n",
      "Processing page 26/85...\n",
      "Processing page 27/85...\n",
      "Processing page 28/85...\n",
      "Processing page 29/85...\n",
      "Processing page 30/85...\n",
      "Processing page 31/85...\n",
      "Processing page 32/85...\n",
      "Processing page 33/85...\n",
      "Processing page 34/85...\n",
      "Processing page 35/85...\n",
      "Processing page 36/85...\n",
      "Processing page 37/85...\n",
      "Processing page 38/85...\n",
      "Processing page 39/85...\n",
      "Processing page 40/85...\n",
      "Processing page 41/85...\n",
      "Processing page 42/85...\n",
      "Processing page 43/85...\n",
      "Processing page 44/85...\n",
      "Processing page 45/85...\n",
      "Processing page 46/85...\n",
      "Processing page 47/85...\n",
      "Processing page 48/85...\n",
      "Processing page 49/85...\n",
      "Processing page 50/85...\n",
      "Processing page 51/85...\n",
      "Processing page 52/85...\n",
      "Processing page 53/85...\n",
      "Processing page 54/85...\n",
      "Processing page 55/85...\n",
      "Processing page 56/85...\n",
      "Processing page 57/85...\n",
      "Processing page 58/85...\n",
      "Processing page 59/85...\n",
      "Processing page 60/85...\n",
      "Processing page 61/85...\n",
      "Processing page 62/85...\n",
      "Processing page 63/85...\n",
      "Processing page 64/85...\n",
      "Processing page 65/85...\n",
      "Processing page 66/85...\n",
      "Processing page 67/85...\n",
      "Processing page 68/85...\n",
      "Processing page 69/85...\n",
      "Processing page 70/85...\n",
      "Processing page 71/85...\n",
      "Processing page 72/85...\n",
      "Processing page 73/85...\n",
      "Processing page 74/85...\n",
      "Processing page 75/85...\n",
      "Processing page 76/85...\n",
      "Processing page 77/85...\n",
      "Processing page 78/85...\n",
      "Processing page 79/85...\n",
      "Processing page 80/85...\n",
      "Processing page 81/85...\n",
      "Processing page 82/85...\n",
      "Processing page 83/85...\n",
      "Processing page 84/85...\n",
      "Processing page 85/85...\n",
      "Extracting key data from amazon_10k_2016.pdf...\n",
      "Successfully extracted key data from amazon_10k_2016.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2018.pdf ---\n",
      "PDF has 85 pages\n",
      "Processing page 1/85...\n",
      "Processing page 2/85...\n",
      "Processing page 3/85...\n",
      "Processing page 4/85...\n",
      "Processing page 5/85...\n",
      "Processing page 6/85...\n",
      "Processing page 7/85...\n",
      "Processing page 8/85...\n",
      "Processing page 9/85...\n",
      "Processing page 10/85...\n",
      "Processing page 11/85...\n",
      "Processing page 12/85...\n",
      "Processing page 13/85...\n",
      "Processing page 14/85...\n",
      "Processing page 15/85...\n",
      "Processing page 16/85...\n",
      "Processing page 17/85...\n",
      "Processing page 18/85...\n",
      "Processing page 19/85...\n",
      "Processing page 20/85...\n",
      "Processing page 21/85...\n",
      "Processing page 22/85...\n",
      "Processing page 23/85...\n",
      "Processing page 24/85...\n",
      "Processing page 25/85...\n",
      "Processing page 26/85...\n",
      "Processing page 27/85...\n",
      "Processing page 28/85...\n",
      "Processing page 29/85...\n",
      "Processing page 30/85...\n",
      "Processing page 31/85...\n",
      "Processing page 32/85...\n",
      "Processing page 33/85...\n",
      "Processing page 34/85...\n",
      "Processing page 35/85...\n",
      "Processing page 36/85...\n",
      "Processing page 37/85...\n",
      "Processing page 38/85...\n",
      "Processing page 39/85...\n",
      "Processing page 40/85...\n",
      "Processing page 41/85...\n",
      "Processing page 42/85...\n",
      "Processing page 43/85...\n",
      "Processing page 44/85...\n",
      "Processing page 45/85...\n",
      "Processing page 46/85...\n",
      "Processing page 47/85...\n",
      "Processing page 48/85...\n",
      "Processing page 49/85...\n",
      "Processing page 50/85...\n",
      "Processing page 51/85...\n",
      "Processing page 52/85...\n",
      "Processing page 53/85...\n",
      "Processing page 54/85...\n",
      "Processing page 55/85...\n",
      "Processing page 56/85...\n",
      "Processing page 57/85...\n",
      "Processing page 58/85...\n",
      "Processing page 59/85...\n",
      "Processing page 60/85...\n",
      "Processing page 61/85...\n",
      "Processing page 62/85...\n",
      "Processing page 63/85...\n",
      "Processing page 64/85...\n",
      "Processing page 65/85...\n",
      "Processing page 66/85...\n",
      "Processing page 67/85...\n",
      "Processing page 68/85...\n",
      "Processing page 69/85...\n",
      "Processing page 70/85...\n",
      "Processing page 71/85...\n",
      "Processing page 72/85...\n",
      "Processing page 73/85...\n",
      "Processing page 74/85...\n",
      "Processing page 75/85...\n",
      "Processing page 76/85...\n",
      "Processing page 77/85...\n",
      "Processing page 78/85...\n",
      "Processing page 79/85...\n",
      "Processing page 80/85...\n",
      "Processing page 81/85...\n",
      "Processing page 82/85...\n",
      "Processing page 83/85...\n",
      "Processing page 84/85...\n",
      "Processing page 85/85...\n",
      "Extracting key data from amazon_10k_2018.pdf...\n",
      "Error processing amazon_10k_2018.pdf: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/meta-vlm-llama-4-scout-17b-16e-instruct-2025-04-14-20-01-24-485 in account 333633606362 for more information.\n",
      "\n",
      "--- Extracting key data from amazon_10k_2021.pdf ---\n",
      "PDF has 80 pages\n",
      "Processing page 1/80...\n",
      "Processing page 2/80...\n",
      "Processing page 3/80...\n",
      "Processing page 4/80...\n",
      "Processing page 5/80...\n",
      "Processing page 6/80...\n",
      "Processing page 7/80...\n",
      "Processing page 8/80...\n",
      "Processing page 9/80...\n",
      "Processing page 10/80...\n",
      "Processing page 11/80...\n",
      "Processing page 12/80...\n",
      "Processing page 13/80...\n",
      "Processing page 14/80...\n",
      "Processing page 15/80...\n",
      "Processing page 16/80...\n",
      "Processing page 17/80...\n",
      "Processing page 18/80...\n",
      "Processing page 19/80...\n",
      "Processing page 20/80...\n",
      "Processing page 21/80...\n",
      "Processing page 22/80...\n",
      "Processing page 23/80...\n",
      "Processing page 24/80...\n",
      "Processing page 25/80...\n",
      "Processing page 26/80...\n",
      "Processing page 27/80...\n",
      "Processing page 28/80...\n",
      "Processing page 29/80...\n",
      "Processing page 30/80...\n",
      "Processing page 31/80...\n",
      "Processing page 32/80...\n",
      "Processing page 33/80...\n",
      "Processing page 34/80...\n",
      "Processing page 35/80...\n",
      "Processing page 36/80...\n",
      "Processing page 37/80...\n",
      "Processing page 38/80...\n",
      "Processing page 39/80...\n",
      "Processing page 40/80...\n",
      "Processing page 41/80...\n",
      "Processing page 42/80...\n",
      "Processing page 43/80...\n",
      "Processing page 44/80...\n",
      "Processing page 45/80...\n",
      "Processing page 46/80...\n",
      "Processing page 47/80...\n",
      "Processing page 48/80...\n",
      "Processing page 49/80...\n",
      "Processing page 50/80...\n",
      "Processing page 51/80...\n",
      "Processing page 52/80...\n",
      "Processing page 53/80...\n",
      "Processing page 54/80...\n",
      "Processing page 55/80...\n",
      "Processing page 56/80...\n",
      "Processing page 57/80...\n",
      "Processing page 58/80...\n",
      "Processing page 59/80...\n",
      "Processing page 60/80...\n",
      "Processing page 61/80...\n",
      "Processing page 62/80...\n",
      "Processing page 63/80...\n",
      "Processing page 64/80...\n",
      "Processing page 65/80...\n",
      "Processing page 66/80...\n",
      "Processing page 67/80...\n",
      "Processing page 68/80...\n",
      "Processing page 69/80...\n",
      "Processing page 70/80...\n",
      "Processing page 71/80...\n",
      "Processing page 72/80...\n",
      "Processing page 73/80...\n",
      "Processing page 74/80...\n",
      "Processing page 75/80...\n",
      "Processing page 76/80...\n",
      "Processing page 77/80...\n",
      "Processing page 78/80...\n",
      "Processing page 79/80...\n",
      "Processing page 80/80...\n",
      "Extracting key data from amazon_10k_2021.pdf...\n",
      "Successfully extracted key data from amazon_10k_2021.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2024.pdf ---\n",
      "PDF has 94 pages\n",
      "Processing page 1/94...\n",
      "Processing page 2/94...\n",
      "Processing page 3/94...\n",
      "Processing page 4/94...\n",
      "Processing page 5/94...\n",
      "Processing page 6/94...\n",
      "Processing page 7/94...\n",
      "Processing page 8/94...\n",
      "Processing page 9/94...\n",
      "Processing page 10/94...\n",
      "Processing page 11/94...\n",
      "Processing page 12/94...\n",
      "Processing page 13/94...\n",
      "Processing page 14/94...\n",
      "Processing page 15/94...\n",
      "Processing page 16/94...\n",
      "Processing page 17/94...\n",
      "Processing page 18/94...\n",
      "Processing page 19/94...\n",
      "Processing page 20/94...\n",
      "Processing page 21/94...\n",
      "Processing page 22/94...\n",
      "Processing page 23/94...\n",
      "Processing page 24/94...\n",
      "Processing page 25/94...\n",
      "Processing page 26/94...\n",
      "Processing page 27/94...\n",
      "Processing page 28/94...\n",
      "Processing page 29/94...\n",
      "Processing page 30/94...\n",
      "Processing page 31/94...\n",
      "Processing page 32/94...\n",
      "Processing page 33/94...\n",
      "Processing page 34/94...\n",
      "Processing page 35/94...\n",
      "Processing page 36/94...\n",
      "Processing page 37/94...\n",
      "Processing page 38/94...\n",
      "Processing page 39/94...\n",
      "Processing page 40/94...\n",
      "Processing page 41/94...\n",
      "Processing page 42/94...\n",
      "Processing page 43/94...\n",
      "Processing page 44/94...\n",
      "Processing page 45/94...\n",
      "Processing page 46/94...\n",
      "Processing page 47/94...\n",
      "Processing page 48/94...\n",
      "Processing page 49/94...\n",
      "Processing page 50/94...\n",
      "Processing page 51/94...\n",
      "Processing page 52/94...\n",
      "Processing page 53/94...\n",
      "Processing page 54/94...\n",
      "Processing page 55/94...\n",
      "Processing page 56/94...\n",
      "Processing page 57/94...\n",
      "Processing page 58/94...\n",
      "Processing page 59/94...\n",
      "Processing page 60/94...\n",
      "Processing page 61/94...\n",
      "Processing page 62/94...\n",
      "Processing page 63/94...\n",
      "Processing page 64/94...\n",
      "Processing page 65/94...\n",
      "Processing page 66/94...\n",
      "Processing page 67/94...\n",
      "Processing page 68/94...\n",
      "Processing page 69/94...\n",
      "Processing page 70/94...\n",
      "Processing page 71/94...\n",
      "Processing page 72/94...\n",
      "Processing page 73/94...\n",
      "Processing page 74/94...\n",
      "Processing page 75/94...\n",
      "Processing page 76/94...\n",
      "Processing page 77/94...\n",
      "Processing page 78/94...\n",
      "Processing page 79/94...\n",
      "Processing page 80/94...\n",
      "Processing page 81/94...\n",
      "Processing page 82/94...\n",
      "Processing page 83/94...\n",
      "Processing page 84/94...\n",
      "Processing page 85/94...\n",
      "Processing page 86/94...\n",
      "Processing page 87/94...\n",
      "Processing page 88/94...\n",
      "Processing page 89/94...\n",
      "Processing page 90/94...\n",
      "Processing page 91/94...\n",
      "Processing page 92/94...\n",
      "Processing page 93/94...\n",
      "Processing page 94/94...\n",
      "Extracting key data from amazon_10k_2024.pdf...\n",
      "Successfully extracted key data from amazon_10k_2024.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2019.pdf ---\n",
      "PDF has 89 pages\n",
      "Processing page 1/89...\n",
      "Processing page 2/89...\n",
      "Processing page 3/89...\n",
      "Processing page 4/89...\n",
      "Processing page 5/89...\n",
      "Processing page 6/89...\n",
      "Processing page 7/89...\n",
      "Processing page 8/89...\n",
      "Processing page 9/89...\n",
      "Processing page 10/89...\n",
      "Processing page 11/89...\n",
      "Processing page 12/89...\n",
      "Processing page 13/89...\n",
      "Processing page 14/89...\n",
      "Processing page 15/89...\n",
      "Processing page 16/89...\n",
      "Processing page 17/89...\n",
      "Processing page 18/89...\n",
      "Processing page 19/89...\n",
      "Processing page 20/89...\n",
      "Processing page 21/89...\n",
      "Processing page 22/89...\n",
      "Processing page 23/89...\n",
      "Processing page 24/89...\n",
      "Processing page 25/89...\n",
      "Processing page 26/89...\n",
      "Processing page 27/89...\n",
      "Processing page 28/89...\n",
      "Processing page 29/89...\n",
      "Processing page 30/89...\n",
      "Processing page 31/89...\n",
      "Processing page 32/89...\n",
      "Processing page 33/89...\n",
      "Processing page 34/89...\n",
      "Processing page 35/89...\n",
      "Processing page 36/89...\n",
      "Processing page 37/89...\n",
      "Processing page 38/89...\n",
      "Processing page 39/89...\n",
      "Processing page 40/89...\n",
      "Processing page 41/89...\n",
      "Processing page 42/89...\n",
      "Processing page 43/89...\n",
      "Processing page 44/89...\n",
      "Processing page 45/89...\n",
      "Processing page 46/89...\n",
      "Processing page 47/89...\n",
      "Processing page 48/89...\n",
      "Processing page 49/89...\n",
      "Processing page 50/89...\n",
      "Processing page 51/89...\n",
      "Processing page 52/89...\n",
      "Processing page 53/89...\n",
      "Processing page 54/89...\n",
      "Processing page 55/89...\n",
      "Processing page 56/89...\n",
      "Processing page 57/89...\n",
      "Processing page 58/89...\n",
      "Processing page 59/89...\n",
      "Processing page 60/89...\n",
      "Processing page 61/89...\n",
      "Processing page 62/89...\n",
      "Processing page 63/89...\n",
      "Processing page 64/89...\n",
      "Processing page 65/89...\n",
      "Processing page 66/89...\n",
      "Processing page 67/89...\n",
      "Processing page 68/89...\n",
      "Processing page 69/89...\n",
      "Processing page 70/89...\n",
      "Processing page 71/89...\n",
      "Processing page 72/89...\n",
      "Processing page 73/89...\n",
      "Processing page 74/89...\n",
      "Processing page 75/89...\n",
      "Processing page 76/89...\n",
      "Processing page 77/89...\n",
      "Processing page 78/89...\n",
      "Processing page 79/89...\n",
      "Processing page 80/89...\n",
      "Processing page 81/89...\n",
      "Processing page 82/89...\n",
      "Processing page 83/89...\n",
      "Processing page 84/89...\n",
      "Processing page 85/89...\n",
      "Processing page 86/89...\n",
      "Processing page 87/89...\n",
      "Processing page 88/89...\n",
      "Processing page 89/89...\n",
      "Extracting key data from amazon_10k_2019.pdf...\n",
      "Successfully extracted key data from amazon_10k_2019.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2017.pdf ---\n",
      "PDF has 85 pages\n",
      "Processing page 1/85...\n",
      "Processing page 2/85...\n",
      "Processing page 3/85...\n",
      "Processing page 4/85...\n",
      "Processing page 5/85...\n",
      "Processing page 6/85...\n",
      "Processing page 7/85...\n",
      "Processing page 8/85...\n",
      "Processing page 9/85...\n",
      "Processing page 10/85...\n",
      "Processing page 11/85...\n",
      "Processing page 12/85...\n",
      "Processing page 13/85...\n",
      "Processing page 14/85...\n",
      "Processing page 15/85...\n",
      "Processing page 16/85...\n",
      "Processing page 17/85...\n",
      "Processing page 18/85...\n",
      "Processing page 19/85...\n",
      "Processing page 20/85...\n",
      "Processing page 21/85...\n",
      "Processing page 22/85...\n",
      "Processing page 23/85...\n",
      "Processing page 24/85...\n",
      "Processing page 25/85...\n",
      "Processing page 26/85...\n",
      "Processing page 27/85...\n",
      "Processing page 28/85...\n",
      "Processing page 29/85...\n",
      "Processing page 30/85...\n",
      "Processing page 31/85...\n",
      "Processing page 32/85...\n",
      "Processing page 33/85...\n",
      "Processing page 34/85...\n",
      "Processing page 35/85...\n",
      "Processing page 36/85...\n",
      "Processing page 37/85...\n",
      "Processing page 38/85...\n",
      "Processing page 39/85...\n",
      "Processing page 40/85...\n",
      "Processing page 41/85...\n",
      "Processing page 42/85...\n",
      "Processing page 43/85...\n",
      "Processing page 44/85...\n",
      "Processing page 45/85...\n",
      "Processing page 46/85...\n",
      "Processing page 47/85...\n",
      "Processing page 48/85...\n",
      "Processing page 49/85...\n",
      "Processing page 50/85...\n",
      "Processing page 51/85...\n",
      "Processing page 52/85...\n",
      "Processing page 53/85...\n",
      "Processing page 54/85...\n",
      "Processing page 55/85...\n",
      "Processing page 56/85...\n",
      "Processing page 57/85...\n",
      "Processing page 58/85...\n",
      "Processing page 59/85...\n",
      "Processing page 60/85...\n",
      "Processing page 61/85...\n",
      "Processing page 62/85...\n",
      "Processing page 63/85...\n",
      "Processing page 64/85...\n",
      "Processing page 65/85...\n",
      "Processing page 66/85...\n",
      "Processing page 67/85...\n",
      "Processing page 68/85...\n",
      "Processing page 69/85...\n",
      "Processing page 70/85...\n",
      "Processing page 71/85...\n",
      "Processing page 72/85...\n",
      "Processing page 73/85...\n",
      "Processing page 74/85...\n",
      "Processing page 75/85...\n",
      "Processing page 76/85...\n",
      "Processing page 77/85...\n",
      "Processing page 78/85...\n",
      "Processing page 79/85...\n",
      "Processing page 80/85...\n",
      "Processing page 81/85...\n",
      "Processing page 82/85...\n",
      "Processing page 83/85...\n",
      "Processing page 84/85...\n",
      "Processing page 85/85...\n",
      "Extracting key data from amazon_10k_2017.pdf...\n",
      "Successfully extracted key data from amazon_10k_2017.pdf\n",
      "\n",
      "--- Extracting key data from amazon_10k_2023.pdf ---\n",
      "PDF has 81 pages\n",
      "Processing page 1/81...\n",
      "Processing page 2/81...\n",
      "Processing page 3/81...\n",
      "Processing page 4/81...\n",
      "Processing page 5/81...\n",
      "Processing page 6/81...\n",
      "Processing page 7/81...\n",
      "Processing page 8/81...\n",
      "Processing page 9/81...\n",
      "Processing page 10/81...\n",
      "Processing page 11/81...\n",
      "Processing page 12/81...\n",
      "Processing page 13/81...\n",
      "Processing page 14/81...\n",
      "Processing page 15/81...\n",
      "Processing page 16/81...\n",
      "Processing page 17/81...\n",
      "Processing page 18/81...\n",
      "Processing page 19/81...\n",
      "Processing page 20/81...\n",
      "Processing page 21/81...\n",
      "Processing page 22/81...\n",
      "Processing page 23/81...\n",
      "Processing page 24/81...\n",
      "Processing page 25/81...\n",
      "Processing page 26/81...\n",
      "Processing page 27/81...\n",
      "Processing page 28/81...\n",
      "Processing page 29/81...\n",
      "Processing page 30/81...\n",
      "Processing page 31/81...\n",
      "Processing page 32/81...\n",
      "Processing page 33/81...\n",
      "Processing page 34/81...\n",
      "Processing page 35/81...\n",
      "Processing page 36/81...\n",
      "Processing page 37/81...\n",
      "Processing page 38/81...\n",
      "Processing page 39/81...\n",
      "Processing page 40/81...\n",
      "Processing page 41/81...\n",
      "Processing page 42/81...\n",
      "Processing page 43/81...\n",
      "Processing page 44/81...\n",
      "Processing page 45/81...\n",
      "Processing page 46/81...\n",
      "Processing page 47/81...\n",
      "Processing page 48/81...\n",
      "Processing page 49/81...\n",
      "Processing page 50/81...\n",
      "Processing page 51/81...\n",
      "Processing page 52/81...\n",
      "Processing page 53/81...\n",
      "Processing page 54/81...\n",
      "Processing page 55/81...\n",
      "Processing page 56/81...\n",
      "Processing page 57/81...\n",
      "Processing page 58/81...\n",
      "Processing page 59/81...\n",
      "Processing page 60/81...\n",
      "Processing page 61/81...\n",
      "Processing page 62/81...\n",
      "Processing page 63/81...\n",
      "Processing page 64/81...\n",
      "Processing page 65/81...\n",
      "Processing page 66/81...\n",
      "Processing page 67/81...\n",
      "Processing page 68/81...\n",
      "Processing page 69/81...\n",
      "Processing page 70/81...\n",
      "Processing page 71/81...\n",
      "Processing page 72/81...\n",
      "Processing page 73/81...\n",
      "Processing page 74/81...\n",
      "Processing page 75/81...\n",
      "Processing page 76/81...\n",
      "Processing page 77/81...\n",
      "Processing page 78/81...\n",
      "Processing page 79/81...\n",
      "Processing page 80/81...\n",
      "Processing page 81/81...\n",
      "Extracting key data from amazon_10k_2023.pdf...\n",
      "Successfully extracted key data from amazon_10k_2023.pdf\n",
      "\n",
      "Successfully extracted data from the following PDFs:\n",
      "  - amazon10k_2022.pdf\n",
      "  - amazon_10k_2020.pdf\n",
      "  - amazon_10k_2015.pdf\n",
      "  - amazon_10k_2016.pdf\n",
      "  - amazon_10k_2021.pdf\n",
      "  - amazon_10k_2024.pdf\n",
      "  - amazon_10k_2019.pdf\n",
      "  - amazon_10k_2017.pdf\n",
      "  - amazon_10k_2023.pdf\n",
      "\n",
      "Answering question: How did Amazon's revenue and net income change over time?\n",
      "\n",
      "Synthesizing information and answering question...\n",
      "Error synthesizing information: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/meta-vlm-llama-4-scout-17b-16e-instruct-2025-04-14-20-01-24-485 in account 333633606362 for more information.\n",
      "Sorry, I couldn't generate an answer for: How did Amazon's revenue and net income change over time?\n",
      "\n",
      "Answering question: What are the main business segments driving growth at Amazon over the years?\n",
      "\n",
      "Synthesizing information and answering question...\n",
      "Time taken: 48.69 seconds\n",
      "\n",
      "==================================================\n",
      "ANSWER to: What are the main business segments driving growth at Amazon over the years?\n",
      "==================================================\n",
      "## Main Business Segments Driving Growth at Amazon\n",
      "\n",
      "Based on the provided 10-K reports from Amazon across multiple years, the main business segments driving growth at Amazon can be identified as follows:\n",
      "\n",
      "### 1. North America\n",
      "- **Description**: This segment includes retail sales to consumers, sellers, enterprises, and content creators in North America.\n",
      "- **Growth Trend**: Consistently a significant contributor to Amazon's revenue, with a focus on selection, price, and convenience.\n",
      "\n",
      "### 2. International\n",
      "- **Description**: This segment includes retail sales to consumers, sellers, enterprises, and content creators outside of North America.\n",
      "- **Growth Trend**: Plays a crucial role in Amazon's global expansion, with a focus on increasing market share in international markets.\n",
      "\n",
      "### 3. Amazon Web Services (AWS)\n",
      "- **Description**: Offers a broad set of global compute, storage, database, and other service offerings to developers, enterprises, and content creators.\n",
      "- **Growth Trend**: Has been a significant growth driver for Amazon, with a rapid increase in revenue and profitability.\n",
      "\n",
      "### Comparison Across Years\n",
      "\n",
      "- **2014-2016**: Amazon's business segments were primarily focused on North America and International, with AWS emerging as a growth area.\n",
      "- **2017-2019**: AWS continued to grow rapidly, becoming a major contributor to Amazon's profitability. The North America and International segments remained crucial for retail sales.\n",
      "- **2020-2022**: AWS continued to drive growth, with a significant increase in revenue. The North America and International segments also showed growth, with an increased focus on e-commerce, cloud computing, and digital content.\n",
      "\n",
      "### Key Trends\n",
      "\n",
      "- **Seasonality**: Amazon experiences higher sales volume during the fourth quarter across all years.\n",
      "- **Competition**: Intense competition in e-commerce, cloud computing, and digital content is a consistent trend.\n",
      "- **Expansion**: Rapid expansion into new products, services, technologies, and geographic regions is a key strategy for growth.\n",
      "\n",
      "### Revenue and Net Income Growth\n",
      "\n",
      "| Year | Revenue (in millions) | Net Income (in millions) |\n",
      "| --- | --- | --- |\n",
      "| 2014 | 89,015 | 236 |\n",
      "| 2015 | 107,006 | 596 |\n",
      "| 2016 | 135,987 | 2,371 |\n",
      "| 2018 | 232,883 | 10,073 |\n",
      "| 2019 | 280,520 | 18,750 |\n",
      "| 2020 | 386,064 | 18,675 |\n",
      "| 2021 | Not provided | Not provided |\n",
      "| 2022 | 513,983 | 18,240 |\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The main business segments driving growth at Amazon over the years are North America, International, and Amazon Web Services (AWS). AWS has emerged as a significant growth driver, contributing substantially to Amazon's revenue and profitability. The North America and International segments continue to be crucial for Amazon's retail business, with a focus on expanding product offerings, improving customer experience, and increasing market share. Amazon's ability to adapt to changing market conditions, innovate, and expand into new areas has been key to its growth across all segments.\n",
      "\n",
      "Answering question: How has AWS evolved as a segment and what is its contribution to Amazon's overall business?\n",
      "\n",
      "Synthesizing information and answering question...\n",
      "Time taken: 46.27 seconds\n",
      "\n",
      "==================================================\n",
      "ANSWER to: How has AWS evolved as a segment and what is its contribution to Amazon's overall business?\n",
      "==================================================\n",
      "## Evolution of AWS as a Segment and Its Contribution to Amazon's Overall Business\n",
      "\n",
      "Amazon Web Services (AWS) has undergone significant evolution as a segment since its inception and has become a crucial contributor to Amazon's overall business. Based on the provided 10-K reports from various years, here's a comprehensive analysis of AWS's growth and its impact on Amazon's business:\n",
      "\n",
      "### Early Years (2014-2016)\n",
      "\n",
      "* In 2014, AWS was not explicitly mentioned as a separate segment, but it was described as a part of Amazon's technology infrastructure.\n",
      "* By 2015, AWS emerged as a distinct segment, serving developers and enterprises of all sizes, including start-ups, government agencies, and academic institutions.\n",
      "* In 2016, AWS continued to grow, offering a broad set of global compute, storage, database, and other service offerings.\n",
      "\n",
      "### Growth and Expansion (2017-2020)\n",
      "\n",
      "* By 2017, AWS had become a significant contributor to Amazon's revenue, with a description that highlighted its cloud computing services for businesses and governments.\n",
      "* In 2018, AWS was described as serving developers and enterprises of all sizes through its cloud computing services, with a broad set of global compute, storage, database, and other service offerings.\n",
      "* In 2019, AWS continued to be a major segment, serving developers, enterprises, and content creators.\n",
      "\n",
      "### Current Status (2021-2023)\n",
      "\n",
      "* In 2020, AWS was described as serving developers, enterprises, and content creators, with a focus on cloud computing services.\n",
      "* By 2021, AWS had become a critical component of Amazon's business, serving developers and enterprises of all sizes, including start-ups, government agencies, and academic institutions.\n",
      "* In 2022, AWS continued to be a significant segment, with a description that emphasized its role in serving developers and enterprises of all sizes.\n",
      "* In 2023, AWS remained a vital part of Amazon's business, with a focus on serving developers and enterprises of all sizes.\n",
      "\n",
      "### Contribution to Amazon's Overall Business\n",
      "\n",
      "While the exact revenue figures for AWS are not provided in the given text, it's clear that AWS has become a substantial contributor to Amazon's overall revenue. In 2022, Amazon's total revenue was $513.98 billion, and in 2020, it was $386.06 billion. Although the specific AWS revenue figures are not provided, it's evident that AWS has grown significantly over the years and plays a crucial role in Amazon's financial performance.\n",
      "\n",
      "### Key Trends and Insights\n",
      "\n",
      "* **Growth**: AWS has consistently grown and expanded its offerings over the years, becoming a critical component of Amazon's business.\n",
      "* **Increased Importance**: AWS's importance to Amazon's overall business has increased, with a greater emphasis on its role in serving developers, enterprises, and content creators.\n",
      "* **Diversification**: AWS has diversified its services, offering a broad set of global compute, storage, database, and other service offerings.\n",
      "* **Competition**: AWS faces intense competition in the cloud computing market, but its scale, scope, and innovation have enabled it to maintain a strong position.\n",
      "\n",
      "In conclusion, AWS has evolved significantly as a segment since its early days, growing into a critical component of Amazon's overall business. Its contribution to Amazon's revenue has increased over the years, and it continues to play a vital role in the company's financial performance.\n",
      "\n",
      "Script completed. The endpoint remains active.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing PDF files\n",
    "pdf_directory = \"/home/ec2-user/SageMaker/Llama4_Assets/\"  # Replace with your directory path\n",
    "\n",
    "# Connect to your existing endpoint\n",
    "endpoint_name = 'meta-vlm-llama-4-scout-17b-16e-instruct-2025-04-14-20-01-24-485'  # Replace with your actual endpoint name\n",
    "print(f\"Connecting to existing endpoint: {endpoint_name}\")\n",
    "\n",
    "# Create a proper SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Create the predictor with the SageMaker session\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "print(\"Successfully connected to the endpoint\")\n",
    "\n",
    "try:\n",
    "    # Find PDF files\n",
    "    pdf_files = find_pdf_files(pdf_directory)\n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files found. Exiting.\")\n",
    "        raise SystemExit(0)\n",
    "    \n",
    "    # Extract summaries from PDFs\n",
    "    print(\"\\nExtracting key data from all PDFs...\")\n",
    "    pdf_summaries = extract_key_data_from_pdfs(pdf_files, predictor)\n",
    "    \n",
    "    if not pdf_summaries:\n",
    "        print(\"Failed to extract data from any PDFs. Exiting.\")\n",
    "        raise SystemExit(0)\n",
    "    \n",
    "    print(\"\\nSuccessfully extracted data from the following PDFs:\")\n",
    "    for pdf_name in pdf_summaries.keys():\n",
    "        print(f\"  - {pdf_name}\")\n",
    "    \n",
    "    # Define your questions\n",
    "    questions = [\n",
    "        \"How did Amazon's revenue and net income change over time?\",\n",
    "        \"What are the main business segments driving growth at Amazon over the years?\",\n",
    "        \"How has AWS evolved as a segment and what is its contribution to Amazon's overall business?\"\n",
    "    ]\n",
    "    \n",
    "    # Answer each question\n",
    "    for question in questions:\n",
    "        print(f\"\\nAnswering question: {question}\")\n",
    "        answer = synthesize_and_answer_question(pdf_summaries, question, predictor)\n",
    "        \n",
    "        if answer:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"ANSWER to: {question}\")\n",
    "            print(\"=\"*50)\n",
    "            print(answer)\n",
    "        else:\n",
    "            print(f\"Sorry, I couldn't generate an answer for: {question}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3443ce9d-5d13-454e-b727-ae731e38966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/15/25 05:51:38] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-vlm-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-14-20-01-24-485        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/15/25 05:51:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=852953;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=935791;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-vlm-llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-instruct-\u001b[1;36m2025\u001b[0m-04-14-20-01-24-485        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/15/25 05:51:39] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-vlm-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-scout-17b-16e-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-14-20-01-24-485        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/15/25 05:51:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=128557;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=318901;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-vlm-llama-\u001b[1;36m4\u001b[0m-scout-17b-16e-instruct-\u001b[1;36m2025\u001b[0m-04-14-20-01-24-485        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
