{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84870b3",
   "metadata": {},
   "source": [
    "# NOTE: This notebook was developed using a SageMaker AI Notebook using the conda_pytorch_p10 kernel. Please use a similar setup for the best experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5fef8-cb09-478c-9150-f57b0ac4809f",
   "metadata": {},
   "source": [
    "# üé¨ Agentic Video Processing with Llama 4 and Amazon Bedrock\n",
    "\n",
    "This notebook walks you through how to use AWS Strands to develop a multi-agent video processing solution powered by Llama 4 models hosted on Amazon Bedrock. \n",
    "\n",
    "## üöÄ What You'll Accomplish\n",
    "By the end of this notebook, you'll have built a complete AI system that can:\n",
    "- üé• **Automatically extract key frames** from any video\n",
    "- üëÅÔ∏è **Analyze visual content** with advanced AI understanding\n",
    "- ‚è∞ **Understand temporal relationships** between scenes\n",
    "- üìù **Generate comprehensive summaries** of video content\n",
    "- üåê **Deploy a web interface** for easy video processing\n",
    "\n",
    "There's a set of agents that we'll walk you through below. Before we jump into that, let's learn more about Bedrock, Strands, and Llama 4.\n",
    "\n",
    "\n",
    "## ‚òÅÔ∏è Amazon Bedrock\n",
    "\n",
    "\n",
    "Amazon Bedrock is a fully managed service that offers a choice of industry leading foundation models (FMs) along with a broad set of capabilities that you need to build generative AI applications, simplifying development with security, privacy, and responsible AI. With the comprehensive capabilities of Amazon Bedrock, you can experiment with a variety of top FMs, customize them privately with your data using techniques such as fine-tuning and retrieval-augmented generation (RAG), and create managed agents that execute complex business tasks‚Äîfrom booking travel and processing insurance claims to creating ad campaigns and managing inventory‚Äîall without writing any code. Since Amazon Bedrock is serverless, you don't have to manage any infrastructure, and you can securely integrate and deploy generative AI capabilities into your applications using the AWS services you are already familiar with. If you want to dive deep into, you can go [here](https://aws.amazon.com/bedrock/faqs/). \n",
    "\n",
    "## üï∏Ô∏è Strands SDK\n",
    "\n",
    "Strands Agents is an open source SDK that takes a model-driven approach to building and running AI agents in just a few lines of code. Strands scales from simple to complex agent use cases, and from local development to deployment in production. Multiple teams at AWS already use Strands for their AI agents in production, including Amazon Q Developer, AWS Glue, and VPC Reachability Analyzer.\n",
    "\n",
    "- [Introducing Strands Agents, an Open Source AI Agents SDK](https://aws.amazon.com/blogs/opensource/introducing-strands-agents-an-open-source-ai-agents-sdk/)\n",
    "\n",
    "\n",
    "## ü¶ô Meta Llama 4\n",
    "\n",
    "Llama 4 is a powerful family of large language models developed by Meta, specifically designed for enterprise applications. Available in two variants‚ÄîScout and Maverick‚Äîthese models represent significant advancements in AI capabilities. Llama 4 has the following Key Features and Capabilities: \n",
    "\n",
    "- üîç Multimodal Understanding: Accepts text plus up to 5 images as input, delivering text responses with sophisticated visual comprehension\n",
    "- üåç Extensive Multilingual Support: Proficient in Arabic, English, French, German, Hindi, Indonesian, Italian, Portuguese, Spanish, Tagalog, Thai, and Vietnamese (image understanding is English-only)\n",
    "- ‚ö° Mixture-of-Experts Architecture: Utilizes an innovative design where only 17B parameters are active during computation, despite larger total parameter counts\n",
    "- üè¢ Enterprise-Ready Applications: Optimized for coding tasks, tool-calling, multimodal understanding, and powering agentic systems\n",
    "\n",
    "## üìä Model Comparison\n",
    "| Feature | Llama 4 Scout | Llama 4 Maverick |\n",
    "|---------|---------------|------------------|\n",
    "| Active parameters | 17B | 17B |\n",
    "| Total parameters | 109B | 400B |\n",
    "| Number of experts | 16 | 128 |\n",
    "| Maximum context length | 10M tokens | 1M tokens |\n",
    "\n",
    "These models represent a significant advancement over previous Llama versions, with substantially improved reasoning capabilities, multimodal understanding, and performance on complex enterprise tasks. The mixture-of-experts architecture allows for impressive capabilities while maintaining efficient computation during inference.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dfbf69-8f7e-47a9-b0f2-a78181417035",
   "metadata": {},
   "source": [
    "üì¶ Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b59f2-7436-42c0-9459-7eb4f39f2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.39.0)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: strands in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.1.0)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (11.2.1)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.5.0)\n",
      "Requirement already satisfied: gradio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (5.42.0)\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.39.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.40.0,>=1.39.0->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.0->boto3) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (1.11.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (3.11.2)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.12.9)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.47.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (4.14.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio-client==1.11.1->gradio) (2025.7.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.16.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.2)\n",
      "Requirement already satisfied: strands-agents==0.1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: strands-agents-builder==0.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: strands-agents-tools==0.1.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.1.7)\n",
      "Requirement already satisfied: boto3==1.39.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.39.0)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow==11.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (11.2.1)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (1.39.13)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (0.17.0)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (1.13.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (1.36.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (4.14.1)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents==0.1.9) (6.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.39.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.39.0) (0.13.0)\n",
      "Requirement already satisfied: halo<1.0.0,>=0.0.31 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-builder==0.1.4) (0.0.31)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-builder==0.1.4) (3.0.51)\n",
      "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-builder==0.1.4) (14.0.0)\n",
      "Requirement already satisfied: aws-requests-auth<0.5.0,>=0.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (0.4.3)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (0.4.6)\n",
      "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (0.4.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (2.10.1)\n",
      "Requirement already satisfied: slack-bolt<2.0.0,>=1.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (1.23.0)\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (1.14.0)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools==0.1.7) (9.1.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opencv-python==4.11.0.86) (1.26.4)\n",
      "Requirement already satisfied: requests>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aws-requests-auth<0.5.0,>=0.4.3->strands-agents-tools==0.1.7) (2.32.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents==0.1.9) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents==0.1.9) (2.5.0)\n",
      "Requirement already satisfied: log_symbols>=0.0.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from halo<1.0.0,>=0.0.31->strands-agents-builder==0.1.4) (0.0.14)\n",
      "Requirement already satisfied: spinners>=0.0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from halo<1.0.0,>=0.0.31->strands-agents-builder==0.1.4) (0.0.24)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from halo<1.0.0,>=0.0.31->strands-agents-builder==0.1.4) (3.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from halo<1.0.0,>=0.0.31->strands-agents-builder==0.1.4) (1.17.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (4.9.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (4.24.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.47.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.35.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents==0.1.9) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents==0.1.9) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.30.0->strands-agents==0.1.9) (0.57b0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-builder==0.1.4) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents==0.1.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents==0.1.9) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents==0.1.9) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-builder==0.1.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-builder==0.1.4) (2.19.2)\n",
      "Requirement already satisfied: slack_sdk<4,>=3.35.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools==0.1.7) (3.36.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[ollama]<1.0.0,>=0.1.0->strands-agents-builder==0.1.4) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (0.26.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-builder==0.1.4) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=0.14.0->aws-requests-auth<0.5.0,>=0.4.3->strands-agents-tools==0.1.7) (3.4.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.8.0->strands-agents==0.1.9) (8.2.1)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "!pip install -r requirements.txt"
=======
    "!uv pip install -r requirements.txt"
>>>>>>> a86569d (refactor: changing notebook flow and required depedencies plus add a closing section)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf7dc3-848c-44aa-b27c-166a28ef033c",
   "metadata": {},
   "source": [
    "üì¶ Import all of the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8944e-3b8b-4267-9c5c-4f8fa4317248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from strands import Agent, tool\n",
    "from s3_frame_extraction_agent import s3_frame_extraction_agent\n",
    "from retrieve_json import retrieve_json_from_s3\n",
    "from retrieve_json import retrieve_json_agent\n",
    "from c_temporal_analysis_agent import c_temporal_analysis_agent\n",
    "from llama4_coordinator_agent import llama4_coordinator_agent\n",
    "from summary_generation_agent import summary_generation_agent\n",
    "from llama4_coordinator_agent import upload_analysis_results\n",
    "from s_visual_analysis_agent import s_visual_analysis_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5551d89-495e-4e98-86a6-1354777305aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current default region from boto3 session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "# Set environment variables based on detected region\n",
    "if region:\n",
    "    os.environ['AWS_DEFAULT_REGION'] = region\n",
    "    os.environ['AWS_REGION'] = region\n",
    "    boto3.setup_default_session(region_name=region)\n",
    "\n",
    "# Define your Bedrock model (adjust if needed)\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id='us.meta.llama4-maverick-17b-instruct-v1:0',\n",
    "    region_name=region,\n",
    "    streaming=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2111-78e8-4d12-baf9-91b464fa0aee",
   "metadata": {},
   "source": [
    "üé¨ SageMaker Video Upload Function\n",
    "\n",
    "This Python function `upload_to_sagemaker_bucket()` handles uploading video files to a SageMaker S3 bucket with organized folder structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d05db8-6966-4fc6-9c07-704380ff2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "local_video_path=\"../../videos/buglifeflik.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cda639e-309d-4fbb-8c3b-6882b04e94cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded to s3://sagemaker-us-west-2-333633606362/videos/buglifeflik/buglifeflik.mp4\n"
     ]
    }
   ],
   "source": [
    "def upload_to_sagemaker_bucket(local_video_path, base_folder=\"videos/\"):\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Get default SageMaker bucket\n",
    "    account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "    region = boto3.Session().region_name\n",
    "    bucket_name = f\"sagemaker-{region}-{account_id}\"\n",
    "    # Get filename and create subfolder name\n",
    "    filename = os.path.basename(local_video_path)\n",
    "    filename_without_ext = os.path.splitext(filename)[0]\n",
    "    # Create the full S3 path: videos/filename_without_ext/filename\n",
    "    s3_key = os.path.join(base_folder, filename_without_ext, filename)\n",
    "    # Upload file\n",
    "    s3.upload_file(local_video_path, bucket_name, s3_key)  \n",
    "    s3_uri = f\"s3://{bucket_name}/{s3_key}\"\n",
    "    print(f\"Uploaded to {s3_uri}\")  \n",
    "\n",
    "    s3_folder_path = os.path.join(base_folder, filename_without_ext)\n",
    "    s3_folder_uri = f\"s3://{bucket_name}/{s3_folder_path}\"\n",
    "\n",
    "    return s3_folder_uri\n",
    "\n",
    "# Example usage: Provide your local video path here\n",
    "s3_video_uri = upload_to_sagemaker_bucket(local_video_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f51b108-55b6-4881-837a-eb26edd0c17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-333633606362/videos/buglifeflik\n"
     ]
    }
   ],
   "source": [
    "print(s3_video_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb894d-ddc3-4108-a311-719a5bcbf4fe",
   "metadata": {},
   "source": [
    "üöÄ Agent Workflow Kickoff\n",
    "\n",
    "This code initiates the video processing agent workflow:\n",
    "\n",
    "```python\n",
    "# Start the workflow\n",
    "video_instruction = f\"Process a video from {s3_video_uri}\"\n",
    "print(video_instruction)\n",
    "response = llama4_coordinator_agent(video_instruction)\n",
    "```\n",
    "\n",
    "Once the video processing agent is kicked off, you will see an output of all the tools passing the outputs to each other. It may take a few minutes to run. The final agent should be the summary_generation_agent, which will summarize the video. It should look like:\n",
    "\n",
    "```\n",
    "Tool #: run_summary_generation\n",
    "\n",
    "Output of the generated summary of the video.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7950ed-0181-4bfc-b070-7774342a644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: run_frame_extraction\n",
      "\n",
      "Tool #2: run_visual_analysis\n",
      "\n",
      "Tool #3: retrieve_json_from_s3\n",
      "\n",
      "Tool #4: run_temporal_reasoning\n",
      "\n",
      "Tool #5: run_summary_generation\n",
      "\n",
      "Tool #6: run_summary_generation\n",
      "**What happens in the video:**\n",
      "The video follows Flik as he navigates through a series of events, starting from being cautious in a natural setting, seeking help or communicating with other insects, participating in a crucial discussion or planning, and finally taking action with the group.\n",
      "\n",
      "**Chronological Sequence of Events:**\n",
      "The sequence begins with Flik being cautious near a tree, followed by him approaching a group of insects, then being part of a significant gathering or discussion, and concludes with Flik and the insects taking action together.\n",
      "\n",
      "**Sequence of events:**\n",
      "1. Flik is initially seen being cautious in a natural environment.\n",
      "2. He then approaches a group of insects, likely to communicate or seek help.\n",
      "3. A gathering of insects is shown with Flik at the center, indicating a crucial discussion or planning.\n",
      "4. The final scene shows Flik and the insects in action, possibly executing a plan or facing a challenge.\n",
      "\n",
      "**Key visual elements:**\n",
      "The key visual elements include Flik's cautious initial stance, his interaction with other insects, the gathering or discussion, and the final action scene, highlighting the progression from solitude to collective action.\n",
      "\n",
      "**Overall Narrative:**\n",
      "The narrative follows Flik's journey from caution and seeking help to participating in a crucial discussion and finally to taking action with a group of insects, suggesting a story arc that involves progression, planning, and collective action.\n",
      "Tool #7: upload_analysis_results\n",
      "The video processing is complete. The final analysis results are saved to s3://sagemaker-us-west-2-333633606362/videos/buglifeflik/analysis_results_20250818_190012.json.The video processing is complete. The final analysis results are saved to s3://sagemaker-us-west-2-333633606362/videos/buglifeflik/analysis_results_20250818_190012.json.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start the workflow\n",
    "agent = llama4_coordinator_agent()\n",
    "video_instruction = f\"Process a video from {s3_video_uri}. Use tools in this order: run_frame_extraction, run_visual_analysis, retrieve_json_from_s3, run temporal_reasoning, run_summary_generation_ upload_analysis_results\" \n",
    "response = agent(video_instruction)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78a44e7-b8d6-4728-b20c-9102ef441f83",
   "metadata": {},
   "source": [
    "üîÑ Instantiate a new agent for processing\n",
    "\n",
    "Feel free to test additional videos by adding it to the /videos folder and adding it to the S3 URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a994b90-d78a-4ad8-bf01-63045e812fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For video 2\n",
    "agent = llama4_coordinator_agent()\n",
    "video_instruction = f\"Process a video from {s3_video_uri}\"\n",
    "response = agent(video_instruction)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "1f093828",
=======
   "id": "documentation-section-moved",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# üìö How the Multi-Agent System Works\n",
    "\n",
    "Now that you've seen the system in action, here's how the agents work together:\n",
    "\n",
    "## üîÑ Agent Flow\n",
    "1. üéØ **Coordinator Agent** - Orchestrates the entire workflow\n",
    "2. üé¨ **Frame Extraction Agent** - Extracts key frames from video\n",
    "3. üëÅÔ∏è **Visual Analysis Agent** - Analyzes each frame with Llama 4\n",
    "4. ‚è∞ **Temporal Analysis Agent** - Understands sequence and flow\n",
    "5. üìù **Summary Generation Agent** - Creates final comprehensive summary\n",
    "\n",
    "## üèóÔ∏è Architecture Benefits\n",
    "- ‚ö° **Parallel Processing** - Each agent optimized for its specific task\n",
    "- üîß **Modular Design** - Easy to modify or replace individual agents\n",
    "- üìà **Scalable** - Can handle multiple videos simultaneously\n",
    "- üõ°Ô∏è **Robust** - Built-in error handling and retry mechanisms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14052b0a-e750-4c85-b5be-7b6f9aa41cff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìö Video Analysis Agentic Flow Documentation\n",
    "\n",
    "Now that you've seen the system in action, let's dive deeper into how it works!\n",
    "\n",
    "## üîç Overview\n",
    "\n",
    "This document explains the detailed agentic workflow for the video analysis system. The system uses a multi-agent architecture where specialized AI agents handle different stages of video processing, orchestrated by a coordinator agent.\n",
    "\n",
    "## üèóÔ∏è System Architecture\n",
    "\n",
    "The system follows a sequential pipeline where each agent performs a specific task and passes its output to the next agent in the chain. This modular approach ensures separation of concerns and allows for independent optimization of each processing stage.\n",
    "\n",
    "## üîÑ Agentic Flow Diagram\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[User Input: S3 Video Path] --> B[Coordinator Agent]\n",
    "    \n",
    "    B --> C[Frame Extraction Agent]\n",
    "    C --> D[Extract Frames from S3 Video]\n",
    "    D --> E[Upload Frames to S3 Folder]\n",
    "    E --> F[Return S3 Folder Path]\n",
    "    \n",
    "    F --> G[Visual Analysis Agent]\n",
    "    G --> H[List Frames in S3 Folder]\n",
    "    H --> I[Download & Resize Frames]\n",
    "    I --> J[Analyze Each Frame with Bedrock]\n",
    "    J --> K[Return Frame Descriptions]\n",
    "    \n",
    "    K --> L[Temporal Analysis Agent]\n",
    "    L --> M[Analyze Chronological Sequence]\n",
    "    M --> N[Identify Transitions & Flow]\n",
    "    N --> O[Return Temporal Analysis]\n",
    "    \n",
    "    O --> P[Summary Generation Agent]\n",
    "    P --> Q[Synthesize Visual & Temporal Data]\n",
    "    Q --> R[Generate Comprehensive Summary]\n",
    "    R --> S[Final Video Summary]\n",
    "    \n",
    "    subgraph \"AWS Services\"\n",
    "        T[S3 Storage]\n",
    "        U[Bedrock AI Models]\n",
    "    end\n",
    "    \n",
    "    C -.-> T\n",
    "    G -.-> T\n",
    "    G -.-> U\n",
    "    L -.-> U\n",
    "    P -.-> U\n",
    "    \n",
    "    style B fill:#e1f5fe\n",
    "    style C fill:#f3e5f5\n",
    "    style G fill:#e8f5e8\n",
    "    style L fill:#fff3e0\n",
    "    style P fill:#fce4ec\n",
    "```\n",
    "\n",
    "## ü§ñ Detailed Agent Breakdown\n",
    "\n",
    "### 1. üéØ Coordinator Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Orchestrates the entire video processing workflow by calling other agents in sequence.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Receives video input\n",
    "- Calls frame extraction agent\n",
    "- Passes frame location to visual analysis agent\n",
    "- Forwards visual analysis results to temporal analysis agent\n",
    "- Combines visual and temporal results for summary generation\n",
    "\n",
    "**Tools Available**:\n",
    "- `run_frame_extraction()`\n",
    "- `run_visual_analysis()`\n",
    "- `run_temporal_reasoning()`\n",
    "- `run_summary_generation()`\n",
    "\n",
    "### 2. üé¨ Frame Extraction Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Extracts key frames from videos stored in S3 buckets.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Calculates optimal frame positions (max 5 frames by default)\n",
    "- Uses OpenCV for frame extraction with seeking optimization\n",
    "- Resizes frames and uploads to S3 with parallel processing\n",
    "- Returns structured JSON with frame locations\n",
    "\n",
    "**Tools Available**:\n",
    "- `extract_frames_from_s3()`: Main extraction function\n",
    "- `get_frames_folder_path()`: Parses extraction results\n",
    "\n",
    "**Technical Details**:\n",
    "- Uses `cv2.CAP_PROP_POS_FRAMES` for efficient seeking\n",
    "- Parallel uploads with `ThreadPoolExecutor` (max 3 workers)\n",
    "- JPEG compression with 85% quality\n",
    "- Automatic folder naming with timestamps\n",
    "\n",
    "### 3. üëÅÔ∏è Visual Analysis Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Analyzes extracted frames to identify objects, people, actions, and settings.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Lists all frames in the S3 folder\n",
    "- Downloads and processes each frame\n",
    "- Resizes images to meet Bedrock's 262,144 pixel limit\n",
    "- Performs visual analysis using Bedrock's vision capabilities\n",
    "- Implements throttling protection and retry mechanisms\n",
    "\n",
    "**Tools Available**:\n",
    "- `list_s3_frames()`: Lists image files in S3 folder\n",
    "- `resize_s3_image()`: Resizes large images\n",
    "- `analyze_image()`: Single frame analysis with retry logic\n",
    "- `analyze_all_frames()`: Async processing of all frames\n",
    "- `analyze_frames_batch()`: Batch processing with delays\n",
    "\n",
    "**Anti-Throttling Features**:\n",
    "- Exponential backoff for retry attempts\n",
    "- Controlled concurrency (max 2 concurrent requests)\n",
    "- Batch processing with configurable delays\n",
    "- Automatic image resizing for Bedrock compatibility\n",
    "\n",
    "### 4. ‚è∞ Temporal Analysis Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Analyzes temporal relationships and sequences between frames.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Examines chronological sequence of events\n",
    "- Identifies transitions between frames\n",
    "- Analyzes overall narrative flow\n",
    "- Detects key changes or movements over time\n",
    "\n",
    "**Analysis Focus Areas**:\n",
    "1. **Chronological Sequence**: Order of events across frames\n",
    "2. **Transitions**: How scenes change between frames\n",
    "3. **Narrative Flow**: Overall story or progression\n",
    "4. **Key Changes**: Significant movements or alterations\n",
    "\n",
    "### 5. üìù Summary Generation Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Creates comprehensive video summaries from visual and temporal analysis data.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Synthesizes visual analysis results\n",
    "- Incorporates temporal flow insights\n",
    "- Generates coherent narrative summaries\n",
    "- Provides structured output formats\n",
    "\n",
    "**Tools Available**:\n",
    "- `generate_comprehensive_summary()`: Creates detailed summaries\n",
    "- `customize_output_format()`: Formats output (narrative, bullets, JSON, etc.)\n",
    "- `summarize_visual_temporal()`: Combines visual and temporal data\n",
    "\n",
    "### üìä Sample of Visual Analysis Output\n",
    "```json\n",
    "{\n",
    "  \"folder\": \"s3://bucket-name/frames-folder/\",\n",
    "  \"analyses\": [\n",
    "    {\n",
    "      \"image_url\": \"s3://bucket-name/frame_1.jpg\",\n",
    "      \"analysis\": \"Detailed description of frame content...\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### ‚è∞ Temporal Analysis Output\n",
    "```\n",
    "Structured analysis of:\n",
    "- Chronological sequence of events\n",
    "- Transitions between frames\n",
    "- Overall narrative flow\n",
    "- Key changes or movements\n",
    "```\n",
    "\n",
    "### üìù Final Summary Output\n",
    "```\n",
    "Comprehensive video summary combining visual elements, \n",
    "temporal flow, and narrative structure into a coherent \n",
    "description of the video content.\n",
    "```\n",
    "\n",
    "## ‚ö° Performance Optimizations\n",
    "\n",
    "### üé¨ Frame Extraction\n",
    "- **Seeking Optimization**: Uses `cv2.CAP_PROP_POS_FRAMES` instead of sequential reading\n",
    "- **Parallel Uploads**: ThreadPoolExecutor with 3 workers\n",
    "- **Smart Sampling**: Distributes frames evenly across video duration\n",
    "\n",
    "### üëÅÔ∏è Visual Analysis\n",
    "- **Async Processing**: Concurrent frame analysis with semaphore control\n",
    "- **Batch Processing**: Groups frames to minimize API calls\n",
    "- **Image Optimization**: Automatic resizing and compression\n",
    "\n",
    "### üíæ Memory Management\n",
    "- **Temporary Files**: Automatic cleanup of downloaded content\n",
    "- **Streaming**: Direct S3 to Bedrock processing where possible\n",
    "- **Resource Limits**: Controlled concurrency to prevent resource exhaustion\n",
    "\n",
    "## ‚öôÔ∏è Configuration Parameters\n",
    "\n",
    "### üé¨ Frame Extraction\n",
    "- `max_frames`: Maximum frames to extract (default: 5)\n",
    "- `jpeg_quality`: Compression quality (default: 85)\n",
    "- `max_workers`: Parallel upload threads (default: 3)\n",
    "\n",
    "### üëÅÔ∏è Visual Analysis\n",
    "- `max_concurrent`: Concurrent analysis requests (default: 2)\n",
    "- `batch_size`: Frames per batch (default: 3)\n",
    "- `delay_between_batches`: Batch delay in seconds (default: 5.0)\n",
    "- `max_pixels`: Image size limit (default: 262,144)\n",
    "\n",
    "### üîÑ Retry Logic\n",
    "- `max_retries`: Maximum retry attempts (default: 3)\n",
    "- `base_delay`: Initial retry delay (default: 2 seconds)\n",
    "- `max_delay`: Maximum retry delay (default: 30 seconds)\n",
    "\n",
    "## üí° Usage Examples\n",
    "\n",
    "### üöÄ Basic Usage\n",
    "```python\n",
    "# Process a video through the coordinator\n",
    "response = coordinator_agent(\"Process a video from s3://my-bucket/videos/sample-video\")\n",
    "```\n",
    "\n",
    "### üîß Individual Agent Usage\n",
    "```python\n",
    "# Extract frames only\n",
    "frames_result = s3_frame_extraction_agent(\"Extract frames from s3://my-bucket/videos/sample-video\")\n",
    "\n",
    "# Analyze specific frames\n",
    "analysis_result = s3_visual_analysis_agent(\"Analyze frames in s3://my-bucket/frames-folder/\")\n",
    "\n",
    "# Temporal analysis\n",
    "temporal_result = temporal_analysis_agent(\"Analyze temporal flow: [frame descriptions]\")\n",
    "\n",
    "# Generate summary\n",
    "summary_result = summary_generation_agent(\"Create summary from: [analysis data]\")\n",
    "```\n",
    "\n",
    "## ‚úÖ Best Practices\n",
    "\n",
    "1. **üé• Video Preparation**: Ensure videos are in supported formats (mp4, avi, mov)\n",
    "2. **üìÅ S3 Organization**: Use consistent folder structures for better management\n",
    "3. **üìä Monitoring**: Watch for throttling errors and adjust concurrency accordingly\n",
    "4. **üßπ Resource Management**: Clean up temporary files and unused S3 objects\n",
    "5. **üõ°Ô∏è Error Handling**: Implement proper error handling for production use\n",
    "6. **üí∞ Cost Optimization**: Monitor Bedrock usage and optimize frame extraction parameters\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### ‚ö†Ô∏è Common Issues\n",
    "- **üö´ Throttling Errors**: Reduce concurrency or increase delays\n",
    "- **üìè Image Size Errors**: Ensure automatic resizing is enabled\n",
    "- **üîê S3 Access Issues**: Verify bucket permissions and region settings\n",
    "- **ü§ñ Model Availability**: Check Bedrock model availability in your region\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradio-section-id",
>>>>>>> a86569d (refactor: changing notebook flow and required depedencies plus add a closing section)
   "metadata": {},
   "source": [
    "# üöÄ Running the Gradio Application\n",
    "\n",
    "Launch the web interface for interactive video processing:\n",
    "\n",
    "```bash\n",
    "python gradio_app.py\n",
    "```\n",
    "\n",
    "This will start the Gradio interface where you can:\n",
    "- üìÅ Upload video files through the web interface\n",
    "- ‚è±Ô∏è Monitor processing progress in real-time\n",
    "- üñºÔ∏è View extracted frames and analysis results\n",
<<<<<<< HEAD
    "- üíæ Download the final analysis results\n",
    "\n",
    "## üîó Accessing from SageMaker\n",
    "\n",
    "If running this notebook in SageMaker, access the Gradio interface at:\n",
    "\n",
    "**https://your-notebook-instance.notebook.region.sagemaker.aws/proxy/7860/**\n",
    "\n",
    "Replace `your-notebook-instance` and `region` with your actual SageMaker notebook details."
=======
    "- üíæ Download the final analysis results"
>>>>>>> a86569d (refactor: changing notebook flow and required depedencies plus add a closing section)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "f4aee64a",
=======
   "id": "8a506c0f",
>>>>>>> a86569d (refactor: changing notebook flow and required depedencies plus add a closing section)
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gradio_app.py"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "documentation-section-moved",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# üìö How the Multi-Agent System Works\n",
    "\n",
    "Now that you've seen the system in action, here's how the agents work together:\n",
    "\n",
    "## üîÑ Agent Flow\n",
    "1. üéØ **Coordinator Agent** - Orchestrates the entire workflow\n",
    "2. üé¨ **Frame Extraction Agent** - Extracts key frames from video\n",
    "3. üëÅÔ∏è **Visual Analysis Agent** - Analyzes each frame with Llama 4\n",
    "4. ‚è∞ **Temporal Analysis Agent** - Understands sequence and flow\n",
    "5. üìù **Summary Generation Agent** - Creates final comprehensive summary\n",
    "\n",
    "## üèóÔ∏è Architecture Benefits\n",
    "- ‚ö° **Parallel Processing** - Each agent optimized for its specific task\n",
    "- üîß **Modular Design** - Easy to modify or replace individual agents\n",
    "- üìà **Scalable** - Can handle multiple videos simultaneously\n",
    "- üõ°Ô∏è **Robust** - Built-in error handling and retry mechanisms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14052b0a-e750-4c85-b5be-7b6f9aa41cff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìö Video Analysis Agentic Flow Documentation\n",
    "\n",
    "Now that you've seen the system in action, let's dive deeper into how it works!\n",
    "\n",
    "## üîç Overview\n",
    "\n",
    "This document explains the detailed agentic workflow for the video analysis system. The system uses a multi-agent architecture where specialized AI agents handle different stages of video processing, orchestrated by a coordinator agent.\n",
    "\n",
    "## üèóÔ∏è System Architecture\n",
    "\n",
    "The system follows a sequential pipeline where each agent performs a specific task and passes its output to the next agent in the chain. This modular approach ensures separation of concerns and allows for independent optimization of each processing stage.\n",
    "\n",
    "## üîÑ Agentic Flow Diagram\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[User Input: S3 Video Path] --> B[Coordinator Agent]\n",
    "    \n",
    "    B --> C[Frame Extraction Agent]\n",
    "    C --> D[Extract Frames from S3 Video]\n",
    "    D --> E[Upload Frames to S3 Folder]\n",
    "    E --> F[Return S3 Folder Path]\n",
    "    \n",
    "    F --> G[Visual Analysis Agent]\n",
    "    G --> H[List Frames in S3 Folder]\n",
    "    H --> I[Download & Resize Frames]\n",
    "    I --> J[Analyze Each Frame with Bedrock]\n",
    "    J --> K[Return Frame Descriptions]\n",
    "    \n",
    "    K --> L[Temporal Analysis Agent]\n",
    "    L --> M[Analyze Chronological Sequence]\n",
    "    M --> N[Identify Transitions & Flow]\n",
    "    N --> O[Return Temporal Analysis]\n",
    "    \n",
    "    O --> P[Summary Generation Agent]\n",
    "    P --> Q[Synthesize Visual & Temporal Data]\n",
    "    Q --> R[Generate Comprehensive Summary]\n",
    "    R --> S[Final Video Summary]\n",
    "    \n",
    "    subgraph \"AWS Services\"\n",
    "        T[S3 Storage]\n",
    "        U[Bedrock AI Models]\n",
    "    end\n",
    "    \n",
    "    C -.-> T\n",
    "    G -.-> T\n",
    "    G -.-> U\n",
    "    L -.-> U\n",
    "    P -.-> U\n",
    "    \n",
    "    style B fill:#e1f5fe\n",
    "    style C fill:#f3e5f5\n",
    "    style G fill:#e8f5e8\n",
    "    style L fill:#fff3e0\n",
    "    style P fill:#fce4ec\n",
    "```\n",
    "\n",
    "## ü§ñ Detailed Agent Breakdown\n",
    "\n",
    "### 1. üéØ Coordinator Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Orchestrates the entire video processing workflow by calling other agents in sequence.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Receives video input\n",
    "- Calls frame extraction agent\n",
    "- Passes frame location to visual analysis agent\n",
    "- Forwards visual analysis results to temporal analysis agent\n",
    "- Combines visual and temporal results for summary generation\n",
    "\n",
    "**Tools Available**:\n",
    "- `run_frame_extraction()`\n",
    "- `run_visual_analysis()`\n",
    "- `run_temporal_reasoning()`\n",
    "- `run_summary_generation()`\n",
    "\n",
    "### 2. üé¨ Frame Extraction Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Extracts key frames from videos stored in S3 buckets.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Calculates optimal frame positions (max 5 frames by default)\n",
    "- Uses OpenCV for frame extraction with seeking optimization\n",
    "- Resizes frames and uploads to S3 with parallel processing\n",
    "- Returns structured JSON with frame locations\n",
    "\n",
    "**Tools Available**:\n",
    "- `extract_frames_from_s3()`: Main extraction function\n",
    "- `get_frames_folder_path()`: Parses extraction results\n",
    "\n",
    "**Technical Details**:\n",
    "- Uses `cv2.CAP_PROP_POS_FRAMES` for efficient seeking\n",
    "- Parallel uploads with `ThreadPoolExecutor` (max 3 workers)\n",
    "- JPEG compression with 85% quality\n",
    "- Automatic folder naming with timestamps\n",
    "\n",
    "### 3. üëÅÔ∏è Visual Analysis Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Analyzes extracted frames to identify objects, people, actions, and settings.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Lists all frames in the S3 folder\n",
    "- Downloads and processes each frame\n",
    "- Resizes images to meet Bedrock's 262,144 pixel limit\n",
    "- Performs visual analysis using Bedrock's vision capabilities\n",
    "- Implements throttling protection and retry mechanisms\n",
    "\n",
    "**Tools Available**:\n",
    "- `list_s3_frames()`: Lists image files in S3 folder\n",
    "- `resize_s3_image()`: Resizes large images\n",
    "- `analyze_image()`: Single frame analysis with retry logic\n",
    "- `analyze_all_frames()`: Async processing of all frames\n",
    "- `analyze_frames_batch()`: Batch processing with delays\n",
    "\n",
    "**Anti-Throttling Features**:\n",
    "- Exponential backoff for retry attempts\n",
    "- Controlled concurrency (max 2 concurrent requests)\n",
    "- Batch processing with configurable delays\n",
    "- Automatic image resizing for Bedrock compatibility\n",
    "\n",
    "### 4. ‚è∞ Temporal Analysis Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Analyzes temporal relationships and sequences between frames.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Examines chronological sequence of events\n",
    "- Identifies transitions between frames\n",
    "- Analyzes overall narrative flow\n",
    "- Detects key changes or movements over time\n",
    "\n",
    "**Analysis Focus Areas**:\n",
    "1. **Chronological Sequence**: Order of events across frames\n",
    "2. **Transitions**: How scenes change between frames\n",
    "3. **Narrative Flow**: Overall story or progression\n",
    "4. **Key Changes**: Significant movements or alterations\n",
    "\n",
    "### 5. üìù Summary Generation Agent\n",
    "\n",
    "**Model**: `us.meta.llama4-maverick-17b-instruct-v1:0`\n",
    "\n",
    "**Purpose**: Creates comprehensive video summaries from visual and temporal analysis data.\n",
    "\n",
    "**Key Responsibilities**:\n",
    "- Synthesizes visual analysis results\n",
    "- Incorporates temporal flow insights\n",
    "- Generates coherent narrative summaries\n",
    "- Provides structured output formats\n",
    "\n",
    "**Tools Available**:\n",
    "- `generate_comprehensive_summary()`: Creates detailed summaries\n",
    "- `customize_output_format()`: Formats output (narrative, bullets, JSON, etc.)\n",
    "- `summarize_visual_temporal()`: Combines visual and temporal data\n",
    "\n",
    "### üìä Sample of Visual Analysis Output\n",
    "```json\n",
    "{\n",
    "  \"folder\": \"s3://bucket-name/frames-folder/\",\n",
    "  \"analyses\": [\n",
    "    {\n",
    "      \"image_url\": \"s3://bucket-name/frame_1.jpg\",\n",
    "      \"analysis\": \"Detailed description of frame content...\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### ‚è∞ Temporal Analysis Output\n",
    "```\n",
    "Structured analysis of:\n",
    "- Chronological sequence of events\n",
    "- Transitions between frames\n",
    "- Overall narrative flow\n",
    "- Key changes or movements\n",
    "```\n",
    "\n",
    "### üìù Final Summary Output\n",
    "```\n",
    "Comprehensive video summary combining visual elements, \n",
    "temporal flow, and narrative structure into a coherent \n",
    "description of the video content.\n",
    "```\n",
    "\n",
    "## ‚ö° Performance Optimizations\n",
    "\n",
    "### üé¨ Frame Extraction\n",
    "- **Seeking Optimization**: Uses `cv2.CAP_PROP_POS_FRAMES` instead of sequential reading\n",
    "- **Parallel Uploads**: ThreadPoolExecutor with 3 workers\n",
    "- **Smart Sampling**: Distributes frames evenly across video duration\n",
    "\n",
    "### üëÅÔ∏è Visual Analysis\n",
    "- **Async Processing**: Concurrent frame analysis with semaphore control\n",
    "- **Batch Processing**: Groups frames to minimize API calls\n",
    "- **Image Optimization**: Automatic resizing and compression\n",
    "\n",
    "### üíæ Memory Management\n",
    "- **Temporary Files**: Automatic cleanup of downloaded content\n",
    "- **Streaming**: Direct S3 to Bedrock processing where possible\n",
    "- **Resource Limits**: Controlled concurrency to prevent resource exhaustion\n",
    "\n",
    "## ‚öôÔ∏è Configuration Parameters\n",
    "\n",
    "### üé¨ Frame Extraction\n",
    "- `max_frames`: Maximum frames to extract (default: 5)\n",
    "- `jpeg_quality`: Compression quality (default: 85)\n",
    "- `max_workers`: Parallel upload threads (default: 3)\n",
    "\n",
    "### üëÅÔ∏è Visual Analysis\n",
    "- `max_concurrent`: Concurrent analysis requests (default: 2)\n",
    "- `batch_size`: Frames per batch (default: 3)\n",
    "- `delay_between_batches`: Batch delay in seconds (default: 5.0)\n",
    "- `max_pixels`: Image size limit (default: 262,144)\n",
    "\n",
    "### üîÑ Retry Logic\n",
    "- `max_retries`: Maximum retry attempts (default: 3)\n",
    "- `base_delay`: Initial retry delay (default: 2 seconds)\n",
    "- `max_delay`: Maximum retry delay (default: 30 seconds)\n",
    "\n",
    "## üí° Usage Examples\n",
    "\n",
    "### üöÄ Basic Usage\n",
    "```python\n",
    "# Process a video through the coordinator\n",
    "response = coordinator_agent(\"Process a video from s3://my-bucket/videos/sample-video\")\n",
    "```\n",
    "\n",
    "### üîß Individual Agent Usage\n",
    "```python\n",
    "# Extract frames only\n",
    "frames_result = s3_frame_extraction_agent(\"Extract frames from s3://my-bucket/videos/sample-video\")\n",
    "\n",
    "# Analyze specific frames\n",
    "analysis_result = s3_visual_analysis_agent(\"Analyze frames in s3://my-bucket/frames-folder/\")\n",
    "\n",
    "# Temporal analysis\n",
    "temporal_result = temporal_analysis_agent(\"Analyze temporal flow: [frame descriptions]\")\n",
    "\n",
    "# Generate summary\n",
    "summary_result = summary_generation_agent(\"Create summary from: [analysis data]\")\n",
    "```\n",
    "\n",
    "## ‚úÖ Best Practices\n",
    "\n",
    "1. **üé• Video Preparation**: Ensure videos are in supported formats (mp4, avi, mov)\n",
    "2. **üìÅ S3 Organization**: Use consistent folder structures for better management\n",
    "3. **üìä Monitoring**: Watch for throttling errors and adjust concurrency accordingly\n",
    "4. **üßπ Resource Management**: Clean up temporary files and unused S3 objects\n",
    "5. **üõ°Ô∏è Error Handling**: Implement proper error handling for production use\n",
    "6. **üí∞ Cost Optimization**: Monitor Bedrock usage and optimize frame extraction parameters\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### ‚ö†Ô∏è Common Issues\n",
    "- **üö´ Throttling Errors**: Reduce concurrency or increase delays\n",
    "- **üìè Image Size Errors**: Ensure automatic resizing is enabled\n",
    "- **üîê S3 Access Issues**: Verify bucket permissions and region settings\n",
    "- **ü§ñ Model Availability**: Check Bedrock model availability in your region\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
=======
>>>>>>> a86569d (refactor: changing notebook flow and required depedencies plus add a closing section)
   "id": "json-visualization-id",
   "metadata": {},
   "source": [
    "# üìä Visualizing Analysis Results\n",
    "\n",
    "View and explore the JSON analysis file generated by the processing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "json-viz-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
<<<<<<< HEAD
    "\n",
    "# Automatically find and display the latest analysis JSON file\n",
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name or \"us-west-2\"\n",
    "bucket = f\"sagemaker-{region}-{account_id}\"\n",
    "\n",
    "# List all analysis files in the videos folder\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=\"videos/\")\n",
    "analysis_files = [obj for obj in response.get('Contents', []) if obj['Key'].endswith('analysis_results.json')]\n",
    "\n",
    "if analysis_files:\n",
    "    # Get the most recent analysis file\n",
    "    latest_file = max(analysis_files, key=lambda x: x['LastModified'])\n",
    "    print(f\"üìÑ Loading latest analysis: {latest_file['Key']}\")\n",
    "    \n",
    "    # Download and display the JSON content\n",
    "    response = s3.get_object(Bucket=bucket, Key=latest_file['Key'])\n",
    "    analysis_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä VIDEO ANALYSIS RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(json.dumps(analysis_data, indent=2))\n",
    "else:\n",
    "    print(\"‚ùå No analysis files found. Run the video processing first.\")"
=======
    "from pprint import pprint\n",
    "\n",
    "def load_and_display_analysis(s3_uri):\n",
    "    \"\"\"\n",
    "    Load and display the analysis results JSON file from S3\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Parse S3 URI\n",
    "    bucket = s3_uri.split('/')[2]\n",
    "    key = '/'.join(s3_uri.split('/')[3:])\n",
    "    \n",
    "    try:\n",
    "        # Download and parse JSON\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        analysis_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "        \n",
    "        print(\"=== VIDEO ANALYSIS RESULTS ===\")\n",
    "        print(f\"Video: {analysis_data.get('video_path', 'Unknown')}\")\n",
    "        print(f\"Processing Date: {analysis_data.get('timestamp', 'Unknown')}\")\n",
    "        print(\"\\n=== FRAME EXTRACTION ===\")\n",
    "        frame_info = analysis_data.get('frame_extraction', {})\n",
    "        print(f\"Frames Extracted: {len(frame_info.get('frames', []))}\")\n",
    "        print(f\"Frames Folder: {frame_info.get('frames_folder', 'Unknown')}\")\n",
    "        \n",
    "        print(\"\\n=== VISUAL ANALYSIS ===\")\n",
    "        visual_analysis = analysis_data.get('visual_analysis', {})\n",
    "        analyses = visual_analysis.get('analyses', [])\n",
    "        for i, analysis in enumerate(analyses[:3]):  # Show first 3 frames\n",
    "            print(f\"\\nFrame {i+1}:\")\n",
    "            print(f\"Image: {analysis.get('image_url', 'Unknown')}\")\n",
    "            print(f\"Analysis: {analysis.get('analysis', 'No analysis')[:200]}...\")\n",
    "        \n",
    "        print(\"\\n=== TEMPORAL ANALYSIS ===\")\n",
    "        temporal = analysis_data.get('temporal_analysis', 'No temporal analysis available')\n",
    "        print(temporal[:500] + \"...\" if len(temporal) > 500 else temporal)\n",
    "        \n",
    "        print(\"\\n=== FINAL SUMMARY ===\")\n",
    "        summary = analysis_data.get('final_summary', 'No summary available')\n",
    "        print(summary)\n",
    "        \n",
    "        return analysis_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Automatically find and load the most recent analysis file\n",
    "s3 = boto3.client('s3')\n",
    "bucket = s3_video_uri.split('/')[2]\n",
    "prefix = '/'.join(s3_video_uri.split('/')[3:])\n",
    "\n",
    "# List analysis files\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=f\"{prefix}/analysis_results_\")\n",
    "if 'Contents' in response:\n",
    "    # Get the most recent analysis file\n",
    "    latest_file = max(response['Contents'], key=lambda x: x['LastModified'])\n",
    "    analysis_s3_uri = f\"s3://{bucket}/{latest_file['Key']}\"\n",
    "    analysis_data = load_and_display_analysis(analysis_s3_uri)\n",
    "else:\n",
    "    print(\"No analysis files found\")"
>>>>>>> a86569d (refactor: changing notebook flow and required depedencies plus add a closing section)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section-id",
   "metadata": {},
   "source": [
    "# üßπ Cleanup and Resource Management\n",
    "\n",
    "## üóÇÔ∏è What to Clean Up\n",
    "\n",
    "1. **‚òÅÔ∏è S3 Storage**: Delete temporary frame folders and old processing files\n",
    "2. **üíª Local Files**: Remove any downloaded videos or cached images\n",
    "3. **üìä Analysis Results**: Archive or delete old analysis JSON files\n",
    "\n",
    "## üõ†Ô∏è How to Clean Up\n",
    "\n",
    "- **‚úã S3**: Go to S3 console and delete folders with \"frames_\" prefix\n",
    "- **üìì SageMaker**: Stop and delete your SageMaker notebook instance when finished\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section-id",
   "metadata": {},
   "source": [
    "# üéØ Conclusion: The Future of Agentic Video Processing\n",
    "\n",
    "This notebook demonstrated a complete multi-agent video processing solution using Llama 4 on Amazon Bedrock. The system successfully:\n",
    "\n",
    "- üé¨ **Extracts key frames** from videos using computer vision\n",
    "- üß† **Analyzes visual content** with advanced AI models\n",
    "- ‚è∞ **Understands temporal relationships** between scenes\n",
    "- üìù **Generates comprehensive summaries** of video content\n",
    "\n",
    "## üöÄ What We've Built\n",
    "\n",
    "The multi-agent architecture ensures each processing step is optimized and can be scaled independently. This solution represents the convergence of Llama 4's sophisticated reasoning, AWS cloud infrastructure, and Strands SDK orchestration.\n",
    "\n",
    "## üîÆ Future Enhancements\n",
    "\n",
    "- üéµ **Audio Analysis**: Add speech-to-text and audio understanding\n",
    "- üì∫ **Real-time Processing**: Stream live video analysisa\n",
    "- ü§ñ **Automated Actions**: Trigger workflows based on video content\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
