{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c73fd5-4e9d-4e42-ae60-8dc50c9dc73c",
   "metadata": {},
   "source": [
    "# Evaluate LLMs performance by metrics using Amazon Bedrock Automatic Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6f511-21f5-4c5c-ac9c-d6d0afc374d2",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Automatic model evaluation jobs allow you to quickly evaluate a model's ability to perform a task. You can either provide your own custom prompt dataset that you've tailored to a specific use case, or you can use an available built-in dataset.\n",
    "\n",
    "For supported regions and models please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/evaluation-support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8459e-881b-4d1e-9818-d6e7639e4a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install --upgrade --quiet awscli boto3 seaborn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8fee1-9f8f-4b52-97bc-d44aae8ad9db",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "Please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-type-automatic.html for complete list of pre-requsites to run automatic model evaluation jobs which will be done in the following cells. \n",
    "\n",
    "**But make sure that following pre-requistes are met before running this notebook.**\n",
    "\n",
    "*1. S3 bucket in the same region as Amazon Bedrock models.*\n",
    "\n",
    "*2. IAM role running this notebook has privilege to create/update IAM roles and S3 bucket.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb442d79-b17f-4a3f-9ea6-b1d34f502e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fc01e-e788-471c-a58b-3bbe5e1e1937",
   "metadata": {},
   "source": [
    "### Select models for evaluation\n",
    "Select model1 and model2 for comparison. Please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/evaluation-support.html to choose from the supported models and you can get the modelID using AWS CLI or Boto3 as follows.\n",
    "\n",
    "**AWS CLI:**\n",
    "```\n",
    "aws bedrock list-foundation-models\n",
    "```\n",
    "\n",
    "**Boto3:**\n",
    "```\n",
    "import boto3\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "bedrock_client.list_foundation_models()\n",
    "```\n",
    "\n",
    "Once you have the model ID from the supported list, please update the options list in the next two cells **only if needed.**\n",
    "\n",
    "Otherwise, you can choose between the given options as below without updating modelID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757e116-e6ad-4eda-97ab-5c747c82773f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1 = widgets.Dropdown(\n",
    "    options=[\n",
    "        'meta.llama3-1-8b-instruct-v1:0',\n",
    "        'meta.llama3-1-70b-instruct-v1:0',\n",
    "        'meta.llama3-1-405b-instruct-v1:0',\n",
    "    ],\n",
    "    value='meta.llama3-1-8b-instruct-v1:0',\n",
    "    description='Select model1:',\n",
    "    disabled=False,\n",
    ")\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7554a-2747-410c-ac5b-e4dcc22d4fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2 = widgets.Dropdown(\n",
    "    options=[\n",
    "        'meta.llama3-2-3b-instruct-v1:0',\n",
    "        'meta.llama3-1-70b-instruct-v1:0',\n",
    "        'meta.llama3-2-1b-instruct-v1:0',\n",
    "    ],\n",
    "    value='meta.llama3-2-3b-instruct-v1:0',\n",
    "    description='Select model2:',\n",
    "    disabled=False,\n",
    ")\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cb5b2-0066-4a87-a7df-38dd0dbcfa06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('You selected models {} and {} for evaluation'.format(model_1.value, model_2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f0295-5fde-4441-b4b2-ae393dc02d0e",
   "metadata": {},
   "source": [
    "### Choose a S3 Bucket for Model Evaluation jobs\n",
    "\n",
    "As part of the pre-requisites, we need a S3 bucket in the same region for input datasets and output of model evaluation jobs.\n",
    "\n",
    "In this example, we used Sagemaker's default session bucket. But if you are running this notebook not in Sagemaker, please follow the comments with the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d253e-c2d8-4c81-afbd-ad4d4ad25bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker #comment if Sagemaker is not used\n",
    "import boto3\n",
    "sess = sagemaker.Session() #comment if Sagemaker is not used\n",
    "\n",
    "#If you want to use a custom s3 bucket or running this notebook without Sagemaker, please mention the bucket name as follows\n",
    "#bucket = \"\"\n",
    "bucket=None\n",
    "\n",
    "if bucket is None and sess is not None: \n",
    "    # set to default bucket if a bucket name is not given\n",
    "    bucket = sess.default_bucket()\n",
    " \n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=bucket) #comment if Sagemaker is not used\n",
    " \n",
    "\n",
    "print(f\"Model Evaluation bucket: {bucket}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cf05d-a2d2-4a66-b439-112c38b14e75",
   "metadata": {},
   "source": [
    "### Enable Cross Origin Resource Sharing (CORS) on S3 bucket\n",
    "\n",
    "Automatic model evaluations jobs that are created using the Amazon Bedrock console require that you specify a CORS configuration on the S3 bucket.\n",
    "\n",
    "Please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security-cors.html for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c8718-44e1-4563-85dd-e122d79a91fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cors\n",
    "# Define the configuration rules\n",
    "cors_configuration = {\n",
    "    'CORSRules': [\n",
    "    {\n",
    "        \"AllowedHeaders\": [\n",
    "            \"*\"\n",
    "        ],\n",
    "        \"AllowedMethods\": [\n",
    "            \"GET\",\n",
    "            \"PUT\",\n",
    "            \"POST\",\n",
    "            \"DELETE\"\n",
    "        ],\n",
    "        \"AllowedOrigins\": [\n",
    "            \"*\"\n",
    "        ],\n",
    "        \"ExposeHeaders\": [\n",
    "            \"Access-Control-Allow-Origin\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "}\n",
    "\n",
    "# Set the CORS configuration\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_bucket_cors(Bucket=bucket,\n",
    "                   CORSConfiguration=cors_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4845fe74-b49a-408a-ab46-35bc16bef555",
   "metadata": {},
   "source": [
    "### IAM service role\n",
    "\n",
    "To run an automatic model evaluation job you must create a service role. The service role allows Amazon Bedrock to perform actions on your behalf in your AWS account. Please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/automatic-service-roles.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e24f18-7c02-4b30-b7c2-7d8ac92498a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create IAM role\n",
    "iam = boto3.client('iam')\n",
    "aws_acct = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "assume_role_policy_document = json.dumps({\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowBedrockToAssumeRole\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": aws_acct\n",
    "                },\n",
    "                \"ArnEquals\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:bedrock:{}:{}:evaluation-job/*\".format(region, aws_acct)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da5d0d-d629-46ce-883e-8ec00571ee0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "role_name=\"Amazon-Bedrock-model-eval-{}\".format(str(datetime.datetime.now().timestamp()).split('.')[0])\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument = assume_role_policy_document\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30c1a8-3797-424d-a00d-8c3326226154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "\n",
    "role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2619f82-8ee0-4869-9851-1a960bf801e3",
   "metadata": {},
   "source": [
    "### Add Permissions to Amazon Bedrock and access S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4bd66-eae4-4b71-8709-d53244001b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_s3_policy_doc = json.dumps({\n",
    "\"Version\": \"2012-10-17\",\n",
    "\"Statement\": [\n",
    "    {\n",
    "        \"Sid\": \"AllowAccessToCustomDatasetsAndOutput\",\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Action\": [\n",
    "            \"s3:GetObject\",\n",
    "            \"s3:ListBucket\",\n",
    "            \"s3:PutObject\"\n",
    "        ],\n",
    "        \"Resource\": [\n",
    "            \"arn:aws:s3:::{}\".format(bucket),\n",
    "            \"arn:aws:s3:::{}/outputs/\".format(bucket),\n",
    "            \"arn:aws:s3:::{}/custom_datasets/\".format(bucket),\n",
    "            \"arn:aws:s3:::{}/*\".format(bucket),\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "}\n",
    ")\n",
    "\n",
    "aws_br_policy_doc = json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowAccessToBedrockResources\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:InvokeModel\",\n",
    "                \"bedrock:InvokeModelWithResponseStream\",\n",
    "                \"bedrock:CreateModelInvocationJob\",\n",
    "                \"bedrock:StopModelInvocationJob\",\n",
    "                \"bedrock:GetProvisionedModelThroughput\",\n",
    "                \"bedrock:GetInferenceProfile\", \n",
    "                \"bedrock:ListInferenceProfiles\",\n",
    "                \"bedrock:GetImportedModel\",\n",
    "                \"bedrock:GetPromptRouter\",\n",
    "                \"sagemaker:InvokeEndpoint\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:bedrock:*::foundation-model/*\",\n",
    "                \"arn:aws:bedrock:*:{}:inference-profile/*\".format(aws_acct),\n",
    "                \"arn:aws:bedrock:*:{}:provisioned-model/*\".format(aws_acct),\n",
    "                \"arn:aws:bedrock:*:{}:imported-model/*\".format(aws_acct),\n",
    "                \"arn:aws:bedrock:*:{}:application-inference-profile/*\".format(aws_acct),\n",
    "                \"arn:aws:bedrock:*:{}:default-prompt-router/*\".format(aws_acct),\n",
    "                \"arn:aws:sagemaker:*:{}:endpoint/*\".format(aws_acct),\n",
    "                \"arn:aws:bedrock:*:{}:marketplace/model-endpoint/all-access\".format(aws_acct)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44619227-8ac0-4d81-ae47-08ce061223b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_s3_response = iam.put_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyName=\"s3_access\",\n",
    "    PolicyDocument=aws_s3_policy_doc\n",
    ")\n",
    "iam_s3_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55969bd-b158-4eb5-9aef-4b516d11a819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_bedrock_response = iam.put_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyName=\"br_access\",\n",
    "    PolicyDocument=aws_br_policy_doc\n",
    ")\n",
    "iam_bedrock_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f4783-8e87-4bc3-bb8c-90282c9fa977",
   "metadata": {},
   "source": [
    "#### Get ARNs for the selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59fd19-8bf4-48f5-ac25-4756088c875e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "region = boto3.session.Session().region_name\n",
    "region_prefix = region.split('-')[0]\n",
    "model_arns = []\n",
    "\n",
    "for model in model_1.value, model_2.value:\n",
    "    fm_response = bedrock_client.get_foundation_model(\n",
    "        modelIdentifier=model\n",
    "    )\n",
    "    if fm_response['modelDetails']['inferenceTypesSupported'][0] == \"ON_DEMAND\":\n",
    "        model_arn = fm_response['modelDetails']['modelArn']\n",
    "    elif fm_response['modelDetails']['inferenceTypesSupported'][0] == \"INFERENCE_PROFILE\":\n",
    "        model = \"{}.{}\".format(region_prefix, model)\n",
    "        model_arn = bedrock_client.get_inference_profile(\n",
    "            inferenceProfileIdentifier=model\n",
    "        )['inferenceProfileArn']\n",
    "    print(model_arn)\n",
    "    model_arns.append(model_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f65358-9c52-4dff-b34f-98e3b230ea06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for custom model\n",
    "model_arns[1] = \"arn:aws:bedrock:us-west-2:072851894905:imported-model/1vb1vige5vll\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945b2ff-2252-422e-afe8-1e2394d81505",
   "metadata": {},
   "source": [
    "#### Function to submit automatic model evaluation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79126936-46c7-4cee-8da5-d708ebf7d2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_eval(model_arn, dataset, task_type, output_path, job_name, metric_names, custom_ds=False, custom_ds_s3=None):\n",
    "    if custom_ds:\n",
    "        ds = {\n",
    "                'name': dataset,\n",
    "                'datasetLocation': {\n",
    "                    's3Uri': custom_ds_s3\n",
    "                        }\n",
    "            }\n",
    "    else:\n",
    "        ds = {\n",
    "                'name': dataset\n",
    "            }\n",
    "    job_request = bedrock_client.create_evaluation_job(\n",
    "        jobName=job_name,\n",
    "        jobDescription=\"Bedrock Model evaluation job\",\n",
    "        roleArn=role_arn,\n",
    "        inferenceConfig={\n",
    "            \"models\": [\n",
    "                {\n",
    "                    \"bedrockModel\": {\n",
    "                        \"modelIdentifier\":model_arn,\n",
    "                        \"inferenceParams\":\"{\\\"inferenceConfig\\\":{\\\"maxTokens\\\": 1024,\\\"temperature\\\":0.3,\\\"topP\\\":0.5}}\"\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        },\n",
    "        outputDataConfig={\n",
    "            \"s3Uri\": output_path\n",
    "        },\n",
    "        evaluationConfig={\n",
    "            \"automated\": {\n",
    "                \"datasetMetricConfigs\": [\n",
    "                    {\n",
    "                        \"taskType\": task_type,\n",
    "                        \"dataset\": ds,\n",
    "                        \"metricNames\": metric_names\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return job_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf97e5-7a1a-42cd-a3f5-82605a03cd80",
   "metadata": {},
   "source": [
    "## <ins> Automatic Model evaluation using Builtin Dataset </ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d0456-c77f-4509-ae80-aadf65ec6216",
   "metadata": {},
   "source": [
    "### Define taskType, Dataset and metrics for evaluation\n",
    "\n",
    "**Task Type:**\n",
    "Model evaluation supports the following task types that assess different aspects of the model's performance:\n",
    "\n",
    "* General text generation – the model performs natural language processing and text generation tasks.\n",
    "* Text summarization – the model performs summarizes text based on the prompts you provide.\n",
    "* Question and answer – the model provides answers based on your prompts.\n",
    "* Text classification – the model categorizes text into predefined classes based on the input dataset.\n",
    "\n",
    "**Metrics:**\n",
    "You can choose from the following the metrics that you want the model evaluation job to create.\n",
    "\n",
    "* Toxicity – The presence of harmful, abusive, or undesirable content generated by the model.\n",
    "* Accuracy – The model's ability to generate outputs that are factually correct, coherent, and aligned with the intended task or query.\n",
    "* Robustness – The model's ability to maintain consistent and reliable performance in the face of various types of challenges or perturbations.\n",
    "\n",
    "**Datasets:**\n",
    "Amazon Bedrock provides multiple built-in prompt datasets that you can use in an automatic model evaluation job. Each built-in dataset is based off an open-source dataset. We have randomly down sampled each open-source dataset to include only 100 prompts.\n",
    "\n",
    "For complete list of supported datasets, Task Types and metrics, please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80acac96-ee68-4ff6-86d2-1f215a8c21af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "### Use any one of the following examples combinations of task_type, dataset and metrics or from supported built-in task_types, metrics and datasets from \n",
    "### https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets.html#model-evaluation-prompt-datasets-builtin\n",
    "\n",
    "#### Example-1 #####\n",
    "task_type = \"QuestionAndAnswer\"\n",
    "dataset = \"Builtin.NaturalQuestions\"\n",
    "metric_names = [\"Builtin.Accuracy\", \"Builtin.Robustness\", \"Builtin.Toxicity\"]\n",
    "\n",
    "#### Example-1 #####\n",
    "#task_type = \"Classification\"\n",
    "#dataset = \"Builtin.WomensEcommerceClothingReviews\"\n",
    "#metric_names = [\"Builtin.Accuracy\", \"Builtin.Robustness\"] \n",
    "\n",
    "output_path = \"s3://{}/outputs/\".format(bucket)\n",
    "\n",
    "eval_jobs = []\n",
    "for model_arn in model_arns:\n",
    "    job_name = \"model-eval-{}-{}\".format(model_arn.split('/')[-1].split(':')[0], str(datetime.datetime.now().timestamp()).split('.')[0])\n",
    "    job_name = job_name.replace(\".\", \"-\")\n",
    "    job = model_eval(model_arn, dataset, task_type, output_path, job_name, metric_names)\n",
    "    eval_jobs.append(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144ddd6-c615-45e9-9b72-5526a4051cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to check the job status in a loop until \"COMPLETED\" or \"FAILED\" post submission.\n",
    "def check_job_status(eval_jobs):\n",
    "    # Loop through and wait for the evaluation jobs to complete . \n",
    "    from IPython.display import clear_output\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    \n",
    "    max_time = time.time() + 2*60*60 # 2 hours - Update the max time if needed\n",
    "    while time.time() < max_time:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        get_eval_job1 = bedrock_client.get_evaluation_job(\n",
    "            jobIdentifier=eval_jobs[0]['jobArn']\n",
    "        )\n",
    "\n",
    "        job1_status = get_eval_job1[\"status\"]\n",
    "        get_eval_job2 = bedrock_client.get_evaluation_job(\n",
    "            jobIdentifier=eval_jobs[1]['jobArn']\n",
    "        )\n",
    "\n",
    "        job2_status = get_eval_job2[\"status\"]\n",
    "        clear_output(wait=True)\n",
    "        print(f\"{current_time} : Model evluation job1 is {job1_status} and job2 is {job2_status}.\")\n",
    "\n",
    "        if (job1_status == \"Completed\" or job1_status == \"Failed\") and (job2_status == \"Completed\" or job2_status == \"Failed\"):\n",
    "            break\n",
    "\n",
    "        time.sleep(60)\n",
    "    return get_eval_job1, get_eval_job2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96359be5-cef6-4d16-a629-80c5e4615fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check jobs status and go to loop until finish\n",
    "get_eval_job1, get_eval_job2 = check_job_status(eval_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6c797-a2f4-4e06-8acb-4749da122934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get the S3 output location of model evaluation job.\n",
    "s3_client = boto3.client('s3')\n",
    "def get_output_jsonl(bucket, eval_job_response, model, task_type, dataset):\n",
    "    prefix = \"{}{}/{}/models/{}/taskTypes/{}/datasets/{}\".format(\"/\".join(eval_job_response[\"outputDataConfig\"][\"s3Uri\"].split('/')[3:]), eval_job_response[\"jobName\"], eval_job_response[\"jobArn\"].split(\"/\")[1], model, task_type, dataset)\n",
    "    response = s3_client.list_objects(\n",
    "        Bucket=bucket,\n",
    "        Prefix=prefix,\n",
    "    )\n",
    "    return response['Contents'][0]['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c09a77-5842-4253-a8ca-4a191c5ec1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_val1 = get_eval_job1['inferenceConfig']['models'][0]['bedrockModel']['modelIdentifier'].split('/')[-1]\n",
    "model_val2 = get_eval_job2['inferenceConfig']['models'][0]['bedrockModel']['modelIdentifier'].split('/')[-1]\n",
    "job1_output = get_output_jsonl(bucket, get_eval_job1, model_val1, task_type, dataset)\n",
    "job2_output = get_output_jsonl(bucket, get_eval_job2, model_val2, task_type, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247286a-8650-4850-9ddc-e99b4aeaec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve metrics from the output\n",
    "import json\n",
    "s3_res = boto3.resource('s3')\n",
    "\n",
    "def retrieve_metrics(bucket, output_jsonl):\n",
    "    content_object = s3_res.Object(bucket, output_jsonl)\n",
    "    jsonl_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "    output_content = [json.loads(jline) for jline in jsonl_content.splitlines()]\n",
    "    return output_content\n",
    "\n",
    "job1_metrics =  retrieve_metrics(bucket, job1_output)\n",
    "job2_metrics =  retrieve_metrics(bucket, job2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2e685-bf53-403d-9af9-19f2129086cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to filter and load the metrics in pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def pd_metrics(model1, model2, metric, job1_metrics, job2_metrics):\n",
    "    met1 = []\n",
    "    met2 = []\n",
    "    met_index = [job1_metrics[0]['automatedEvaluationResult']['scores'].index(i) for i in job1_metrics[0]['automatedEvaluationResult']['scores'] if i[\"metricName\"]==metric]\n",
    "    for i, (x, y) in enumerate(zip(job1_metrics, job2_metrics)):\n",
    "        met1.append(x['automatedEvaluationResult']['scores'][met_index[0]]['result'])\n",
    "        met2.append(y['automatedEvaluationResult']['scores'][met_index[0]]['result'])\n",
    "    met = pd.DataFrame({model1.split(':')[0]: met1, model2.split(':')[0]: met2})\n",
    "    return met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fadcf6-e126-4fc3-8c5f-7c9be0dd7a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [m.split('.')[1] for m in metric_names]\n",
    "stats_list = []\n",
    "for metric in metrics:\n",
    "    met_pd = pd_metrics(model_1.value, model_2.value, metric, job1_metrics, job2_metrics)\n",
    "    stats_list.append(met_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f02877-af69-425c-ba6d-8324adec316b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to line plot for model comparison per metric\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_line_metrics(metrics, stats_list):\n",
    "    for metric, df in zip(metrics, stats_list):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.lineplot(data=df, markers=True, palette=\"flare\")\n",
    "        plt.legend(title='Model')\n",
    "        plt.xlabel('Inference test')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(metric)\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c234c2-1427-4560-b325-e80266a5360a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_line_metrics(metrics, stats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac336b-93f2-4fec-b784-e1c1f565f669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot bar chart for avg accuracy per model\n",
    "def plt_acc_bar(df, metric):\n",
    "    # Calculate the average of each column\n",
    "    column_averages = df.mean()\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure()\n",
    "    sns.barplot(x=column_averages.index, y=column_averages.values)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(\"Average metric - {}\".format(metric))\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Average Value')\n",
    "\n",
    "    # Rotate x-axis labels if there are many columns\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Add value labels on top of each bar\n",
    "    for i, v in enumerate(column_averages.values):\n",
    "        plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d73b2-7090-441b-953c-267299215755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Average Accuracy\n",
    "plt_acc_bar(stats_list[0], metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fb861-35f2-438d-bb2c-0ef706401ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to bin the accuracy data in different accuracy(in percentage) bins [0, 20, 40, 60, 80, 100] and compare between models\n",
    "\n",
    "\n",
    "def bin_data(series, bins_list):\n",
    "    bins = pd.cut(series, bins=bins_list)\n",
    "    return bins, bins.value_counts().index\n",
    "\n",
    "def plot_bin_accuracy(df, bins_list):\n",
    "    # Apply binning to both columns\n",
    "    df_binned = df.apply(lambda x: bin_data(x, bins_list)[0])\n",
    "    bin_edges = bin_data(df.values.flatten(), bins_list)[1]\n",
    "\n",
    "    # Melt the DataFrame to long format\n",
    "    df_melted = df_binned.melt(var_name='model', value_name='bin')\n",
    "\n",
    "    # Count the occurrences of each bin for each model\n",
    "    df_counted = df_melted.groupby(['model', 'bin']).size().reset_index(name='count')\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='bin', y='count', hue='model', data=df_counted)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Comparison of Accuracy Range Across Two Models')\n",
    "    plt.xlabel('Accuracy Range')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Model')\n",
    "\n",
    "    # Set x-axis labels to actual bin ranges\n",
    "    plt.xticks(range(len(bin_edges)), [f'({interval.left:.2f}, {interval.right:.2f}]' for interval in bin_edges], rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd12bce-612a-42a9-9cdc-609af02f929f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_bin_accuracy(stats_list[0], bins_list=[0, 0.2, 0.4, 0.6, 0.8, 1.0]) #update the bin values as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62763e41-ca05-4197-a8ec-0f40583e382a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <ins> Automatic Model Evaluation using  Custom Dataset </ins>\n",
    "\n",
    "Now lets start evaluating the same models with a custom dataset. \n",
    "\n",
    "*For this demo purpose only, we use Databricks Dolly-15k Dataset from HuggingFace.*\n",
    "\n",
    "**Note: Customers may use their own validation(groundtruth) dataset in the given format below based on their workload.**\n",
    "\n",
    "\n",
    "You can create a custom prompt dataset in an automatic model evaluation jobs. Custom prompt datasets must be stored in Amazon S3, and use the JSON line format and use the .jsonl file extension. Each line must be a valid JSON object. There can be up to 1000 prompts in your dataset per automatic evaluation job.\n",
    "\n",
    "**Custom dataset must use the following keys value pairs format.**\n",
    "\n",
    "`prompt` – required to indicate the input for the following tasks:\n",
    "* The prompt that your model should respond to, in general text generation.\n",
    "* The question that your model should answer in the question and answer task type.\n",
    "* The text that your model should summarize in text summarization task.\n",
    "* The text that your model should classify in classification tasks.\n",
    "\n",
    "`referenceResponse` – required to indicate the ground truth response against which your model is evaluated for the following tasks types:\n",
    "* The answer for all prompts in question and answer tasks.\n",
    "* The answer for all accuracy, and robustness evaluations.\n",
    "\n",
    "`category` – (optional) generates evaluation scores reported for each category.\n",
    "\n",
    "As an example, accuracy requires both the question asked, and a answer to check the model's response against. In this example, use the key `prompt` with the value contains the question, the key `referenceResponse` with the value contains the answer and the key `category` contains the category of the question as follows.\n",
    "\n",
    "```\n",
    "{\"prompt\": \"Are The Smiths a good band?\", \n",
    "\"referenceResponse\": \"The Smiths were one of the most critically acclaimed bands to come from England in the 1980s. Typically classified as an \\\"indie rock\\\" band, the band released 4 albums from 1984 until their breakup in 1987. The band members, notably Morrissey and Johnny Marr, would go on to accomplish successful solo careers.\",\n",
    "\"category\": \"general_qa\"}\n",
    "```\n",
    "\n",
    "Please refer to https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets.html#model-evaluation-prompt-datasets-custom for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64c53d-8c9d-4d04-980a-a302749e7537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!wget https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12f489-793c-4858-ae98-e5c9e5b0d652",
   "metadata": {},
   "source": [
    "### In this example, we will sample 100 records of \"open_qa\" category from dolly-15k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ad499-7204-46ec-9fb5-31744d180eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter and select 100 records from dolly dataset\n",
    "import json\n",
    "\n",
    "def filter_jsonl(data, key, value):\n",
    "    filtered_data = []\n",
    "    for item in data:\n",
    "        if item.get(key) == value:\n",
    "            filtered_data.append(item)\n",
    "    return filtered_data\n",
    "\n",
    "with open('databricks-dolly-15k.jsonl', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "filtered_data = filter_jsonl(data, \"category\", \"open_qa\")[:100]\n",
    "print(len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b637d7-973b-453c-87cd-6cde34ac6df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to modify the format as needed for custom dataset\n",
    "\n",
    "custom_jsonl = './custom_dataset.jsonl'\n",
    "\n",
    "def write_jsonl(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            item_mod = {}\n",
    "            item_mod['prompt'] = item['instruction']\n",
    "            item_mod['referenceResponse'] = item['response']\n",
    "            item_mod['category'] = item['category']\n",
    "            f.write(json.dumps(item_mod) + '\\n')\n",
    "\n",
    "# Write to JSONL file\n",
    "write_jsonl(filtered_data, custom_jsonl)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad13d6-2672-4d42-a6b6-6756091f544d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Copy dataset jsonl to S3 Bucket\n",
    "import boto3\n",
    "\n",
    "s3_res = boto3.resource('s3')\n",
    "s3_res.Bucket(bucket).upload_file(custom_jsonl, 'custom_datasets/dolly/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752ad95-9c13-43cc-b99a-dd6d7c8818ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose task_type, metrics and s3 input/output path\n",
    "task_type = \"QuestionAndAnswer\"\n",
    "metric_names = [\"Builtin.Accuracy\", \"Builtin.Robustness\", \"Builtin.Toxicity\"] #Add or remove metrics within the list format\n",
    "output_path = \"s3://{}/outputs/\".format(bucket)\n",
    "cus_ds_s3 = \"s3://{}/custom_datasets/dolly/\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc25d7-2195-4963-9313-fed6aa8743a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submit automatic model evaluation jobs with custom dataset\n",
    "import datetime\n",
    "cust_eval_jobs = []\n",
    "for model_arn in model_arns:\n",
    "    job_name = \"model-eval-custom-{}-{}\".format(model_arn.split('/')[-1].split(':')[0], str(datetime.datetime.now().timestamp()).split('.')[0])\n",
    "    job_name = job_name.replace(\".\", \"-\")\n",
    "    job = model_eval(model_arn, \"custom\", task_type, output_path, job_name, metric_names, custom_ds=True, custom_ds_s3=cus_ds_s3)\n",
    "    cust_eval_jobs.append(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177886eb-1f18-4872-b8b9-b148e02aa317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Track evluation job status in a loop until \"COMPLETED\" or \"FAILED\"\n",
    "get_cust_eval_job1, get_cust_eval_job2 = check_job_status(cust_eval_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6524d-9d9b-4370-94f3-5e19e7df17d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get evaluation jobs output\n",
    "model_val1 = get_cust_eval_job1['inferenceConfig']['models'][0]['bedrockModel']['modelIdentifier'].split('/')[-1]\n",
    "model_val2 = get_cust_eval_job2['inferenceConfig']['models'][0]['bedrockModel']['modelIdentifier'].split('/')[-1]\n",
    "cust_job1_output = get_output_jsonl(bucket, get_cust_eval_job1, model_val1, task_type, dataset=\"custom\")\n",
    "cust_job2_output = get_output_jsonl(bucket, get_cust_eval_job2, model_val2, task_type, dataset=\"custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aaf83-d050-422f-bb36-c65e602d8693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve metrics\n",
    "cust_job1_metrics =  retrieve_metrics(bucket, cust_job1_output)\n",
    "cust_job2_metrics =  retrieve_metrics(bucket, cust_job2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b4712-9ab7-40b9-8353-d32c5131fec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [ m.split('.')[1] for m in metric_names]\n",
    "cust_stats_list = []\n",
    "for metric in metrics:\n",
    "    met_pd = pd_metrics(model_1.value, model_2.value, metric, cust_job1_metrics, cust_job2_metrics)\n",
    "    cust_stats_list.append(met_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b89ca-c7d2-4532-aced-370f52fac732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Draw line plot for model comparison per metric\n",
    "plot_line_metrics(metrics, cust_stats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fba552-a916-498b-b299-7b31e6a7a0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Average Accuracy per model\n",
    "plt_acc_bar(cust_stats_list[0], metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271cda0-b881-42fb-a02f-0ed268d41103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot across different ranges of accuracy and compare\n",
    "plot_bin_accuracy(cust_stats_list[0], bins_list=[0, 0.2, 0.4, 0.6, 0.8, 1.0]) #update the bin values as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a6795-4051-432d-a371-39b54a3efad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 4.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-311-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
