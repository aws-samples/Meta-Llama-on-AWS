{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4901509a-8316-47a3-879b-544a43b37ef3",
   "metadata": {},
   "source": [
    "# Best-practices for prompt engineering Text-to-SQL on Llama3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa596a49-ce47-4053-a93d-699bdef52426",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b488b5-d05b-45d2-84fb-6bc80cc30241",
   "metadata": {},
   "source": [
    "This notebook introduces a versatile approach that leverages Llama 3 models on Amazon Bedrock, including advanced prompt engineering, to convert natural language questions into executable SQL queries. Our approach generates SQL queries capable of joining data from multiple tables, enabling information retrieval from complex database structures. This multi-table capability is crucial in real-world scenarios where data is often distributed across various tables with intricate relationships, and queries need to combine information from multiple sources to provide comprehensive insights.\n",
    "\n",
    "Moreover, our approach demonstrates high scalability through dynamically selecting and retrieving the most relevant table schemas based on the given natural language question. This scalability is achieved by employing intelligent schema matching algorithms powered by ChromaDB. ChromaDB analyzes the question and automatically identifies the appropriate tables and relationships required to construct the SQL query, eliminating the need for manual intervention.\n",
    "\n",
    "Our solution can be applied in practical scenarios where companies manage numerous databases with intricate table relationships, such as in the finance industry for analyzing customer transactions across multiple accounts and products, or in healthcare for integrating patient records from various systems and data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126d29c-4748-4831-8aff-60d71c61462e",
   "metadata": {},
   "source": [
    "---\n",
    "## Llama 3 Model Selection\n",
    "\n",
    "Today, there are two Llama 3 models available on Amazon Bedrock:\n",
    "\n",
    "### 1. Llama 3 8B\n",
    "\n",
    "- **Description:** Ideal for limited computational power and resources, faster training times, and edge devices.\n",
    "- **Max Tokens:** 2,048\n",
    "- **Context Window:** 8,196\n",
    "- **Languages:** English\n",
    "- **Supported Use Cases:** Synthetic Text Generation, Text Classification, and Sentiment Analysis.\n",
    "\n",
    "### 2. Llama 3 70B\n",
    "\n",
    "- **Description:** Ideal for content creation, conversational AI, language understanding, research development, and enterprise applications. \n",
    "- **Max Tokens:** 2,048\n",
    "- **Context Window:** 8,196\n",
    "- **Languages:** English\n",
    "- **Supported Use Cases:** Synthetic Text Generation and Accuracy, Text Classification and Nuance, Sentiment Analysis and Nuance Reasoning, Language Modeling, Dialogue Systems, and Code Generation.\n",
    "\n",
    "### Performance and Cost Trade-offs\n",
    "\n",
    "The table below compares the model performance on the Massive Multitask Language Understanding (MMLU) benchmark and their on-demand pricing on Amazon Bedrock.\n",
    "\n",
    "| Model           | MMLU Score | Price per 1,000 Input Tokens | Price per 1,000 Output Tokens |\n",
    "|-----------------|------------|------------------------------|-------------------------------|\n",
    "| Llama 3 8B | 68.4%      | \\$0.0004                   | \\$0.0006                    |\n",
    "| Llama 3 70B | 82.0%      | \\$0.00265                   | \\$0.0035                     |\n",
    "\n",
    "For more information, refer to the following links:\n",
    "\n",
    "1. [Llama 3 8B Model Cards and Prompt Formats](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3)\n",
    "2. [Amazon Bedrock Pricing Page](https://aws.amazon.com/bedrock/pricing/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd85684",
   "metadata": {},
   "source": [
    "## The Approach to the Text-to-SQL Problem\n",
    "This notebook covers the following approaches\n",
    "\n",
    "### Few-shot text-to-SQL (Single Table vs Multiple Tables)\n",
    "Few-shot text-to-SQL is an approach for querying databases by translating natural language questions into SQL queries, using only a few training examples.\n",
    "\n",
    "Providing just a few examples of natural language questions paired with the equivalent SQL queries allows models to learn the mapping from natural language to SQL.\n",
    "\n",
    "Reference : https://arxiv.org/abs/2305.12586\n",
    "\n",
    "### Few-shot text-to-SQL powered by ChromaDB (Schema Retrieval vs Enhance Schema Retrieval with Sample Questions)\n",
    "\n",
    "This approach leverages ChromaDB, a vector database, to assist the few-shot text-to-SQL translation process. ChromaDB can be used in two ways:\n",
    "\n",
    "1. **Schema Retrieval**: In this method, ChromaDB stores the database schema information, which includes table names, column names, and their descriptions. When a natural language question is provided, the model can retrieve relevant schema information from ChromaDB to aid in generating the SQL query.\n",
    "\n",
    "2. **Enhanced Schema Retrieval with Sample Questions**: Building upon the previous method, this approach also stores sample natural language questions and their corresponding SQL queries in ChromaDB. When a new question is given, the model can retrieve not only the relevant schema information but also similar sample questions and their SQL queries from ChromaDB. This additional context can further improve the model's ability to accurately translate the natural language question into an SQL query.\n",
    "\n",
    "By leveraging ChromaDB, the few-shot text-to-SQL translation process can benefit from efficient schema and sample data retrieval, potentially leading to better performance and generalization across different databases and query types.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058dceec",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "This notebook will provide code snippets to assist with implementing two differents approaches to converting a natural language question into a SQL query that would answer it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b33e6",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Getting Started](#getting-started)\n",
    "    + [Install Dependencies](#step-1-install-dependencies)\n",
    "    + [Setup Bedrock and Database](#step-2-set-up-bedrock-client-and-database-connection)\n",
    "    + [Build Database](#step-3-build-database)\n",
    "    + [Create Helper Functions](#step-4-create-helper-functions)\n",
    "1. [Few-Shot Text-to-SQL](#few-shot-text-to-sql)\n",
    "1. [Analyzing a Single Table with Few-Shot Learning](#analyzing-a-single-table-with-few-shot-learning)\n",
    "    + [Create a Few-Shot Prompt](#step-1-create-a-few-shot-prompt)\n",
    "    + [Execute Few-Shot Prompts](#step-2-execute-few-shot-prompts)\n",
    "1. [Analyzing Multiple Table with Few-Shot Learning](#analyzing-multiple-table-with-few-shot-learning)\n",
    "    + [Create a Few-Shot Prompt](#step-1-create-a-few-shot-prompt)\n",
    "    + [Execute Few-Shot Prompts](#step-2-execute-few-shot-prompts)\n",
    "1. [Limitations of Few-Shot Learning](#limitation-of-few-shot-learning)\n",
    "1. [Few-shot text-to-SQL powered by ChromaDB](#few-shot-text-to-sql-powered-by-chromadb)\n",
    "1. [Schema Retrieval](#schema-retrieval)\n",
    "    + [Data Preprocessing](#step-1-data-processing)\n",
    "    + [Ingest docs into ChromaDB](#step-2-ingest-docs-into-chromadb)\n",
    "    + [Create a Few-Shot Prompt](#step-3-create-a-few-shot-prompt)\n",
    "    + [Execute Few-Shot Prompts](#step-4-execute-few-shot-prompts)\n",
    "    + [Conclusion](#step-5-conclusion)\n",
    "1. [Enhanced Schema Retrieval with Sample Questions](#enhanced-schema-retrieval-with-sample-questions)\n",
    "    + [Data Preprocessing](#step-1-data-processing)\n",
    "    + [Ingest docs into ChromaDB](#step-2-ingest-docs-into-chromadb)\n",
    "    + [Execute Few-Shot Prompts](#step-3-execute-few-shot-prompts)\n",
    "    + [Conclusion](#step-4-conclusion)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a20c2",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "+ AWS Python SDKs [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) to be able to submit API calls to [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "+ [LangChain](https://python.langchain.com/v0.1/docs/get_started/introduction/) is a framework that provides off the shelf components to make it easier to build applications with large language models. It is supported in multiple programming languages, such as Python, JavaScript, Java and Go. In this notebook, LangChai is used to build a prompt template.\n",
    "\n",
    "+ [ChromaDB](https://www.trychroma.com/) is a vector database that enables efficient semantic search, storage, and retrieval of unstructured data like text, images, and audio. It's designed to work well with large language models (LLMs) and provides a simple and scalable way to build applications that can search and retrieve relevant information from vast amounts of data.\n",
    "\n",
    "+ RDS (Relational Database Service) for [MySQL](https://aws.amazon.com/rds/mysql/) is a managed database service provided by Amazon Web Services (AWS). RDS for MySQL simplifies the setup, operation, and scaling of MySQL databases.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a6bb4",
   "metadata": {},
   "source": [
    "## Pre-requisites:\n",
    "\n",
    "1. Use kernel either `conda_python3`, `conda_pytorch_p310` or `conda_tensorflow2_p310`.\n",
    "2. Install the required packages.\n",
    "3. Access to the LLM API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd282c-e45f-463e-9f68-f80176f4f0af",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92d068-da09-4d98-97f6-d14e7b0b8f6f",
   "metadata": {},
   "source": [
    "In this notebook, Llama 3 70B is used. By deploying the notebook through our cloudformation template, it is granted the appropriate IAM permissions to send API request to Bedrock.\n",
    "\n",
    "Refer [here](https://aws.amazon.com/blogs/aws/metas-llama-3-models-are-now-available-in-amazon-bedrock/) for details on how Amazon Bedrock provides access to Metaâ€™s Llama 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae4171-4f20-4a68-b6e1-0a40a3854de5",
   "metadata": {},
   "source": [
    "### SageMaker Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465f181-b661-4f59-bdac-92ed0e164203",
   "metadata": {},
   "source": [
    "#### Changing instance type\n",
    "---\n",
    "Models are supported on the following instance types:\n",
    "\n",
    " - Llama3 8B Text Generation: `ml.g5.2xlarge`, `ml.g5.4xlarge`, `ml.g5.8xlarge`, `ml.g5.12xlarge`, `ml.g5.24xlarge`, `ml.g5.48xlarge`, and `ml.p4d.24xlarge`\n",
    "- Llama3 70B Text Generation: `ml.g5.48xlarge`, and `ml.p4d.24xlarge`\n",
    " - BGE Large En v1.5: `ml.g5.2xlarge`, `ml.c6i.xlarge`,`ml.g5.4xlarge`, `ml.g5.8xlarge`, `ml.p3.2xlarge`, and `ml.g4dn.2xlarge`\n",
    "\n",
    "By default, the JumpStartModel class selects a default instance type available in your region. If you would like to use a different instance type, you can do so by specifying instance type in the JumpStartModel class.\n",
    "\n",
    "`my_model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.12xlarge\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be911213",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b2317-d90d-481f-8d51-464a93650978",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1f1bb-966d-4726-804c-b0d1f9108d8c",
   "metadata": {},
   "source": [
    "### Step 0: Select Hosting Model Service\n",
    "\n",
    "Here, you can select to run this notebook using SageMaker JumpStart or Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9f9044-79b0-4f76-9085-0f8c28568f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to run the LLM for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B)  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the LLM for this notebook using Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "def ask_for_service():\n",
    "    service = input(\"Do you want to run the LLM for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B) \").strip().upper()\n",
    "    if service in ['S', 'SAGEMAKER']:\n",
    "        return 'Amazon SageMaker'\n",
    "    elif service in ['B', 'BEDROCK', '']:\n",
    "        return 'Amazon Bedrock'\n",
    "    else:\n",
    "        print(\"Invalid input. Using Amazon Bedrock by default.\")\n",
    "        return 'Amazon Bedrock'\n",
    "\n",
    "# Call the function and get the selected service\n",
    "llm_selected_service = ask_for_service()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the LLM for this notebook using {llm_selected_service}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516b0617-6f4b-4344-b44d-8abf090b9c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to run the Embedding for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B)  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the Embedding for this notebook using Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "def ask_for_service():\n",
    "    service = input(\"Do you want to run the Embedding for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B) \").strip().upper()\n",
    "    if service in ['S', 'SAGEMAKER']:\n",
    "        return 'Amazon SageMaker'\n",
    "    elif service in ['B', 'BEDROCK', '']:\n",
    "        return 'Amazon Bedrock'\n",
    "    else:\n",
    "        print(\"Invalid input. Using Amazon Bedrock by default.\")\n",
    "        return 'Amazon Bedrock'\n",
    "\n",
    "# Call the function and get the selected service\n",
    "embedding_selected_service = ask_for_service()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the Embedding for this notebook using {embedding_selected_service}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c904c9df-7245-4c3b-98af-96298a61d1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if llm_selected_service == 'Amazon SageMaker':\n",
    "    # Import the JumpStartModel class from the SageMaker JumpStart library\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "    # Specify the model ID for the HuggingFace Llama 3 Instruct LLM model\n",
    "    llama3_8b_id = \"meta-textgeneration-llama-3-70b-instruct\"\n",
    "    llama3_70b_id = \"meta-textgeneration-llama-3-8b-instruct\"\n",
    "    DEFULT_LLM_MODEL_ID = llama3_70b_id\n",
    "    if DEFULT_LLM_MODEL_ID == llama3_70b_id:\n",
    "        instance_type = \"ml.g5.48xlarge\"\n",
    "    else:\n",
    "        instance_type = \"ml.g5.12xlarge\"\n",
    "    model = JumpStartModel(model_id=DEFULT_LLM_MODEL_ID, instance_type=instance_type)\n",
    "    llm_predictor = model.deploy(accept_eula=True)\n",
    "    print(f\"LLM SageMaker Endpoint Name: {llm_predictor.endpoint_name}\")\n",
    "else:\n",
    "    llm_predictor = None\n",
    "    llama3_8b_id = \"meta.llama3-8b-instruct-v1:0\"\n",
    "    llama3_70b_id = \"meta.llama3-70b-instruct-v1:0\"\n",
    "    DEFULT_LLM_MODEL_ID = llama3_70b_id\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "if embedding_selected_service == 'Amazon SageMaker':\n",
    "    # Import the JumpStartModel class from the SageMaker JumpStart library\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "    # Deploy BGE Large En embedding model on Amazon SageMaker JumpStart:\n",
    "    # Specify the model ID for the HuggingFace BGE Large EN Embedding model\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"huggingface-sentencesimilarity-bge-large-en\"\n",
    "    text_embedding_model = JumpStartModel(model_id=DEFAULT_EMBEDDING_MODEL_ID)\n",
    "    embedding_predictor = text_embedding_model.deploy()\n",
    "    print(f\"LLM SageMaker Endpoint Name: {embedding_predictor.endpoint_name}\")\n",
    "else:\n",
    "    embedding_predictor = None\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26350f6e-2ae8-40c0-86f2-626cc595af71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Install Dependencies\n",
    "\n",
    "Here, we will install all the required dependencies to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d52454-073b-4a5a-b293-924419e1c8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3==1.34.127 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install mysql-connector-python==8.4.0 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install langchain==0.2.5 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install chromadb==0.5.0 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install numpy==1.26.4 -qU --force --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a4385-1945-4358-ad33-a6d80c867d95",
   "metadata": {},
   "source": [
    "**Note:** *When installing libraries using the pip, you may encounter errors or warnings during the installation process. These are generally not critical and can be safely ignored. However, after installing the libraries, it is recommended to restart the kernel or computing environment you are working in. Restarting the kernel ensures that the newly installed libraries are loaded properly and available for use in your code or workflow.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f0206-1fe9-46a8-a6ff-c1fb3d045578",
   "metadata": {},
   "source": [
    "#### Now lets import the required modules to run the notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756999dd-ac11-4b3a-8e43-2c4cdc2ad9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import chromadb\n",
    "from chromadb.api.types import (\n",
    "    Documents,\n",
    "    EmbeddingFunction,\n",
    "    Embeddings,\n",
    ")\n",
    "import json\n",
    "from langchain import PromptTemplate\n",
    "import mysql.connector as db\n",
    "import re\n",
    "from typing import Dict, List, Any\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12765f-10a8-4aae-9e62-4ee7f4e526cc",
   "metadata": {},
   "source": [
    "### Step 2: Set up Bedrock and database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2493f9-833f-40ff-a9db-b81f47e37c66",
   "metadata": {},
   "source": [
    "Here, we retrieve the services that are already deployed as a part of the cloudformation template to be used in building the application. The services include,\n",
    "\n",
    "+ Secret ARN with RDS for MySQL Database credentials\n",
    "+ Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d355be7-9365-41d5-8f63-153898c7c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackname = \"text2sql\"  # If your stack name differs from \"text2sql\", please provide your stack name here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca002c7-3416-4ac5-b9a1-2b730557fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "response = cfn.describe_stack_resources(\n",
    "    StackName=stackname\n",
    ")\n",
    "cfn_outputs = cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']\n",
    "\n",
    "# Get rds secret arn and database endpoint from cloudformation outputs\n",
    "for output in cfn_outputs:\n",
    "    if 'SecretArn' in output['OutputKey']:\n",
    "        rds_secret_id = output['OutputValue']\n",
    "\n",
    "    if 'DatabaseEndpoint' in output['OutputKey']:\n",
    "        db_host = output['OutputValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e5601b-287b-421e-8711-ef73d5c09cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secrets_client = boto3.client('secretsmanager')\n",
    "credentials = json.loads(secrets_client.get_secret_value(SecretId=rds_secret_id)['SecretString'])\n",
    "\n",
    "# Get password and username from secrets\n",
    "db_password = credentials['password']\n",
    "db_user = credentials['username']\n",
    "db_name = \"airline_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a2a69-265b-4daa-a5fd-bdb55646fa3b",
   "metadata": {},
   "source": [
    "Setup Bedrock Client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ebc10d-b6ea-4ef9-a67f-1d99098eb052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c970c8c-f566-430f-b12b-e669cc7241eb",
   "metadata": {},
   "source": [
    "Establish the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705ab665-9b2e-4141-b7fb-df3329ac61c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_conn = db.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5934167-da56-48c4-905a-51f515d8f680",
   "metadata": {},
   "source": [
    "#### Use this section to check all the databases already in your test database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49eb5c2b-a0a0-49dc-8c4a-4742576f6756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_cursor = db_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09ede071-2cdc-4f0c-9042-5acb59909459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('airline_db',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sys',)\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(\"SHOW DATABASES\")\n",
    "\n",
    "for tmp_db_name in db_cursor:\n",
    "    print(tmp_db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a8a54-2782-4c4f-8524-6fef2cfa880a",
   "metadata": {},
   "source": [
    "### Step 3: Build Database\n",
    "Now the notebook will drop the test table and also the test database if it exists. It then proceeds with creation of the table.\n",
    "Then it will insert test data for use in our prompting examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cb5ef-41ea-43d9-ace9-8ca9c2dda260",
   "metadata": {},
   "source": [
    "#### Load table schema settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2579b20a-eb9c-4146-88e7-d4936d8d3038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_settings(file_path):\n",
    "    \"\"\"\n",
    "    Reads a YAML file and returns its contents as a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the YAML file.\n",
    "\n",
    "    Returns:\n",
    "        obj: The contents of the YAML file as a Python object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(f\"Error: Failed to parse the YAML file '{file_path}': {exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcf569e-6c76-4eee-8be7-cc0ab13a3802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load table settings\n",
    "settings_airplanes = load_settings('schemas/airplanes.yml')\n",
    "table_airplanes = settings_airplanes['table_name']\n",
    "table_schema_airplanes = settings_airplanes['table_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ccb4cc8-dc2a-4d21-9946-1308cc7720f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load table settings\n",
    "settings_flights = load_settings('schemas/flights.yml')\n",
    "table_flights = settings_flights['table_name']\n",
    "table_schema_flights = settings_flights['table_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f08ee4d0-58c3-4585-a6c3-21c8e1247177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load table settings\n",
    "settings_airplane_flights = load_settings('schemas/airplanes-flights.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d18b1b-a668-4090-93b9-6a286bae3fe7",
   "metadata": {},
   "source": [
    "#### Clean up database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874cf1ed-bc91-4c5b-88d8-e38d3eae3d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete flights' table\n",
    "db_cursor.execute(f\"DROP TABLE IF EXISTS {db_name}.{table_flights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bb95a58-1630-4ae7-ab97-a8b91be00f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete airplanes' table\n",
    "db_cursor.execute(f\"DROP TABLE IF EXISTS {db_name}.{table_airplanes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b928c6-181c-4bcc-84b6-728aaf261052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete database\n",
    "db_cursor.execute(f\"DROP DATABASE IF EXISTS {db_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f396b2e-b25b-4192-82e5-cf5e5e2f128c",
   "metadata": {},
   "source": [
    "#### Create database and tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e78bdc-c26d-4029-907b-8d9768d9e501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create database `airline_db`\n",
    "db_cursor.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "544ac0d2-4158-4041-bc6d-09b458f60364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table to hold data on fictitious airplanes information called `airplanes`\n",
    "db_cursor.execute(table_schema_airplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65069b84-b9ec-468e-a0fb-138e89e55682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table to hold data on fictitious flights information called `flights`\n",
    "db_cursor.execute(table_schema_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01ebc7-2ac0-412b-8984-e79651661f0a",
   "metadata": {},
   "source": [
    "#### Read sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8405e146-790e-46f8-9c1b-6d38319d7ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read sample data for the airplanes' table\n",
    "with open('sample_data/airplanes.json', 'r') as f:\n",
    "    data_airplanes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050ca63b-6081-4b16-812e-4cac4eb46418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read sample data for the flights' table\n",
    "with open('sample_data/flights.json', 'r') as f:\n",
    "    data_flights = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a902c",
   "metadata": {},
   "source": [
    "#### Ingest sample data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b525973-4700-4c2d-8f5f-7c213ccc5a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert airplanes' data into database\n",
    "for data in data_airplanes:\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO {db_name}.{table_airplanes} \n",
    "        (Airplane_id, Producer, Type) \n",
    "        VALUES (\n",
    "        {data['Airplane_id']},\n",
    "        '{data['Producer']}',\n",
    "        '{data['Type']}'\n",
    "        )\n",
    "        \"\"\"\n",
    "    db_cursor.execute(sql)\n",
    "db_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bea4d6e-714e-48af-8141-3911f762a336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert flights' data into database\n",
    "for data in data_flights:\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO {db_name}.{table_flights}\n",
    "        (Flight_number, Arrival_time, Arrival_date, Departure_time, Departure_date, Destination, Airplane_id) \n",
    "        VALUES (\n",
    "        '{data['Flight_number']}',\n",
    "        '{data['Arrival_time']}',\n",
    "        '{data['Arrival_date']}',\n",
    "        '{data['Departure_time']}',\n",
    "        '{data['Departure_date']}',\n",
    "        '{data['Destination']}',\n",
    "        {data['Airplane_id']}\n",
    "        )\n",
    "        \"\"\"\n",
    "    db_cursor.execute(sql)\n",
    "db_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714660a4",
   "metadata": {},
   "source": [
    "Verify our database connection works and we can retrieve records from our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9792a67b-591b-4364-8caa-10ecb3ba70d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Boeing', '737')\n",
      "(2, 'Airbus', 'A320')\n",
      "(3, 'Embraer', 'E195')\n",
      "(4, 'Bombardier', 'CRJ900')\n",
      "(5, 'Boeing', '777')\n",
      "(6, 'Airbus', 'A330')\n",
      "(7, 'Embraer', 'E175')\n",
      "(8, 'Bombardier', 'Q400')\n",
      "(9, 'Boeing', '787')\n",
      "(10, 'Airbus', 'A350')\n",
      "(11, 'Embraer', 'E190')\n",
      "(12, 'Bombardier', 'CRJ700')\n",
      "(13, 'Boeing', '757')\n",
      "(14, 'Airbus', 'A380')\n",
      "(15, 'Embraer', 'E170')\n",
      "(16, 'Bombardier', 'CRJ200')\n",
      "(17, 'Boeing', '747')\n",
      "(18, 'Airbus', 'A321')\n",
      "(19, 'Embraer', 'E145')\n",
      "(20, 'Bombardier', 'CRJ1000')\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(f\"SELECT * FROM {db_name}.{table_airplanes}\")\n",
    "sql_data = db_cursor.fetchall()\n",
    "\n",
    "for record in sql_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b1c3fd3-aac8-41d4-8790-e7a770e309f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AA123', '2023-06-15T10:30:00', '2023-06-15', '2023-06-15T08:00:00', '2023-06-15', 'Los Angeles', 1)\n",
      "('AA234', '2023-07-02T21:15:00', '2023-07-02', '2023-07-02T18:30:00', '2023-07-02', 'Tampa', 20)\n",
      "('AA890', '2023-06-24T18:40:00', '2023-06-24', '2023-06-24T16:10:00', '2023-06-24', 'Atlanta', 5)\n",
      "('AS345', '2023-06-19T21:00:00', '2023-06-19', '2023-06-19T18:30:00', '2023-06-19', 'Seattle', 7)\n",
      "('AS789', '2023-06-27T15:50:00', '2023-06-27', '2023-06-27T13:20:00', '2023-06-27', 'Phoenix', 7)\n",
      "('DL123', '2023-06-25T22:00:00', '2023-06-25', '2023-06-25T19:30:00', '2023-06-25', 'Las Vegas', 10)\n",
      "('DL345', '2023-06-29T07:30:00', '2023-06-29', '2023-06-29T05:00:00', '2023-06-29', 'Philadelphia', 6)\n",
      "('DL567', '2023-07-03T09:40:00', '2023-07-03', '2023-07-03T07:10:00', '2023-07-03', 'San Diego', 19)\n",
      "('DL789', '2023-06-17T18:20:00', '2023-06-17', '2023-06-17T16:00:00', '2023-06-17', 'Miami', 10)\n",
      "('DL901', '2023-06-21T13:20:00', '2023-06-21', '2023-06-21T10:50:00', '2023-06-21', 'Boston', 6)\n",
      "('JB012', '2023-06-28T20:15:00', '2023-06-28', '2023-06-28T17:45:00', '2023-06-28', 'Orlando', 8)\n",
      "('JB678', '2023-06-20T07:45:00', '2023-06-20', '2023-06-20T05:15:00', '2023-06-20', 'San Francisco', 8)\n",
      "('SW234', '2023-06-22T16:35:00', '2023-06-22', '2023-06-22T14:05:00', '2023-06-22', 'Dallas', 3)\n",
      "('SW678', '2023-06-30T12:45:00', '2023-06-30', '2023-06-30T10:15:00', '2023-06-30', 'Detroit', 3)\n",
      "('UA456', '2023-06-16T14:45:00', '2023-06-16', '2023-06-16T12:15:00', '2023-06-16', 'New York', 6)\n",
      "('UA567', '2023-06-23T09:15:00', '2023-06-23', '2023-06-23T06:45:00', '2023-06-23', 'Houston', 9)\n",
      "('UA901', '2023-07-01T17:00:00', '2023-07-01', '2023-07-01T14:30:00', '2023-07-01', 'Minneapolis', 9)\n",
      "('WN012', '2023-06-18T11:10:00', '2023-06-18', '2023-06-18T09:30:00', '2023-06-18', 'Chicago', 2)\n",
      "('WN456', '2023-06-26T11:25:00', '2023-06-26', '2023-06-26T08:55:00', '2023-06-26', 'Denver', 2)\n",
      "('WN890', '2023-07-04T14:20:00', '2023-07-04', '2023-07-04T11:50:00', '2023-07-04', 'Salt Lake City', 18)\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(f\"SELECT * FROM {db_name}.{table_flights}\")\n",
    "sql_data = db_cursor.fetchall()\n",
    "\n",
    "for record in sql_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf28a8-0d22-4223-989b-243431149e22",
   "metadata": {},
   "source": [
    "### Step 4: Create helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae6aca-18fb-4beb-a6ae-caaeea512d1e",
   "metadata": {},
   "source": [
    "To facilate the usability and readability of the SQL Query Analysis made by Llama 3, we have developed a suite of helper functions tailored to various use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b445fc-da02-477e-a6b6-26848c44a727",
   "metadata": {},
   "source": [
    "The `format_instructions` function is designed to process the input from Llama 3 models, allowing a conversation between roles such as `system`, `user`, and `assistant`. To see more details about Llama 3 prompt formats, click [here](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7912ce9e-598c-47db-9780-b1cc95408f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_instructions(instructions: List[Dict[str, str]]) -> List[str]:\n",
    "    \"\"\"Format instructions where conversation roles must alternate system/user/assistant/user/assistant/...\"\"\"\n",
    "    prompt: List[str] = []\n",
    "    for instruction in instructions:\n",
    "        if instruction[\"role\"] == \"system\":\n",
    "            prompt.extend([\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \"<|eot_id|>\"])\n",
    "        elif instruction[\"role\"] == \"user\":\n",
    "            prompt.extend([\"<|start_header_id|>user<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \"<|eot_id|>\"])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid role: {instruction['role']}. Role must be either 'user' or 'system'.\")\n",
    "    prompt.extend([\"<|start_header_id|>assistant<|end_header_id|>\\n\"])\n",
    "    return \"\".join(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0097cde-7a98-4e3e-a0dc-5f8c7c551c8f",
   "metadata": {},
   "source": [
    "The `execute_query` function will execute SQL queries, typically for retrieving data from a database, and format the results as a string for further processing or display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9401ba7a-de43-410d-8015-a38a60f2b6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query: str) -> str:\n",
    "    \"\"\"Execute an SQL query on the database connection and return the results as a string.\n",
    "\n",
    "    Args:\n",
    "        query (str): SQL query to execute\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the SQL results.\n",
    "    \"\"\"\n",
    "    # Get a cursor from the database connection\n",
    "    mycursor = db_conn.cursor()\n",
    "\n",
    "    # Execute the SQL query\n",
    "    mycursor.execute(query)\n",
    "\n",
    "    # Fetch all result rows\n",
    "    result_rows = mycursor.fetchall()\n",
    "\n",
    "    # Convert result to string with newline between rows\n",
    "    output_text = '\\n'.join([str(x) for x in result_rows])\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaedc7-f395-4d92-9809-8f7b71baa42f",
   "metadata": {},
   "source": [
    "The `sagemaker_chat_completion` function uses the SageMaker Endpoint to invoke the LLMs. The response from the LLM is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62b4863f-ff81-4f02-8c25-7f0d50f99d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sagemaker_chat_completion(\n",
    "    prompt: str,\n",
    "    max_gen_len: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a prompt using the llama3 model via Amazon SageMaker JumpStart.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text to generate completions for.\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": max_gen_len,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"stop\": [\"<|eot_id|>\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Call the model API to generate the completion\n",
    "    response = llm_predictor.predict(body)\n",
    "    completion = response.get('generated_text', '')\n",
    "\n",
    "    return completion.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6babb4b-812d-415f-b666-b1f69fc28706",
   "metadata": {},
   "source": [
    "The `bedrock_chat_completion` function uses the Bedrock client to invoke the LLMs. The response from the LLM is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c11b382-cf2d-4df9-971c-dc92c9a13043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bedrock_chat_completion(\n",
    "    model_id: str,\n",
    "    prompt: str,\n",
    "    max_gen_len: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a prompt using the llama3 model via Amazon Bedrock.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The ID of the llama3 model to use for completion.\n",
    "        prompt (str): The prompt text to generate completions for.\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_gen_len\": max_gen_len,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "    }\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    # Convert the body dictionary to JSON string and encode it as bytes\n",
    "    body_json = json.dumps(body)\n",
    "    body_bytes = body_json.encode('utf-8')\n",
    "\n",
    "    # Call the model API to generate the completion\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body_bytes, modelId=model_id, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = response[\"body\"].read()\n",
    "    response_body = json.loads(response_body)\n",
    "    completion = response_body.get(\"generation\", \"\")\n",
    "\n",
    "    return completion.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997f36-a08b-4189-ba98-a410d9063e41",
   "metadata": {},
   "source": [
    "The Function `get_llm_sql_analysis` generates and executes an SQL query for a given question, and returns a comprehensive analyzes based on the sql query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e8610a-69e9-452b-a3cc-42f6e3129709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_llm_sql_analysis(question: str, sql_sys_prompt: str, qna_sys_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an SQL query based on the given question, executes it, and returns an analysis of the results using Llama 3.\n",
    "\n",
    "    Args:\n",
    "        question (str): The input question for which an SQL query needs to be generated.\n",
    "        sql_sys_prompt (str): The prompt to be used for generating the SQL query using Llama 3.\n",
    "        qna_sys_prompt (str): The prompt to be used for analyzing the SQL query results using Llama 3.\n",
    "\n",
    "    Returns:\n",
    "        str: The analysis of the SQL query results provided by the language model.\n",
    "    \"\"\"\n",
    "    if llm_selected_service == 'Amazon SageMaker':\n",
    "        # Generates SQL query\n",
    "        completion = sagemaker_chat_completion(\n",
    "            prompt=sql_sys_prompt\n",
    "        )\n",
    "    else:\n",
    "        # Generates SQL query\n",
    "        completion = bedrock_chat_completion(\n",
    "            model_id=DEFULT_LLM_MODEL_ID,\n",
    "            prompt=sql_sys_prompt\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Extract the SQL query\n",
    "        pattern = r\"<sql>(.*)</sql>\"\n",
    "        llm_sql_query = re.search(pattern, completion, re.DOTALL).group(1)\n",
    "        print(f\"LLM SQL Query: \\n{llm_sql_query}\")\n",
    "\n",
    "        # Execute SQL query\n",
    "        sql_results = execute_query(llm_sql_query)\n",
    "\n",
    "        if llm_selected_service == 'Amazon SageMaker':\n",
    "            # Generates SQL query\n",
    "            llm_sql_analysis = sagemaker_chat_completion(\n",
    "                prompt=qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "            )\n",
    "        else:\n",
    "            # Generates SQL query\n",
    "            llm_sql_analysis = bedrock_chat_completion(\n",
    "                model_id=DEFULT_LLM_MODEL_ID,\n",
    "                prompt=qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "            )\n",
    "\n",
    "        print(f\"LLM SQL Analysis: \\n{llm_sql_analysis}\")\n",
    "        return llm_sql_analysis\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb825ee-8996-433b-b879-0f2581055ec4",
   "metadata": {},
   "source": [
    "The Class `AmazonBedrockEmbeddingFunction` initializes an embedding function with `Amazon Titan Embedding Model V2` that integrates with ChromaDB . This class can be further extended to add support for other embedding models available on Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df8dfb0a-0b02-444b-b8a1-67ec98772a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonBedrockEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        session: \"boto3.Session\",\n",
    "        model_name: str = \"amazon.titan-embed-text-v2:0\",\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize AmazonBedrockEmbeddingFunction.\n",
    "\n",
    "        Args:\n",
    "            session (boto3.Session): The boto3 session to use.\n",
    "            model_name (str, optional): Identifier of the model, defaults to \"amazon.titan-embed-text-v1\"\n",
    "            **kwargs: Additional arguments to pass to the boto3 client.\n",
    "\n",
    "        Example:\n",
    "            >>> import boto3\n",
    "            >>> session = boto3.Session(profile_name=\"profile\", region_name=\"us-east-1\")\n",
    "            >>> bedrock = AmazonBedrockEmbeddingFunction(session=session)\n",
    "            >>> texts = [\"Hello, world!\", \"How are you?\"]\n",
    "            >>> embeddings = bedrock(texts)\n",
    "        \"\"\"\n",
    "\n",
    "        self._model_name = model_name\n",
    "\n",
    "        self._client = session.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        accept = \"*/*\"\n",
    "        content_type = \"application/json\"\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            input_body = {\"inputText\": text, \"dimensions\": 512, \"normalize\": True}\n",
    "            body = json.dumps(input_body)\n",
    "            response = self._client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=self._model_name,\n",
    "                accept=accept,\n",
    "                contentType=content_type,\n",
    "            )\n",
    "            embedding = json.load(response.get(\"body\")).get(\"embedding\")\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47479bba-58f5-4906-89d7-9eb688588192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonSageMakerEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize AmazonSageMakerEmbeddingFunction.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Additional arguments to pass to the sagemaker embedding function.\n",
    "\n",
    "        Example:\n",
    "            >>> sagemaker = AmazonBedrockEmbeddingFunction()\n",
    "            >>> text_inputs = [\"Hello, world!\", \"How are you?\"]\n",
    "            >>> embeddings = sagemaker(texts)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        accept = \"application/json\"\n",
    "        content_type = \"application/json\"\n",
    "\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            input_body = {\"text_inputs\": text, \"mode\": \"embedding\"}\n",
    "            body = json.dumps(input_body).encode('utf-8')\n",
    "            response = embedding_predictor.predict(\n",
    "                body,\n",
    "                {\n",
    "                    \"ContentType\": content_type,\n",
    "                    \"Accept\": accept,\n",
    "                }\n",
    "            )\n",
    "            embedding = response.get(\"embedding\")\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909b559-22a3-41ff-99d3-96796458dd44",
   "metadata": {},
   "source": [
    "## Few-Shot Text-to-SQL\n",
    "With our database and tables filled with data, we're now ready to walk through the Few-Shot Text-to-SQL approach. We'll start by building some helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccf1fe-ed1a-42f7-885c-8f12a8d15aca",
   "metadata": {},
   "source": [
    "## Analyzing a Single Table with Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e4c5a",
   "metadata": {},
   "source": [
    "### Step 1: Create a Few-Shot Prompt\n",
    "Here, we design our prompt template that will account for our question and answer, and formatted correctly for use with Llama 3 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ea8a0-61e8-4eee-a14a-71e9d6ec303d",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing two parts:\n",
    "\n",
    "1. `table_schema`. This is a description of the structure of the database table, including the name of the table, the names of the columns within each table, and the data types of each column. This information helps Llama 3 to understand the organization and contents of the table.\n",
    "\n",
    "2. `question`. This is the specific request or information that the user wants to obtain from the table.\n",
    "\n",
    "By including both the table schema and the user's question in the system prompt, we provide Llama 3 model a complete understanding of the table structure and the user's desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9528d11-a02e-436d-a06c-b40639dce4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a mysql query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schema:\n",
    "<table_schema>\n",
    "{table_schema}\n",
    "<table_schema>\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "tmp_sql_sys_prompt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb4eb9-d15c-4453-8053-4d80813794c0",
   "metadata": {},
   "source": [
    "Next, we create a new `system prompt` containing two parts:\n",
    "\n",
    "1. `query_results` represents the SQL query results after executing the prompt `tmp_sql_sys_prompt`. This is the raw data that Llama 3 model will use to generate its analysis.\n",
    "\n",
    "2. `question`. This specifies the type of analysis or insight that the user wants Llama 3 model to provide based on the SQL query results.\n",
    "\n",
    "By combining the SQL query results and the user's question into a single system prompt, we provide Llama 3 model all the information it needs to understand the context and provide a comprehensive analysis tailored to the user's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62c5e5b2-13b1-4f70-9484-56b2ef618cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Given the following SQL query results:\n",
    "{query_results}\n",
    "\n",
    "And the original question:\n",
    "{question}\n",
    "\n",
    "Please provide an analysis and interpretation of the results to answer the original question.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "QNA_SYS_PROMPT = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97db613",
   "metadata": {},
   "source": [
    "Building on our last prompt, we'll now add a Single Shot example to our context to better hint the model what we expect for a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de41022-e8fa-423e-a35b-92537e8dfd21",
   "metadata": {},
   "source": [
    "### Step 2: Execute Few Shot Prompts\n",
    "The following cells will demonstrate different questions asked in natural language and the SQL generated by the LLM. The output is contained between the `<sql>` and `</sql>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6617123b-78ea-4631-9871-30c01c7a888a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM SQL Query: \n",
      "SELECT COUNT(*) FROM airline_db.airplanes;\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, we can see that the output is a single value: (20).\n",
      "\n",
      "This suggests that the query was designed to count the total number of airplanes in the database. The result, 20, indicates that there are 20 airplanes in the database.\n",
      "\n",
      "Therefore, the answer to the original question \"What is the total count of airplanes?\" is 20.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schema=table_schema_airplanes\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e9395-5c48-4880-a80e-4874786b7ab1",
   "metadata": {},
   "source": [
    "## Analyzing Multiple Table with Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad7c5d-98a8-4079-b668-29347c563bef",
   "metadata": {},
   "source": [
    "### Step 1: Create a Few-Shot Prompt\n",
    "Now, let's try the same approach using two tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea14d6-539f-442a-85fd-e32dd02abb44",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing the same placeholders as before and including two table schemas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92b4a07c-3762-411b-a0ab-a94c8df3d96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a mysql query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schemas:\n",
    "<table_schemas>\n",
    "<table_schema>\n",
    "{table_schema1}\n",
    "<table_schema>\n",
    "\n",
    "<table_schema>\n",
    "{table_schema2}\n",
    "<table_schema>\n",
    "<table_schemas>\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "tmp_sql_sys_prompt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cead15-002f-4b53-9d9f-da3b4ac94db8",
   "metadata": {},
   "source": [
    "### Step 2: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abce7627-60c2-432b-af9c-beabbe86be54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM SQL Query: \n",
      "\n",
      "SELECT \n",
      "  a.Producer, \n",
      "  COUNT(f.Flight_number) AS total_flights\n",
      "FROM \n",
      "  airline_db.airplanes a \n",
      "  JOIN airline_db.flights f ON a.Airplane_id = f.Airplane_id\n",
      "GROUP BY \n",
      "  a.Producer\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can analyze and interpret the data to answer the original question:\n",
      "\n",
      "**Original Question:** What is the total count of flights per producer?\n",
      "\n",
      "**Results:**\n",
      "\n",
      "* Boeing: 4 flights\n",
      "* Airbus: 8 flights\n",
      "* Embraer: 5 flights\n",
      "* Bombardier: 3 flights\n",
      "\n",
      "**Analysis and Interpretation:**\n",
      "\n",
      "The results show the total count of flights for each aircraft producer. We can see that:\n",
      "\n",
      "* Airbus has the highest number of flights with 8.\n",
      "* Boeing has 4 flights, which is the second-lowest count.\n",
      "* Embraer has 5 flights, which is slightly higher than Boeing's count.\n",
      "* Bombardier has the lowest number of flights with 3.\n",
      "\n",
      "To answer the original question, we can conclude that the total count of flights per producer is:\n",
      "\n",
      "* Airbus: 8\n",
      "* Boeing: 4\n",
      "* Embraer: 5\n",
      "* Bombardier: 3\n",
      "\n",
      "These results provide a snapshot of the number of flights operated by each aircraft producer, allowing us to compare their relative performance in terms of flight operations.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of flights per producer?\"\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schema1=table_schema_airplanes,\n",
    "    table_schema2=table_schema_flights\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518e52c-5ac3-4682-8cb6-921039ffa2d0",
   "metadata": {},
   "source": [
    "## Limitations of Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfcd94-8b32-4cc3-b0cc-7425105958a7",
   "metadata": {},
   "source": [
    "Few-Shot Learning for text-to-SQL tasks, where a language model is trained on a limited number of examples to translate natural language queries into SQL queries, faces significant limitations. One of the key challenges is selecting the appropriate table schema that aligns with the user's question.\n",
    "\n",
    "In a real-world scenario, databases often consist of numerous tables with intricate relationships, making it difficult for the model to identify the relevant tables and columns required to answer a given query accurately. \n",
    "\n",
    "To address this issue, we propose incorporating ChromaDB to facilitate the retrieval of table schemas that are tailored to the user's question.\n",
    "\n",
    "Here's how ChromaDB can help overcome the table schema selection challenge:\n",
    "\n",
    "1. **Table Schema Retrieval**: Each table schema in the database can be converted into a dense vector embedding, capturing its structural information and relationships. The top-ranked table schemas are retrieved and provided as input to the text-to-SQL model, significantly increasing the likelihood of generating accurate SQL queries.\n",
    "\n",
    "2. **Enhancing Schema Retrieval with Sample Questions**: To further improve the accuracy of retrieving the right table schema, we can incorporate sample questions that closely align with each table schema. These sample questions can serve as reference points for matching similar user queries, enabling more precise schema retrieval.\n",
    "\n",
    "We will review this approach further in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366f9d5-f0ca-4008-a8be-04ab47b22779",
   "metadata": {},
   "source": [
    "## Few-shot text-to-SQL powered by ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73cdbb-e062-4d04-981d-ae92ec7e71fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, we will use ChromaDB and the few-shot technique to effeciently retrieve table schemas for better performance and generalization across different databases and query types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765c200-7f94-4044-97ca-4681d5058d6b",
   "metadata": {},
   "source": [
    "## Schema Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf41750-066b-40f5-a4f2-407acec7da60",
   "metadata": {},
   "source": [
    "In this approach, we will store only the table schemas in ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70751dc4-6b3d-45b8-838d-908cd26684ab",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing\n",
    "\n",
    "The first step is to preprocess the data and create a document that will be ingested into ChromaDB. The final doc clearly separates the table schemas by using XML tags such as `<table_schema></table_schema>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8f8888c-2a37-4a0c-8949-baaa24815ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc1 = \"<table_schemas>\\n\"\n",
    "doc1 += f\"<table_schema>\\n {settings_airplanes['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "doc1 += \"\\n</table_schemas>\"\n",
    "\n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d550e81-9156-4d78-b5f6-661f8e065000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc2 = \"<table_schemas>\\n\"\n",
    "doc2 += f\"<table_schema>\\n {settings_flights['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "doc2 += \"\\n</table_schemas>\"\n",
    "print(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "083c5523-020d-46c4-a2fa-2dcc4dd4a1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc3 = \"<table_schemas>\\n\"\n",
    "for table_schema in settings_airplane_flights['table_schemas']:\n",
    "    doc3 += f\"<table_schema>\\n {table_schema} \\n</table_schema>\\n\"\n",
    "doc3 += \"\\n</table_schemas>\".strip()\n",
    "print(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad09a7-e39e-48fe-a4af-e4e573aa8d24",
   "metadata": {},
   "source": [
    "### Step 2: Ingest docs into ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b088a-846e-4ca2-842f-5ff1c6897b26",
   "metadata": {},
   "source": [
    "After the data is preprocessed, the next step is to ingest all `docs` into ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cea1d14-515d-483c-83a5-ac7a5d0f0c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Chroma in-memory, for easy prototyping.\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa0f60b6-e292-4a6c-b900-bcb2ab4e54b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create collection using ChromaDB's internal embedding function\n",
    "collection1 = chroma_client.create_collection(name=\"table-schemas-default-embedding\", metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "619eb8a2-dc67-42ec-8156-408117e8253d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add docs to the collection.\n",
    "collection1.add(\n",
    "    documents=[\n",
    "        doc1,\n",
    "        doc2,\n",
    "        doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_airplanes},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_flights},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": f\"{table_airplanes}-{table_flights}\" }\n",
    "    ],\n",
    "    ids=[table_airplanes, table_flights, f\"{table_airplanes}-{table_flights}\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7669-6cd2-485f-8d41-44fb3526c86e",
   "metadata": {},
   "source": [
    "### Step 3: Create a Few-Shot Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588156e2-5b35-4828-a3ca-e077f2c542ac",
   "metadata": {},
   "source": [
    "Now, we'll use a few-shot approach using the retrieved tables from ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbb802-9437-47b5-b728-9e2e7c9a64df",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing a placeholder including any number of table schemas for ChromaDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc0758c4-7710-43af-ad4f-e1a3123f685a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a mysql query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schemas:\n",
    "<table_schemas>\n",
    "{table_schemas}\n",
    "<table_schemas>\n",
    "\n",
    "Always combine the database name and table name to build your queries. You must identify these two values before proving a valid SQL query.\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "tmp_sql_sys_prompt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc134b9c-96de-47b7-a182-664024d0b2a8",
   "metadata": {},
   "source": [
    "### Step 4: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977f101-cd0b-4ab4-bc6e-85bf3d759f1d",
   "metadata": {},
   "source": [
    "In this example, we expect the table `airplanes` to be used for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8853827-1d81-4ef4-befc-d2f55d52314a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT COUNT(DISTINCT Airplane_id) \n",
      "FROM airline_db.flights;\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, we can see that the output is a single value: `(12)`.\n",
      "\n",
      "This suggests that the SQL query was designed to count the total number of airplanes in the database, and the result is 12.\n",
      "\n",
      "Therefore, the answer to the original question \"What is the total count of airplanes?\" is:\n",
      "\n",
      "**12**\n",
      "\n",
      "In other words, there are 12 airplanes in the database.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection1.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d524f72-c687-49a0-8dbc-21476fbcedcd",
   "metadata": {},
   "source": [
    "### Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2970425-61a7-489d-b133-3cbf0d6e85b9",
   "metadata": {},
   "source": [
    "We can observe that ChromaDB was unable to retrieve the correct table schema for the \"airplanes\" table. The issue arose due to a confusion caused by a foreign key reference. Specifically, ChromaDB retrieved the \"flights\" table instead of the \"airplanes\" table because the \"flights\" table contains a field called \"Airplane_id\" which references the \"airplanes\" table as a foreign key. This foreign key reference led to the confusion, resulting in ChromaDB retrieving the wrong table.\n",
    "\n",
    "To mitigate this issue, two potential solutions can be implemented:\n",
    "\n",
    "1. Use a more robust embedding model like the `Amazon Titan Embedding Model`.\n",
    "\n",
    "2. Include sample questions within the same embedding to enhance the similarity search. By providing the embedding model with relevant sample questions, it may improve the accuracy of retrieving the correct table schema based on the context of the query.\n",
    "\n",
    "We will see this in action in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a5731-2f4c-46f0-b03a-c417338064ed",
   "metadata": {},
   "source": [
    "## Enhanced Schema Retrieval with Sample Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c58d4-9330-438a-9aa6-72340fdc4b64",
   "metadata": {},
   "source": [
    "In this approach, we will store sample questions and the table schemas in ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f41a88-42f6-4fe0-9adf-d18888623e43",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing\n",
    "\n",
    "For this scenario, the final doc clearly separates the sample questions and table schemas by using XML tags such as `<questions></questions>` and `<table_schema></table_schema>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02b791f2-a0fb-4ad5-a4b2-8c3b66eeff93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<questions>\n",
      " 1. How many unique airplane producers are represented in the database?\n",
      "2. What is the most common airplane type in the database?\n",
      "3. Retrieve a list of all airplane IDs and their corresponding producers.\n",
      "4. Find all airplanes produced by a specific manufacturer (e.g., Boeing or Airbus).\n",
      "5. Get the number of airplanes for each type, sorted by count in descending order.\n",
      "6. Retrieve all airplane IDs and types where the type contains a specific substring (e.g., \"737\" or \"A320\").\n",
      "7. Find the airplane ID and producer for the airplane with the highest ID value.\n",
      "8. Get a list of unique producers, along with the count of airplanes for each producer.\n",
      "9. Retrieve all airplane IDs, producers, and types where the producer name starts with a specific letter (e.g., \"B\" for Boeing).\n",
      "10. Find all airplane IDs and types where the type is not equal to a specific value (e.g., \"737\").\n",
      " \n",
      "</questions>\n"
     ]
    }
   ],
   "source": [
    "# List of sample questions related to the table `airplanes`\n",
    "questions = settings_airplanes['questions']\n",
    "\n",
    "# The doc includes a structure format for clearly appending the sample questions to prior table schemas\n",
    "doc1 += f\"\\n<questions>\\n {questions} \\n</questions>\"\n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e54645c8-a56d-4187-8af0-78bb9d873bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<questions>\n",
      " 1. What are the flight numbers of all flights arriving at a specific destination?\n",
      "2. What is the average arrival time for flights on a particular date?\n",
      "3. List the flight numbers and arrival times for flights departing between a given range of dates and times.\n",
      "4. How many flights are scheduled to depart from a specific airport on a given date?\n",
      "5. What is the longest duration between departure and arrival times for any flight?\n",
      "6. List the flight numbers and airplane IDs for flights with a departure delay greater than X hours.\n",
      "7. Find the most frequently used airplane for flights to a particular destination.\n",
      "8. Get the total number of flights scheduled for each destination, grouped by arrival date.\n",
      "9. Retrieve the flight details (flight number, departure/arrival times, airplane ID) for flights using a specific airplane on a given date range.\n",
      "10. List the flight numbers and destinations for flights with a scheduled arrival time between two specified times on a given date.\n",
      " \n",
      "</questions>\n"
     ]
    }
   ],
   "source": [
    "# List of sample questions related to the table `flights`\n",
    "questions = settings_flights['questions']\n",
    "\n",
    "# The doc includes a structure format for clearly appending the sample questions to prior table schemas\n",
    "doc2 += f\"\\n<questions>\\n {questions} \\n</questions>\"\n",
    "print(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d983da1f-426d-4da4-b265-75ff7bfe9ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<questions>\n",
      " 1. What are the different airplane producers represented in the database?\n",
      "2. How many flights are scheduled to arrive at a particular destination on a given date?\n",
      "3. What is the latest arrival time for flights on a particular day?\n",
      "4. Which airplane types are used for flights to a specific destination?\n",
      "5. What is the average departure time for flights using a particular airplane type?\n",
      "6. List all the flights that will depart before a certain time on a given date, sorted by departure time.\n",
      "7. Find the airplane IDs and producers for airplanes that have flown to a particular destination.\n",
      "8. How many different airplane types are used by each producer?\n",
      "9. Get the flight numbers and arrival/departure times for flights using a specific airplane ID.\n",
      "10. Calculate the duration of each flight based on the departure and arrival times.\n",
      "11. Find the most frequently used airplane type for flights to a particular destination.\n",
      "12. List all the flights that will arrive or depart between two given dates/times.\n",
      "13. Get the flight numbers and airplane producers for flights with a departure time within a certain range.\n",
      "14. Count the number of flights per destination, grouped by airplane type.\n",
      "15. Retrieve the flight details for flights using airplanes produced by a specific manufacturer.\n",
      " \n",
      "</questions>\n"
     ]
    }
   ],
   "source": [
    "# List of sample questions related to the JOIN of tables `airplanes` and `flights`\n",
    "questions = settings_airplane_flights['questions']\n",
    "\n",
    "# The doc includes a structure format for clearly appending the sample questions to prior table schemas\n",
    "doc3 += f\"\\n<questions>\\n {questions} \\n</questions>\"\n",
    "print(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee69c27-b639-4380-9f32-356f18b55584",
   "metadata": {},
   "source": [
    "### Step 2: Ingest docs into ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746786d7-8ab0-4b99-b57e-efdba7f1131c",
   "metadata": {
    "tags": []
   },
   "source": [
    "After the data is preprocessed, the next step is to ingest all `docs` into ChromaDB using `Amazon Titan Embedding V2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ea54fec-5074-44bc-bff5-b5b1e7e4a4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create embedding function with AWS\n",
    "if embedding_selected_service == \"Amazon SageMaker\":\n",
    "    aws_ef = AmazonSageMakerEmbeddingFunction()\n",
    "else:\n",
    "    session = boto3.Session()\n",
    "    aws_ef = AmazonBedrockEmbeddingFunction(\n",
    "        session=session,\n",
    "        model_name=DEFAULT_EMBEDDING_MODEL_ID\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3ca323c-68c2-41cb-afbc-03fece3db46b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create collection using Amazon Titan Embedding model\n",
    "collection2 = chroma_client.create_collection(name=\"table-schemas-aws-embedding-model\", embedding_function=aws_ef, metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa251e61-7f75-4c96-9faf-397a785fdcc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add docs to the collection.\n",
    "collection2.add(\n",
    "    documents=[\n",
    "        doc1,\n",
    "        doc2,\n",
    "        doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_airplanes},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_flights},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": f\"{table_airplanes}-{table_flights}\" }\n",
    "    ],\n",
    "    ids=[table_airplanes, table_flights, f\"{table_airplanes}-{table_flights}\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec741334-b2ac-4d27-b11e-ee365dadf0fe",
   "metadata": {},
   "source": [
    "### Step 3: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265c0a3-40d9-482b-98ff-1077b358cecd",
   "metadata": {},
   "source": [
    "In this example, we expect the table `airplanes` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2b9a734-4898-4e00-9df1-af448acb5424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(Airplane_id) FROM airline_db.airplanes;\n",
      "LLM SQL Analysis: \n",
      "A simple yet straightforward question!\n",
      "\n",
      "Analysis and Interpretation:\n",
      "\n",
      "The SQL query results show a single value: `(20)`. This indicates that the query has returned a count of 20, which represents the total number of airplanes.\n",
      "\n",
      "Therefore, the answer to the original question is:\n",
      "\n",
      "There are 20 airplanes.\n",
      "\n",
      "In other words, the total count of airplanes is 20.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86a1b-087f-46c8-8509-5385299e9832",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this second example, we expect the table `airplanes` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0a9fffb-4ebb-4c89-a41f-6e74dc214bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(DISTINCT Producer) FROM airline_db.airplanes;\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, we can see that the output is a single value: `(4)`.\n",
      "\n",
      "This result indicates that there are **4 unique airplane producers** represented in the database.\n",
      "\n",
      "In other words, the query has counted the number of distinct airplane producers in the database, and the answer is 4. This means that there are four different companies or entities that produce airplanes, and they are all represented in the database.\n",
      "\n",
      "Therefore, the answer to the original question is: **There are 4 unique airplane producers represented in the database.**\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"How many unique airplane producers are represented in the database?\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ab7a3-bb1b-4f1b-82d1-4e02f8d40848",
   "metadata": {},
   "source": [
    "For this third example, we expect the table `flights` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd806b74-efe4-4701-8a3e-480e8a456074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT \n",
      "    Arrival_date, \n",
      "    Destination, \n",
      "    COUNT(Flight_number) AS total_flights\n",
      "FROM \n",
      "    airline_db.flights\n",
      "GROUP BY \n",
      "    Arrival_date, \n",
      "    Destination\n",
      "ORDER BY \n",
      "    Arrival_date;\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can analyze and interpret the data to answer the original question.\n",
      "\n",
      "The results show a list of flights with their corresponding arrival dates, destinations, and a column with a value of 1 (which likely represents a single flight). To get the total number of flights scheduled for each destination, grouped by arrival date, we can analyze the data as follows:\n",
      "\n",
      "1. The data contains 30 rows, each representing a single flight.\n",
      "2. The arrival dates range from '2023-06-15' to '2023-07-04', covering 20 days.\n",
      "3. There are 20 unique destinations listed, each appearing only once in the dataset.\n",
      "4. Since each row has a value of 1 in the third column, we can assume that each row represents a single flight.\n",
      "\n",
      "To answer the original question, we need to group the flights by arrival date and count the number of flights for each date. Since each destination appears only once, the count of flights for each date will be 1.\n",
      "\n",
      "Here's a possible interpretation of the results:\n",
      "\n",
      "* For each of the 20 days from '2023-06-15' to '2023-07-04', there is only 1 flight scheduled for each destination.\n",
      "* The total number of flights scheduled for each destination is 1, regardless of the arrival date.\n",
      "\n",
      "If you're expecting to see multiple flights for each destination or a varying number of flights across different dates, the dataset might not be comprehensive or accurate. However, based on the provided data, the interpretation above holds true.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"Get the total number of flights scheduled for each destination, grouped by arrival date\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199367e-7117-4553-b2f6-47073cb17769",
   "metadata": {},
   "source": [
    "For this fourth example, we expect the table `airplanes` and `flights` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a62f3823-367d-47a1-a0de-e4babe42ef08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT a.Airplane_id, a.Producer\n",
      "FROM airline_db.airplanes a\n",
      "JOIN airline_db.flights f ON a.Airplane_id = f.Airplane_id\n",
      "WHERE f.Destination = 'New York';\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can analyze and interpret the output as follows:\n",
      "\n",
      "The result set contains a single row with two columns:\n",
      "\n",
      "* `airplane_id`: 6\n",
      "* `producer`: 'Airbus'\n",
      "\n",
      "This suggests that there is only one airplane that has flown to New York, and its details are as follows:\n",
      "\n",
      "* The airplane has an ID of 6.\n",
      "* The producer of this airplane is Airbus.\n",
      "\n",
      "Therefore, the answer to the original question is that the airplane with ID 6, produced by Airbus, has flown to New York.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"Find the airplane IDs and producers for airplanes that have flown to New York\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce768358-c208-4c81-acff-ecb39b904b91",
   "metadata": {},
   "source": [
    "### Step 4: Conclusion\n",
    "\n",
    "We can observe that ChromaDB and `Amazon Titan Embedding` model were able to retrieve the correct table schemas for the previous examples when also incorporating sample questions as an agregated context.  After successfully implementing these solutions, the issue of incorrectly retrieved table schemas due to foreign key confusions was effectively addressed. The data retrieval process became more accurate and reliable, ensuring that the correct table schemas were consistently retrieved, even in the presence of complex table relationships and foreign key references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5c40f-5e79-4b0a-9c0a-fa16b8195b6b",
   "metadata": {},
   "source": [
    "## Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b500a5c-16cc-4d23-9d06-8666928daa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete resources\n",
    "if llm_selected_service == 'Amazon SageMaker':\n",
    "    llm_predictor.delete_model()\n",
    "    llm_predictor.delete_endpoint()\n",
    "\n",
    "if embedding_selected_service == 'Amazon SageMaker':\n",
    "    embedding_predictor.delete_model()\n",
    "    embedding_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015474d-4387-447d-97a9-e4ae662d49d4",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea39284-8d33-440f-acb7-c33732544e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
