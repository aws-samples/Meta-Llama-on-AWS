{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f1e07e-5f03-4ae1-aa92-b0d8698edc73",
   "metadata": {},
   "source": [
    "## Fine-tune Llama 3.2 11b with prepared dataset\n",
    "\n",
    "In this notebook, we will go over the steps to fine-tune llama 3.2 11b with the dataset that was prepared in the previous notebook for building your own OCR solution.\n",
    "\n",
    "We will ensure that the dataset is first loaded to s3 before we define our hyperparameters that will be used within our SageMaker estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a61fa-f07c-43e9-92ef-7b2b5a8ccf76",
   "metadata": {},
   "source": [
    "### Upload the dataset to the S3\n",
    "\n",
    "Given the dataset contains image, the uploading process will take a while depending on the size of examples you process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684133cf-bda4-4bb4-89d2-782f73877f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'genai-accelerate-2024'\n",
    "subdirectory = 'llama-3-2-vision-folder'\n",
    "train_data_location = f\"s3://{bucket_name}/{subdirectory}\"\n",
    "\n",
    "# Files to upload (metadata.jsonl and images folder)\n",
    "files_to_upload = [\n",
    "    '/home/ec2-user/SageMaker/vision-workshop/dataset/metadata.jsonl',\n",
    "    '/home/ec2-user/SageMaker/vision-workshop/dataset/images'\n",
    "]\n",
    "\n",
    "for file_path in files_to_upload:\n",
    "    if os.path.isfile(file_path):\n",
    "        # Upload single file\n",
    "        file_name = os.path.basename(file_path)\n",
    "        key_path = f\"{subdirectory}/{file_name}\"\n",
    "        try:\n",
    "            s3.upload_file(file_path, bucket_name, key_path)\n",
    "            print(f\"File {file_name} uploaded successfully to {key_path}.\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Error uploading file {file_name}: {e}\")\n",
    "    elif os.path.isdir(file_path):\n",
    "        # Upload directory\n",
    "        for root, _, files in os.walk(file_path):\n",
    "            for file in files:\n",
    "                full_file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(full_file_path, start=file_path)\n",
    "                s3_key = f\"{subdirectory}/images/{relative_path}\"\n",
    "                try:\n",
    "                    s3.upload_file(full_file_path, bucket_name, s3_key)\n",
    "                    print(f\"File {file} uploaded successfully to {s3_key}.\")\n",
    "                except ClientError as e:\n",
    "                    print(f\"Error uploading file {file} to {s3_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7b0d9-7a69-4b67-aff6-1b400779799c",
   "metadata": {},
   "source": [
    "## Define model id and hyperparameters\n",
    "\n",
    "In the next cell we will use the sagemaker library to call the model that we will fine-tune along with the hyperparameters. By default, we will choose 1 epoch as our hyperparamter for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabdbb2-7c9a-4f62-ba17-aa05a562df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Set model ID and version\n",
    "model_id, model_version = \"meta-vlm-llama-3-2-11b-vision-instruct\", \"*\"\n",
    "\n",
    "my_hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=model_id, model_version=model_version\n",
    ")\n",
    "print(my_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbed0d-28ed-4c95-a2c5-40202582be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hyperparameters[\"epoch\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09144a-08db-4554-bcca-3e023cc21bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters.validate(\n",
    "    model_id=model_id, model_version=model_version, hyperparameters=my_hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171491d-a8a2-4fa7-8b00-d570400f84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "\n",
    "\n",
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    environment={\"accept_eula\": \"true\"},  # Please change {\"accept_eula\": \"true\"}\n",
    "    disable_output_compression=True,\n",
    "    instance_type=\"ml.p4de.24xlarge\",\n",
    "    hyperparameters=my_hyperparameters,\n",
    ")\n",
    "estimator.fit({\"training\": train_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab19ad6-6c0f-472b-b7e3-ab14c67b82b6",
   "metadata": {},
   "source": [
    "Studio Kernel Dying issue: If your studio kernel dies and you lose reference to the estimator object, please see section 2. Studio Kernel Dead/Creating JumpStart Model from the training Job on how to deploy endpoint using the training job name and the model id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529404fb-eb5f-4c88-af17-0fe1eca78b86",
   "metadata": {},
   "source": [
    "### Deploy the fine-tuned model\n",
    "\n",
    "------\n",
    "\n",
    "Next, we deploy fine-tuned model. We will compare the performance of fine-tuned and pre-trained model.\n",
    "\n",
    "------\n",
    "Before deployment, we need to know whether the model is finetuned with chat template. If so, we need deploy it with MESSAGES_API_ENABLED and input / output signatures are different.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ab7c64-08d6-4edc-892b-b9fe6370297e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m is_chat_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmy_hyperparameters\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "is_chat_template = True if my_hyperparameters[\"chat_template\"] == \"True\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571ba21-a2d1-4cb0-bb90-5f594536303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chat_template:\n",
    "    estimator.environment = {\"MESSAGES_API_ENABLED\": \"true\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bfeb5-4e97-4366-aceb-cafff28de128",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_predictor = estimator.deploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
