{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb67fda8-2a04-4632-83a2-c60f62390888",
   "metadata": {},
   "source": [
    "# Fine Tuning Llama-4 Scout "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4981d0f9-4db1-4ca9-9a2b-4b134fd80892",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc294ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers \"huggingface_hub[cli]\" scikit-learn --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c804b-4284-4a34-8d76-b72857a72e8b",
   "metadata": {},
   "source": [
    "### Login to huggingface using your tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc88b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add your HF token and ensure that you got access to download meta-llama/Llama-4-Scout-17B-16E-Instruct/tokenizer.model from HF\n",
    "!huggingface-cli login --token \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229fafe-032c-4c33-9100-b860f932f7f1",
   "metadata": {},
   "source": [
    "### Import modules and define SM IAM role, source_dir and s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a2f0b-4905-4287-9259-8d581239db30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "source_dir = \"./src\"\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    " \n",
    "#Using SM bdefeult bucket, please update the S3 bucket as needed\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket) \n",
    " \n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be136d0-5fec-405c-b0be-ac151d0c52c2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f5e2b-b84b-4c50-9c86-414290f98e68",
   "metadata": {},
   "source": [
    "### Download databricks-dolly-15k dataset from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489157e-9821-4aee-b2aa-dae5924ccced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a11c0-53e2-4e36-b75d-bc3f19740685",
   "metadata": {},
   "source": [
    "### Format and split train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9db4d-4062-4b9f-8e32-490f785de1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_transform(row):\n",
    "    content = \"Instruction: {} \\n Context: {}\".format(row['instruction'], row['context'])\n",
    "    prompt = {\n",
    "        \"prompt\": content,\n",
    "        \"response\": row[\"response\"]\n",
    "        \n",
    "    }\n",
    "    return prompt\n",
    "    \n",
    "data = []\n",
    "\n",
    "with open('databricks-dolly-15k.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        trans_data = data_transform(row)\n",
    "        data.append(trans_data)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2,random_state = 42)\n",
    "\n",
    "\n",
    "train[:500].to_json(\"train_dataset.json\", orient=\"records\", force_ascii=False) #comment to train on entire dataset\n",
    "test[:100].to_json(\"test_dataset.json\", orient=\"records\", force_ascii=False) #comment to train on entire dataset\n",
    "#train.to_json(\"train_dataset.json\", orient=\"records\", force_ascii=False)#Uncomment to train on entire dataset\n",
    "#test.to_json(\"test_dataset.json\", orient=\"records\", force_ascii=False) #Uncomment to train on entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5e1ca-4c40-4481-9b2b-8ec5360d65ad",
   "metadata": {},
   "source": [
    "### Upload the train/test dataset to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537471a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "input_path = f's3://{sagemaker_session_bucket}/datasets/llama4'\n",
    " \n",
    "from sagemaker.s3 import S3Uploader\n",
    "train_dataset_s3_path = S3Uploader.upload(local_path=\"./train_dataset.json\", desired_s3_uri=f\"{input_path}/train_v3\")\n",
    "test_dataset_s3_path = S3Uploader.upload(local_path=\"./test_dataset.json\", desired_s3_uri=f\"{input_path}/test_v3\")\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(test_dataset_s3_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c394d2-788c-4442-9507-5c308bf4c620",
   "metadata": {},
   "source": [
    "### Upload config.yaml from source_dir to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6e6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    " \n",
    "# upload the model yaml file to s3\n",
    "model_yaml = \"{}/config.yaml\".format(source_dir)\n",
    "train_config_s3_path = S3Uploader.upload(local_path=model_yaml, desired_s3_uri=f\"{input_path}/config_v2\")\n",
    " \n",
    "print(f\"Training config uploaded to:\")\n",
    "print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b6729-fe94-45c6-8021-ac6a4079ef0a",
   "metadata": {},
   "source": [
    "### Define PyTorch estimator with all required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349af4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "train_dlc_image = \"763104351884.dkr.ecr.{}.amazonaws.com/pytorch-training:2.7.1-gpu-py312-cu128-ubuntu22.04-sagemaker\".format(sess.boto_region_name)\n",
    "# define Training Job Name \n",
    "job_name = f'llama4-scout'\n",
    "\n",
    "#Select Instance type\n",
    "instance_type = 'ml.p4de.24xlarge' # instances type used for the training job - Alternatively you can use p5, p5en instances\n",
    "\n",
    "# create the Estimator\n",
    "pytorch_estimator = PyTorch(\n",
    "    entry_point          = 'run_l4_lora.sh',      # train script\n",
    "    source_dir           = source_dir,  # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type,  \n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 1024,               # the size of the EBS volume in GB\n",
    "    py_version           = 'py312',           # the python version used in the training job\n",
    "    image_uri            = train_dlc_image,\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost\n",
    "    environment  = {\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "        \"HF_TOKEN\": HfFolder.get_token(),       # huggingface token to access gated models, e.g. llama 4\n",
    "        \"FSDP_CPU_RAM_EFFICIENT_LOADING\": \"1\"   # enable CPU RAM efficient loading\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0080e27-5c70-4820-bc1e-45caee849b94",
   "metadata": {},
   "source": [
    "### Intiate SM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb685b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {\n",
    "  'train': train_dataset_s3_path,\n",
    "  'test': test_dataset_s3_path,\n",
    "  'config': train_config_s3_path\n",
    "  }\n",
    " \n",
    "# starting the train job with our uploaded datasets as input\n",
    "pytorch_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4be615-cd81-4fd4-a707-f970bfd53ea7",
   "metadata": {},
   "source": [
    "## Deploy the Fine-tuned model in a Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c4e20-0f54-412d-8126-df1acd71f6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select the latest container. Check the link for the latest available version https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers \n",
    "CONTAINER_VERSION = '0.33.0-lmi15.0.0-cu128'\n",
    "\n",
    "# vLLM container URI\n",
    "container_uri = f'763104351884.dkr.ecr.{sess.boto_region_name}.amazonaws.com/djl-inference:{CONTAINER_VERSION}'\n",
    "\n",
    "# Select instance type\n",
    "instance_type = \"ml.g6e.48xlarge\" \n",
    "\n",
    "print(f\"Container URI: {container_uri}\")\n",
    "print(f\"Instance Type: {instance_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fba17-e40e-4626-80ea-a1a2bab673f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_config = {\n",
    "    \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"2048\",\n",
    "    \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"8\",\n",
    "    \"OPTION_MODEL_LOADING_TIMEOUT\": \"1500\",\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973469ea-37e1-4b06-a348-c37ec395c2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    " \n",
    "model = Model(image_uri=container_uri,\n",
    "              role=role,\n",
    "              model_data=pytorch_estimator.model_data,\n",
    "              env=vllm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70715b-0513-4d56-bb34-6470965b013a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.name_from_base(\"L4-Scout-FineTuned\")\n",
    "\n",
    "print(endpoint_name)\n",
    "llm = model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=instance_type,\n",
    "        endpoint_name=endpoint_name,\n",
    "        container_startup_health_check_timeout = 1800\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c335fd8-cd0c-4be9-959a-c1f00b5d9e03",
   "metadata": {},
   "source": [
    "#### Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbabcac-8998-49b2-b0b9-57fd42a9b9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke the model\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "# Create SageMaker Runtime client\n",
    "smr_client = boto3.client('sagemaker-runtime')\n",
    "##Add your endpoint here \n",
    "#endpoint_name = ''\n",
    "\n",
    "# Invoke with messages format\n",
    "body = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Name popular places to visit in London?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 256,\n",
    "    \"stream\": True,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "first_token_received = False\n",
    "ttft = None\n",
    "token_count = 0\n",
    "full_response = \"\"\n",
    "\n",
    "print(f\"Prompt: {body['messages'][0]['content']}\\n\")\n",
    "print(\"Response:\", end=' ', flush=True)\n",
    "\n",
    "# Invoke endpoint with streaming\n",
    "resp = smr_client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(body),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "# Process streaming response\n",
    "for event in resp['Body']:\n",
    "    if 'PayloadPart' in event:\n",
    "        payload = event['PayloadPart']['Bytes'].decode()\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if payload.startswith('data: '):\n",
    "                data = json.loads(payload[6:])  # Skip \"data: \" prefix\n",
    "            else:\n",
    "                data = json.loads(payload)\n",
    "            \n",
    "            token_count += 1\n",
    "            if not first_token_received:\n",
    "                ttft = time.time() - start_time\n",
    "                first_token_received = True\n",
    "            \n",
    "            # Handle different streaming response formats\n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                # Messages-compatible format\n",
    "                if 'delta' in data['choices'][0] and 'content' in data['choices'][0]['delta']:\n",
    "                    token_text = data['choices'][0]['delta']['content']\n",
    "                    full_response += token_text\n",
    "                    print(token_text, end='', flush=True)\n",
    "            elif 'token' in data and 'text' in data['token']:\n",
    "                # TGI format\n",
    "                token_text = data['token']['text']\n",
    "                full_response += token_text\n",
    "                print(token_text, end='', flush=True)\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            # Skip invalid JSON\n",
    "            continue\n",
    "\n",
    "end_time = time.time()\n",
    "total_latency = end_time - start_time\n",
    "\n",
    "print(\"\\n\\nMetrics:\")\n",
    "print(f\"Time to First Token (TTFT): {ttft:.2f} seconds if tokens received else 'No tokens received'\")\n",
    "print(f\"Total Tokens Generated: {token_count}\")\n",
    "print(f\"Total Latency: {total_latency:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda29284-9150-47f2-b84a-7a97c631ea67",
   "metadata": {},
   "source": [
    "#### Delete endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69985f39-3bda-4eef-8412-5a095d9e2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Deleting SageMaker resources for endpoint: {endpoint_name}\")\n",
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
