{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4901509a-8316-47a3-879b-544a43b37ef3",
   "metadata": {},
   "source": [
    "# Best-practices for prompt engineering Text-to-SQL on Llama3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa596a49-ce47-4053-a93d-699bdef52426",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b488b5-d05b-45d2-84fb-6bc80cc30241",
   "metadata": {},
   "source": [
    "This notebook introduces a versatile approach that leverages Llama 3 models on Amazon Bedrock/Amazon SageMaker JumpStart, including advanced prompt engineering, to convert natural language questions into executable SQL queries. Our approach generates SQL queries capable of joining data from multiple tables, enabling information retrieval from complex database structures. This multi-table capability is crucial in real-world scenarios where data is often distributed across various tables with intricate relationships, and queries need to combine information from multiple sources to provide comprehensive insights.\n",
    "\n",
    "Moreover, our approach demonstrates high scalability through dynamically selecting and retrieving the most relevant table schemas based on the given natural language question. This scalability is achieved by employing intelligent schema matching algorithms powered by ChromaDB. ChromaDB analyzes the question and automatically identifies the appropriate tables and relationships required to construct the SQL query, eliminating the need for manual intervention.\n",
    "\n",
    "Our solution can be applied in practical scenarios where companies manage numerous databases with intricate table relationships, such as in the finance industry for analyzing customer transactions across multiple accounts and products, or in healthcare for integrating patient records from various systems and data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126d29c-4748-4831-8aff-60d71c61462e",
   "metadata": {},
   "source": [
    "---\n",
    "## Llama 3 Model Selection\n",
    "\n",
    "Today, there are two Llama 3 models available on Amazon Bedrock:\n",
    "\n",
    "### 1. Llama 3 8B\n",
    "\n",
    "- **Description:** Ideal for limited computational power and resources, faster training times, and edge devices.\n",
    "- **Max Tokens:** 2,048\n",
    "- **Context Window:** 8,196\n",
    "- **Languages:** English\n",
    "- **Supported Use Cases:** Synthetic Text Generation, Text Classification, and Sentiment Analysis.\n",
    "\n",
    "### 2. Llama 3 70B\n",
    "\n",
    "- **Description:** Ideal for content creation, conversational AI, language understanding, research development, and enterprise applications. \n",
    "- **Max Tokens:** 2,048\n",
    "- **Context Window:** 8,196\n",
    "- **Languages:** English\n",
    "- **Supported Use Cases:** Synthetic Text Generation and Accuracy, Text Classification and Nuance, Sentiment Analysis and Nuance Reasoning, Language Modeling, Dialogue Systems, and Code Generation.\n",
    "\n",
    "### Performance and Cost Trade-offs\n",
    "\n",
    "The table below compares the model performance on the Massive Multitask Language Understanding (MMLU) benchmark and their on-demand pricing on Amazon Bedrock.\n",
    "\n",
    "| Model           | MMLU Score | Price per 1,000 Input Tokens | Price per 1,000 Output Tokens |\n",
    "|-----------------|------------|------------------------------|-------------------------------|\n",
    "| Llama 3 8B | 68.4%      | \\$0.0004                   | \\$0.0006                    |\n",
    "| Llama 3 70B | 82.0%      | \\$0.00265                   | \\$0.0035                     |\n",
    "\n",
    "For more information, refer to the following links:\n",
    "\n",
    "1. [Llama 3 8B Model Cards and Prompt Formats](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3)\n",
    "2. [Amazon Bedrock Pricing Page](https://aws.amazon.com/bedrock/pricing/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd85684",
   "metadata": {},
   "source": [
    "## The Approach to the Text-to-SQL Problem\n",
    "This notebook covers the following approaches\n",
    "\n",
    "### Few-shot text-to-SQL (Single Table vs Multiple Tables)\n",
    "Few-shot text-to-SQL is an approach for querying databases by translating natural language questions into SQL queries, using only a few training examples.\n",
    "\n",
    "Providing just a few examples of natural language questions paired with the equivalent SQL queries allows models to learn the mapping from natural language to SQL.\n",
    "\n",
    "Reference : https://arxiv.org/abs/2305.12586\n",
    "\n",
    "### Few-shot text-to-SQL powered by ChromaDB (Schema Retrieval vs Schema Retrieval powered by ChromaDB)\n",
    "\n",
    "This approach leverages ChromaDB, a vector database, to assist the few-shot text-to-SQL translation process. ChromaDB can be used in two ways:\n",
    "\n",
    "1. **Schema Retrieval**: In this method, we provide manually the table schema within the prompt. When a natural language question is provided, the model uses the schema information to aid in generating the SQL query.\n",
    "\n",
    "2. **Schema Retrieval powered by ChromaDB**: In this method, ChromaDB stores the database schema information, which includes table names, column names, and their descriptions. When a natural language question is provided, the model can retrieve relevant schema information from ChromaDB to aid in generating the SQL query.\n",
    "\n",
    "By leveraging ChromaDB, the few-shot text-to-SQL translation process can benefit from efficient schema and sample data retrieval, potentially leading to better performance and generalization across different databases and query types.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058dceec",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "This notebook will provide code snippets to assist with implementing two differents approaches to converting a natural language question into a SQL query that would answer it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b33e6",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Getting Started](#getting-started)\n",
    "    + [Install Dependencies](#step-1-install-dependencies)\n",
    "    + [Setup Bedrock and Database](#step-2-set-up-bedrock-client-and-database-connection)\n",
    "    + [Build Database](#step-3-build-database)\n",
    "    + [Create Helper Functions](#step-4-create-helper-functions)\n",
    "1. [Few-Shot Text-to-SQL](#few-shot-text-to-sql)\n",
    "1. [Analyzing a Single Table with Few-Shot Learning](#analyzing-a-single-table-with-few-shot-learning)\n",
    "    + [Create a Few-Shot Prompt](#step-1-create-a-few-shot-prompt)\n",
    "    + [Execute Few-Shot Prompts](#step-2-execute-few-shot-prompts)\n",
    "1. [Analyzing Multiple Table with Few-Shot Learning](#analyzing-multiple-table-with-few-shot-learning)\n",
    "    + [Create a Few-Shot Prompt](#step-1-create-a-few-shot-prompt)\n",
    "    + [Execute Few-Shot Prompts](#step-2-execute-few-shot-prompts)\n",
    "1. [Limitations of Few-Shot Learning](#limitation-of-few-shot-learning)\n",
    "1. [Few-shot text-to-SQL powered by ChromaDB](#few-shot-text-to-sql-powered-by-chromadb)\n",
    "1. [Schema Retrieval](#schema-retrieval)\n",
    "    + [Data Preprocessing](#step-1-data-processing)\n",
    "    + [Ingest docs into ChromaDB](#step-2-ingest-docs-into-chromadb)\n",
    "    + [Create a Few-Shot Prompt](#step-3-create-a-few-shot-prompt)\n",
    "    + [Execute Few-Shot Prompts](#step-4-execute-few-shot-prompts)\n",
    "    + [Conclusion](#step-5-conclusion)\n",
    "1. [Enhanced Schema Retrieval with an Embedding Model](#enhanced-schema-retrieval-with-an-embedding-model)\n",
    "    + [Ingest docs into ChromaDB](#step-1-ingest-docs-into-chromadb)\n",
    "    + [Execute Few-Shot Prompts](#step-2-execute-few-shot-prompts)\n",
    "    + [Conclusion](#step-3-conclusion)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a20c2",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "+ AWS Python SDKs [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) to be able to submit API calls to [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "+ [LangChain](https://python.langchain.com/v0.1/docs/get_started/introduction/) is a framework that provides off the shelf components to make it easier to build applications with large language models. It is supported in multiple programming languages, such as Python, JavaScript, Java and Go. In this notebook, LangChain is used to build a prompt template.\n",
    "\n",
    "+ [ChromaDB](https://www.trychroma.com/) is a vector database that enables efficient semantic search, storage, and retrieval of unstructured data like text, images, and audio. It's designed to work well with large language models (LLMs) and provides a simple and scalable way to build applications that can search and retrieve relevant information from vast amounts of data.\n",
    "\n",
    "+ RDS (Relational Database Service) for [MySQL](https://aws.amazon.com/rds/mysql/) is a managed database service provided by Amazon Web Services (AWS). RDS for MySQL simplifies the setup, operation, and scaling of MySQL databases.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a6bb4",
   "metadata": {},
   "source": [
    "## Pre-requisites:\n",
    "\n",
    "1. Use kernel either `conda_python3`, `conda_pytorch_p310` or `conda_tensorflow2_p310`.\n",
    "2. Install the required packages.\n",
    "3. Access to the LLM API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd282c-e45f-463e-9f68-f80176f4f0af",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92d068-da09-4d98-97f6-d14e7b0b8f6f",
   "metadata": {},
   "source": [
    "In this notebook, Llama 3 70B is used. By deploying the notebook through our cloudformation template, it is granted the appropriate IAM permissions to send API request to Bedrock.\n",
    "\n",
    "Refer [here](https://aws.amazon.com/blogs/aws/metas-llama-3-models-are-now-available-in-amazon-bedrock/) for details on how Amazon Bedrock provides access to Meta’s Llama 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae4171-4f20-4a68-b6e1-0a40a3854de5",
   "metadata": {},
   "source": [
    "### SageMaker Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465f181-b661-4f59-bdac-92ed0e164203",
   "metadata": {},
   "source": [
    "#### Changing instance type\n",
    "---\n",
    "Models are supported on the following instance types:\n",
    "\n",
    " - Llama3 8B Text Generation: `ml.g5.2xlarge`, `ml.g5.4xlarge`, `ml.g5.8xlarge`, `ml.g5.12xlarge`, `ml.g5.24xlarge`, `ml.g5.48xlarge`, and `ml.p4d.24xlarge`\n",
    "- Llama3 70B Text Generation: `ml.g5.48xlarge`, and `ml.p4d.24xlarge`\n",
    " - BGE Large En v1.5: `ml.g5.2xlarge`, `ml.c6i.xlarge`,`ml.g5.4xlarge`, `ml.g5.8xlarge`, `ml.p3.2xlarge`, and `ml.g4dn.2xlarge`\n",
    "\n",
    "By default, the JumpStartModel class selects a default instance type available in your region. If you would like to use a different instance type, you can do so by specifying instance type in the JumpStartModel class.\n",
    "\n",
    "`my_model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.12xlarge\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be911213",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b2317-d90d-481f-8d51-464a93650978",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1f1bb-966d-4726-804c-b0d1f9108d8c",
   "metadata": {},
   "source": [
    "### Step 0: Select Hosting Model Service\n",
    "\n",
    "Here, you can select to run this notebook using SageMaker JumpStart or Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9f9044-79b0-4f76-9085-0f8c28568f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to run the LLM for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B)  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the LLM for this notebook using Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "def ask_for_service():\n",
    "    service = input(\"Do you want to run the LLM for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B) \").strip().upper()\n",
    "    if service in ['S', 'SAGEMAKER']:\n",
    "        return 'Amazon SageMaker'\n",
    "    elif service in ['B', 'BEDROCK', '']:\n",
    "        return 'Amazon Bedrock'\n",
    "    else:\n",
    "        print(\"Invalid input. Using Amazon Bedrock by default.\")\n",
    "        return 'Amazon Bedrock'\n",
    "\n",
    "# Call the function and get the selected service\n",
    "llm_selected_service = ask_for_service()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the LLM for this notebook using {llm_selected_service}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516b0617-6f4b-4344-b44d-8abf090b9c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to run the Embedding for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B)  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the Embedding for this notebook using Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "def ask_for_service():\n",
    "    service = input(\"Do you want to run the Embedding for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B) \").strip().upper()\n",
    "    if service in ['S', 'SAGEMAKER']:\n",
    "        return 'Amazon SageMaker'\n",
    "    elif service in ['B', 'BEDROCK', '']:\n",
    "        return 'Amazon Bedrock'\n",
    "    else:\n",
    "        print(\"Invalid input. Using Amazon Bedrock by default.\")\n",
    "        return 'Amazon Bedrock'\n",
    "\n",
    "# Call the function and get the selected service\n",
    "embedding_selected_service = ask_for_service()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the Embedding for this notebook using {embedding_selected_service}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c904c9df-7245-4c3b-98af-96298a61d1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if llm_selected_service == 'Amazon SageMaker':\n",
    "    # Import the JumpStartModel class from the SageMaker JumpStart library\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "    # Specify the model ID for the HuggingFace Llama 3 Instruct LLM model\n",
    "    llama3_8b_id = \"meta-textgeneration-llama-3-8b-instruct\"\n",
    "    llama3_70b_id = \"meta-textgeneration-llama-3-70b-instruct\"\n",
    "    DEFULT_LLM_MODEL_ID = llama3_70b_id\n",
    "    if DEFULT_LLM_MODEL_ID == llama3_70b_id:\n",
    "        instance_type = \"ml.g5.48xlarge\"\n",
    "    else:\n",
    "        instance_type = \"ml.g5.12xlarge\"\n",
    "    model = JumpStartModel(model_id=DEFULT_LLM_MODEL_ID, instance_type=instance_type)\n",
    "    llm_predictor = model.deploy(accept_eula=True)\n",
    "    print(f\"LLM SageMaker Endpoint Name: {llm_predictor.endpoint_name}\")\n",
    "else:\n",
    "    llm_predictor = None\n",
    "    llama3_8b_id = \"meta.llama3-8b-instruct-v1:0\"\n",
    "    llama3_70b_id = \"meta.llama3-70b-instruct-v1:0\"\n",
    "    DEFULT_LLM_MODEL_ID = llama3_70b_id\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "if embedding_selected_service == 'Amazon SageMaker':\n",
    "    # Import the JumpStartModel class from the SageMaker JumpStart library\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "    # Deploy BGE Large En embedding model on Amazon SageMaker JumpStart:\n",
    "    # Specify the model ID for the HuggingFace BGE Large EN Embedding model\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"huggingface-sentencesimilarity-bge-large-en\"\n",
    "    text_embedding_model = JumpStartModel(model_id=DEFAULT_EMBEDDING_MODEL_ID)\n",
    "    embedding_predictor = text_embedding_model.deploy()\n",
    "    print(f\"LLM SageMaker Endpoint Name: {embedding_predictor.endpoint_name}\")\n",
    "else:\n",
    "    embedding_predictor = None\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26350f6e-2ae8-40c0-86f2-626cc595af71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Install Dependencies\n",
    "\n",
    "Here, we will install all the required dependencies to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d52454-073b-4a5a-b293-924419e1c8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3==1.34.127 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install mysql-connector-python==8.4.0 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install langchain==0.2.5 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install chromadb==0.5.0 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install numpy==1.26.4 -qU --force --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a4385-1945-4358-ad33-a6d80c867d95",
   "metadata": {},
   "source": [
    "**Note:** *When installing libraries using the pip, you may encounter errors or warnings during the installation process. These are generally not critical and can be safely ignored. However, after installing the libraries, it is recommended to restart the kernel or computing environment you are working in. Restarting the kernel ensures that the newly installed libraries are loaded properly and available for use in your code or workflow.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f0206-1fe9-46a8-a6ff-c1fb3d045578",
   "metadata": {},
   "source": [
    "#### Now lets import the required modules to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756999dd-ac11-4b3a-8e43-2c4cdc2ad9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import chromadb\n",
    "from chromadb.api.types import (\n",
    "    Documents,\n",
    "    EmbeddingFunction,\n",
    "    Embeddings,\n",
    ")\n",
    "import json\n",
    "from langchain import PromptTemplate\n",
    "import mysql.connector as db\n",
    "import re\n",
    "from typing import Dict, List, Any\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703c9333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Bedrock Client\n",
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12765f-10a8-4aae-9e62-4ee7f4e526cc",
   "metadata": {},
   "source": [
    "### Step 2: Set up database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2493f9-833f-40ff-a9db-b81f47e37c66",
   "metadata": {},
   "source": [
    "Here, we retrieve the services that are already deployed as a part of the cloudformation template to be used in building the application. The services include,\n",
    "\n",
    "+ Secret ARN with RDS for MySQL Database credentials\n",
    "+ Database Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d355be7-9365-41d5-8f63-153898c7c169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackname = \"text2sql\"  # If your stack name differs from \"text2sql\", please provide your stack name here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca002c7-3416-4ac5-b9a1-2b730557fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "response = cfn.describe_stack_resources(\n",
    "    StackName=stackname\n",
    ")\n",
    "cfn_outputs = cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']\n",
    "\n",
    "# Get rds secret arn and database endpoint from cloudformation outputs\n",
    "for output in cfn_outputs:\n",
    "    if 'SecretArn' in output['OutputKey']:\n",
    "        rds_secret_id = output['OutputValue']\n",
    "\n",
    "    if 'DatabaseEndpoint' in output['OutputKey']:\n",
    "        db_host = output['OutputValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e5601b-287b-421e-8711-ef73d5c09cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secrets_client = boto3.client('secretsmanager')\n",
    "credentials = json.loads(secrets_client.get_secret_value(SecretId=rds_secret_id)['SecretString'])\n",
    "\n",
    "# Get password and username from secrets\n",
    "db_password = credentials['password']\n",
    "db_user = credentials['username']\n",
    "db_name = \"airline_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c970c8c-f566-430f-b12b-e669cc7241eb",
   "metadata": {},
   "source": [
    "Establish the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705ab665-9b2e-4141-b7fb-df3329ac61c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_conn = db.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5934167-da56-48c4-905a-51f515d8f680",
   "metadata": {},
   "source": [
    "#### Use this section to check all the databases already in your test database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49eb5c2b-a0a0-49dc-8c4a-4742576f6756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_cursor = db_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09ede071-2cdc-4f0c-9042-5acb59909459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sys',)\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(\"SHOW DATABASES\")\n",
    "\n",
    "for tmp_db_name in db_cursor:\n",
    "    print(tmp_db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a8a54-2782-4c4f-8524-6fef2cfa880a",
   "metadata": {},
   "source": [
    "### Step 3: Build Database\n",
    "Now the notebook will drop the test table and also the test database if it exists. It then proceeds with creation of the table.\n",
    "Then it will insert test data for use in our prompting examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cb5ef-41ea-43d9-ace9-8ca9c2dda260",
   "metadata": {},
   "source": [
    "#### Load table schema settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2579b20a-eb9c-4146-88e7-d4936d8d3038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_settings(file_path):\n",
    "    \"\"\"\n",
    "    Reads a YAML file and returns its contents as a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the YAML file.\n",
    "\n",
    "    Returns:\n",
    "        obj: The contents of the YAML file as a Python object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(f\"Error: Failed to parse the YAML file '{file_path}': {exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcf569e-6c76-4eee-8be7-cc0ab13a3802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load table settings\n",
    "settings_airplanes = load_settings('schemas/airplanes.yml')\n",
    "table_airplanes = settings_airplanes['table_name']\n",
    "table_schema_airplanes = settings_airplanes['table_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ccb4cc8-dc2a-4d21-9946-1308cc7720f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load table settings\n",
    "settings_flights = load_settings('schemas/flights.yml')\n",
    "table_flights = settings_flights['table_name']\n",
    "table_schema_flights = settings_flights['table_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f08ee4d0-58c3-4585-a6c3-21c8e1247177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load table settings\n",
    "settings_airplane_flights = load_settings('schemas/airplanes-flights.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d18b1b-a668-4090-93b9-6a286bae3fe7",
   "metadata": {},
   "source": [
    "#### Clean up database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874cf1ed-bc91-4c5b-88d8-e38d3eae3d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete flights' table\n",
    "db_cursor.execute(f\"DROP TABLE IF EXISTS {db_name}.{table_flights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bb95a58-1630-4ae7-ab97-a8b91be00f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete airplanes' table\n",
    "db_cursor.execute(f\"DROP TABLE IF EXISTS {db_name}.{table_airplanes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b928c6-181c-4bcc-84b6-728aaf261052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete database\n",
    "db_cursor.execute(f\"DROP DATABASE IF EXISTS {db_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f396b2e-b25b-4192-82e5-cf5e5e2f128c",
   "metadata": {},
   "source": [
    "#### Create database and tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e78bdc-c26d-4029-907b-8d9768d9e501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create database `airline_db`\n",
    "db_cursor.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "544ac0d2-4158-4041-bc6d-09b458f60364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table to hold data on fictitious airplanes information called `airplanes`\n",
    "db_cursor.execute(table_schema_airplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65069b84-b9ec-468e-a0fb-138e89e55682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table to hold data on fictitious flights information called `flights`\n",
    "db_cursor.execute(table_schema_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01ebc7-2ac0-412b-8984-e79651661f0a",
   "metadata": {},
   "source": [
    "#### Read sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8405e146-790e-46f8-9c1b-6d38319d7ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read sample data for the airplanes' table\n",
    "with open('sample_data/airplanes.json', 'r') as f:\n",
    "    data_airplanes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050ca63b-6081-4b16-812e-4cac4eb46418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read sample data for the flights' table\n",
    "with open('sample_data/flights.json', 'r') as f:\n",
    "    data_flights = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a902c",
   "metadata": {},
   "source": [
    "#### Ingest sample data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b525973-4700-4c2d-8f5f-7c213ccc5a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert airplanes' data into database\n",
    "for data in data_airplanes:\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO {db_name}.{table_airplanes} \n",
    "        (Airplane_id, Producer, Type) \n",
    "        VALUES (\n",
    "        {data['Airplane_id']},\n",
    "        '{data['Producer']}',\n",
    "        '{data['Type']}'\n",
    "        )\n",
    "        \"\"\"\n",
    "    db_cursor.execute(sql)\n",
    "db_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bea4d6e-714e-48af-8141-3911f762a336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert flights' data into database\n",
    "for data in data_flights:\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO {db_name}.{table_flights}\n",
    "        (Flight_number, Arrival_time, Arrival_date, Departure_time, Departure_date, Destination, Airplane_id) \n",
    "        VALUES (\n",
    "        '{data['Flight_number']}',\n",
    "        '{data['Arrival_time']}',\n",
    "        '{data['Arrival_date']}',\n",
    "        '{data['Departure_time']}',\n",
    "        '{data['Departure_date']}',\n",
    "        '{data['Destination']}',\n",
    "        {data['Airplane_id']}\n",
    "        )\n",
    "        \"\"\"\n",
    "    db_cursor.execute(sql)\n",
    "db_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714660a4",
   "metadata": {},
   "source": [
    "Verify our database connection works and we can retrieve records from our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9792a67b-591b-4364-8caa-10ecb3ba70d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Boeing', '737')\n",
      "(2, 'Airbus', 'A320')\n",
      "(3, 'Embraer', 'E195')\n",
      "(4, 'Bombardier', 'CRJ900')\n",
      "(5, 'Boeing', '777')\n",
      "(6, 'Airbus', 'A330')\n",
      "(7, 'Embraer', 'E175')\n",
      "(8, 'Bombardier', 'Q400')\n",
      "(9, 'Boeing', '787')\n",
      "(10, 'Airbus', 'A350')\n",
      "(11, 'Embraer', 'E190')\n",
      "(12, 'Bombardier', 'CRJ700')\n",
      "(13, 'Boeing', '757')\n",
      "(14, 'Airbus', 'A380')\n",
      "(15, 'Embraer', 'E170')\n",
      "(16, 'Bombardier', 'CRJ200')\n",
      "(17, 'Boeing', '747')\n",
      "(18, 'Airbus', 'A321')\n",
      "(19, 'Embraer', 'E145')\n",
      "(20, 'Bombardier', 'CRJ1000')\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(f\"SELECT * FROM {db_name}.{table_airplanes}\")\n",
    "sql_data = db_cursor.fetchall()\n",
    "\n",
    "for record in sql_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b1c3fd3-aac8-41d4-8790-e7a770e309f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AA123', '2023-06-15T10:30:00', '2023-06-15', '2023-06-15T08:00:00', '2023-06-15', 'Los Angeles', 1)\n",
      "('AA234', '2023-07-02T21:15:00', '2023-07-02', '2023-07-02T18:30:00', '2023-07-02', 'Tampa', 20)\n",
      "('AA890', '2023-06-24T18:40:00', '2023-06-24', '2023-06-24T16:10:00', '2023-06-24', 'Atlanta', 5)\n",
      "('AS345', '2023-06-19T21:00:00', '2023-06-19', '2023-06-19T18:30:00', '2023-06-19', 'Seattle', 7)\n",
      "('AS789', '2023-06-27T15:50:00', '2023-06-27', '2023-06-27T13:20:00', '2023-06-27', 'Phoenix', 7)\n",
      "('DL123', '2023-06-25T22:00:00', '2023-06-25', '2023-06-25T19:30:00', '2023-06-25', 'Las Vegas', 10)\n",
      "('DL345', '2023-06-29T07:30:00', '2023-06-29', '2023-06-29T05:00:00', '2023-06-29', 'Philadelphia', 6)\n",
      "('DL567', '2023-07-03T09:40:00', '2023-07-03', '2023-07-03T07:10:00', '2023-07-03', 'San Diego', 19)\n",
      "('DL789', '2023-06-17T18:20:00', '2023-06-17', '2023-06-17T16:00:00', '2023-06-17', 'Miami', 10)\n",
      "('DL901', '2023-06-21T13:20:00', '2023-06-21', '2023-06-21T10:50:00', '2023-06-21', 'Boston', 6)\n",
      "('JB012', '2023-06-28T20:15:00', '2023-06-28', '2023-06-28T17:45:00', '2023-06-28', 'Orlando', 8)\n",
      "('JB678', '2023-06-20T07:45:00', '2023-06-20', '2023-06-20T05:15:00', '2023-06-20', 'San Francisco', 8)\n",
      "('SW234', '2023-06-22T16:35:00', '2023-06-22', '2023-06-22T14:05:00', '2023-06-22', 'Dallas', 3)\n",
      "('SW678', '2023-06-30T12:45:00', '2023-06-30', '2023-06-30T10:15:00', '2023-06-30', 'Detroit', 3)\n",
      "('UA456', '2023-06-16T14:45:00', '2023-06-16', '2023-06-16T12:15:00', '2023-06-16', 'New York', 6)\n",
      "('UA567', '2023-06-23T09:15:00', '2023-06-23', '2023-06-23T06:45:00', '2023-06-23', 'Houston', 9)\n",
      "('UA901', '2023-07-01T17:00:00', '2023-07-01', '2023-07-01T14:30:00', '2023-07-01', 'Minneapolis', 9)\n",
      "('WN012', '2023-06-18T11:10:00', '2023-06-18', '2023-06-18T09:30:00', '2023-06-18', 'Chicago', 2)\n",
      "('WN456', '2023-06-26T11:25:00', '2023-06-26', '2023-06-26T08:55:00', '2023-06-26', 'Denver', 2)\n",
      "('WN890', '2023-07-04T14:20:00', '2023-07-04', '2023-07-04T11:50:00', '2023-07-04', 'Salt Lake City', 18)\n"
     ]
    }
   ],
   "source": [
    "db_cursor.execute(f\"SELECT * FROM {db_name}.{table_flights}\")\n",
    "sql_data = db_cursor.fetchall()\n",
    "\n",
    "for record in sql_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf28a8-0d22-4223-989b-243431149e22",
   "metadata": {},
   "source": [
    "### Step 4: Create helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae6aca-18fb-4beb-a6ae-caaeea512d1e",
   "metadata": {},
   "source": [
    "To facilate the usability and readability of the SQL Query Analysis made by Llama 3, we have developed a suite of helper functions tailored to various use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b445fc-da02-477e-a6b6-26848c44a727",
   "metadata": {},
   "source": [
    "The `format_instructions` function is designed to process the input from Llama 3 models, allowing a conversation between roles such as `system`, `user`, and `assistant`. To see more details about Llama 3 prompt formats, click [here](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7912ce9e-598c-47db-9780-b1cc95408f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_instructions(instructions: List[Dict[str, str]]) -> List[str]:\n",
    "    \"\"\"Format instructions where conversation roles must alternate system/user/assistant/user/assistant/...\"\"\"\n",
    "    prompt: List[str] = []\n",
    "    for instruction in instructions:\n",
    "        if instruction[\"role\"] == \"system\":\n",
    "            prompt.extend([\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \"<|eot_id|>\"])\n",
    "        elif instruction[\"role\"] == \"user\":\n",
    "            prompt.extend([\"<|start_header_id|>user<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \"<|eot_id|>\"])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid role: {instruction['role']}. Role must be either 'user' or 'system'.\")\n",
    "    prompt.extend([\"<|start_header_id|>assistant<|end_header_id|>\\n\"])\n",
    "    return \"\".join(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0097cde-7a98-4e3e-a0dc-5f8c7c551c8f",
   "metadata": {},
   "source": [
    "The `execute_query` function will execute SQL queries, typically for retrieving data from a database, and format the results as a string for further processing or display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9401ba7a-de43-410d-8015-a38a60f2b6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query: str) -> str:\n",
    "    \"\"\"Execute an SQL query on the database connection and return the results as a string.\n",
    "\n",
    "    Args:\n",
    "        query (str): SQL query to execute\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the SQL results.\n",
    "    \"\"\"\n",
    "    # Get a cursor from the database connection\n",
    "    mycursor = db_conn.cursor()\n",
    "\n",
    "    # Execute the SQL query\n",
    "    mycursor.execute(query)\n",
    "\n",
    "    # Fetch all result rows\n",
    "    result_rows = mycursor.fetchall()\n",
    "\n",
    "    # Convert result to string with newline between rows\n",
    "    output_text = '\\n'.join([str(x) for x in result_rows])\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaedc7-f395-4d92-9809-8f7b71baa42f",
   "metadata": {},
   "source": [
    "The `sagemaker_chat_completion` function uses the SageMaker Endpoint to invoke the LLMs. The response from the LLM is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62b4863f-ff81-4f02-8c25-7f0d50f99d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sagemaker_chat_completion(\n",
    "    prompt: str,\n",
    "    max_gen_len: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a prompt using the llama3 model via Amazon SageMaker JumpStart.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text to generate completions for.\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": max_gen_len,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"stop\": [\"<|eot_id|>\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Call the model API to generate the completion\n",
    "    response = llm_predictor.predict(body)\n",
    "    completion = response.get('generated_text', '')\n",
    "\n",
    "    return completion.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6babb4b-812d-415f-b666-b1f69fc28706",
   "metadata": {},
   "source": [
    "The `bedrock_chat_completion` function uses the Bedrock client to invoke the LLMs. The response from the LLM is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c11b382-cf2d-4df9-971c-dc92c9a13043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bedrock_chat_completion(\n",
    "    model_id: str,\n",
    "    prompt: str,\n",
    "    max_gen_len: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a prompt using the llama3 model via Amazon Bedrock.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The ID of the llama3 model to use for completion.\n",
    "        prompt (str): The prompt text to generate completions for.\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_gen_len\": max_gen_len,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "    }\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    # Convert the body dictionary to JSON string and encode it as bytes\n",
    "    body_json = json.dumps(body)\n",
    "    body_bytes = body_json.encode('utf-8')\n",
    "\n",
    "    # Call the model API to generate the completion\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body_bytes, modelId=model_id, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = response[\"body\"].read()\n",
    "    response_body = json.loads(response_body)\n",
    "    completion = response_body.get(\"generation\", \"\")\n",
    "\n",
    "    return completion.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997f36-a08b-4189-ba98-a410d9063e41",
   "metadata": {},
   "source": [
    "The Function `get_llm_sql_analysis` generates and executes an SQL query for a given question, and returns a comprehensive analyzes based on the sql query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e8610a-69e9-452b-a3cc-42f6e3129709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_llm_sql_analysis(question: str, sql_sys_prompt: str, qna_sys_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an SQL query based on the given question, executes it, and returns an analysis of the results using Llama 3.\n",
    "\n",
    "    Args:\n",
    "        question (str): The input question for which an SQL query needs to be generated.\n",
    "        sql_sys_prompt (str): The prompt to be used for generating the SQL query using Llama 3.\n",
    "        qna_sys_prompt (str): The prompt to be used for analyzing the SQL query results using Llama 3.\n",
    "\n",
    "    Returns:\n",
    "        str: The analysis of the SQL query results provided by the language model.\n",
    "    \"\"\"\n",
    "    if llm_selected_service == 'Amazon SageMaker':\n",
    "        # Generates SQL query\n",
    "        completion = sagemaker_chat_completion(\n",
    "            prompt=sql_sys_prompt\n",
    "        )\n",
    "    else:\n",
    "        # Generates SQL query\n",
    "        completion = bedrock_chat_completion(\n",
    "            model_id=DEFULT_LLM_MODEL_ID,\n",
    "            prompt=sql_sys_prompt\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Extract the SQL query\n",
    "        pattern = r\"<sql>(.*)</sql>\"\n",
    "        llm_sql_query = re.search(pattern, completion, re.DOTALL).group(1)\n",
    "        print(f\"LLM SQL Query: \\n{llm_sql_query}\")\n",
    "\n",
    "        # Execute SQL query\n",
    "        sql_results = execute_query(llm_sql_query)\n",
    "\n",
    "        if llm_selected_service == 'Amazon SageMaker':\n",
    "            # Generates SQL analysis\n",
    "            llm_sql_analysis = sagemaker_chat_completion(\n",
    "                prompt=qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "            )\n",
    "        else:\n",
    "            # Generates SQL analysis\n",
    "            llm_sql_analysis = bedrock_chat_completion(\n",
    "                model_id=DEFULT_LLM_MODEL_ID,\n",
    "                prompt=qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "            )\n",
    "\n",
    "        print(f\"LLM SQL Analysis: \\n{llm_sql_analysis}\")\n",
    "        return llm_sql_analysis\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb825ee-8996-433b-b879-0f2581055ec4",
   "metadata": {},
   "source": [
    "The Class `AmazonBedrockEmbeddingFunction` initializes an embedding function with `Amazon Titan Embedding Model V2` that integrates with ChromaDB . This class can be further extended to add support for other embedding models available on Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df8dfb0a-0b02-444b-b8a1-67ec98772a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonBedrockEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        session: \"boto3.Session\",\n",
    "        model_name: str = \"amazon.titan-embed-text-v2:0\",\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize AmazonBedrockEmbeddingFunction.\n",
    "\n",
    "        Args:\n",
    "            session (boto3.Session): The boto3 session to use.\n",
    "            model_name (str, optional): Identifier of the model, defaults to \"amazon.titan-embed-text-v1\"\n",
    "            **kwargs: Additional arguments to pass to the boto3 client.\n",
    "\n",
    "        Example:\n",
    "            >>> import boto3\n",
    "            >>> session = boto3.Session(profile_name=\"profile\", region_name=\"us-east-1\")\n",
    "            >>> bedrock = AmazonBedrockEmbeddingFunction(session=session)\n",
    "            >>> texts = [\"Hello, world!\", \"How are you?\"]\n",
    "            >>> embeddings = bedrock(texts)\n",
    "        \"\"\"\n",
    "\n",
    "        self._model_name = model_name\n",
    "\n",
    "        self._client = session.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        accept = \"*/*\"\n",
    "        content_type = \"application/json\"\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            input_body = {\"inputText\": text, \"dimensions\": 512, \"normalize\": True}\n",
    "            body = json.dumps(input_body)\n",
    "            response = self._client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=self._model_name,\n",
    "                accept=accept,\n",
    "                contentType=content_type,\n",
    "            )\n",
    "            embedding = json.load(response.get(\"body\")).get(\"embedding\")\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47479bba-58f5-4906-89d7-9eb688588192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonSageMakerEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize AmazonSageMakerEmbeddingFunction.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Additional arguments to pass to the sagemaker embedding function.\n",
    "\n",
    "        Example:\n",
    "            >>> sagemaker = AmazonBedrockEmbeddingFunction()\n",
    "            >>> text_inputs = [\"Hello, world!\", \"How are you?\"]\n",
    "            >>> embeddings = sagemaker(texts)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        accept = \"application/json\"\n",
    "        content_type = \"application/json\"\n",
    "\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            input_body = {\"text_inputs\": text, \"mode\": \"embedding\"}\n",
    "            body = json.dumps(input_body).encode('utf-8')\n",
    "            response = embedding_predictor.predict(\n",
    "                body,\n",
    "                {\n",
    "                    \"ContentType\": content_type,\n",
    "                    \"Accept\": accept,\n",
    "                }\n",
    "            )\n",
    "            embedding = response.get(\"embedding\")\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909b559-22a3-41ff-99d3-96796458dd44",
   "metadata": {},
   "source": [
    "## Few-Shot Text-to-SQL\n",
    "With our database and tables filled with data, we're now ready to walk through the Few-Shot Text-to-SQL approach. We'll start by building some helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccf1fe-ed1a-42f7-885c-8f12a8d15aca",
   "metadata": {},
   "source": [
    "## Analyzing a Single Table with Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e4c5a",
   "metadata": {},
   "source": [
    "### Step 1: Create a Few-Shot Prompt\n",
    "Here, we design our prompt template that will account for our question and answer, and formatted correctly for use with Llama 3 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ea8a0-61e8-4eee-a14a-71e9d6ec303d",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing two parts:\n",
    "\n",
    "1. `table_schema`. This is a description of the structure of the database table, including the name of the table, the names of the columns within each table, and the data types of each column. This information helps Llama 3 to understand the organization and contents of the table.\n",
    "\n",
    "2. `question`. This is the specific request or information that the user wants to obtain from the table.\n",
    "\n",
    "By including both the table schema and the user's question in the system prompt, we provide Llama 3 model a complete understanding of the table structure and the user's desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9528d11-a02e-436d-a06c-b40639dce4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a mysql query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schema:\n",
    "<table_schema>\n",
    "{table_schema}\n",
    "<table_schema>\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "tmp_sql_sys_prompt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb4eb9-d15c-4453-8053-4d80813794c0",
   "metadata": {},
   "source": [
    "Next, we create a new `system prompt` containing two parts:\n",
    "\n",
    "1. `query_results` represents the SQL query results after executing the prompt `tmp_sql_sys_prompt`. This is the raw data that Llama 3 model will use to generate its analysis.\n",
    "\n",
    "2. `question`. This specifies the type of analysis or insight that the user wants Llama 3 model to provide based on the SQL query results.\n",
    "\n",
    "By combining the SQL query results and the user's question into a single system prompt, we provide Llama 3 model all the information it needs to understand the context and provide a comprehensive analysis tailored to the user's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62c5e5b2-13b1-4f70-9484-56b2ef618cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Given the following SQL query results:\n",
    "{query_results}\n",
    "\n",
    "And the original question:\n",
    "{question}\n",
    "\n",
    "Please provide an analysis and interpretation of the results to answer the original question.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "QNA_SYS_PROMPT = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97db613",
   "metadata": {},
   "source": [
    "Building on our last prompt, we'll now add a Single Shot example to our context to better hint the model what we expect for a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de41022-e8fa-423e-a35b-92537e8dfd21",
   "metadata": {},
   "source": [
    "### Step 2: Execute Few Shot Prompts\n",
    "The following cells will demonstrate different questions asked in natural language and the SQL generated by the LLM. The output is contained between the `<sql>` and `</sql>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6617123b-78ea-4631-9871-30c01c7a888a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM SQL Query: \n",
      "SELECT COUNT(*) FROM airline_db.airplanes;\n",
      "LLM SQL Analysis: \n",
      "A simple yet straightforward question!\n",
      "\n",
      "Let's analyze the SQL query results:\n",
      "\n",
      "The result is a single row with a single column containing the value `20`.\n",
      "\n",
      "This suggests that the SQL query was designed to count the total number of airplanes in the database. The query likely used a `COUNT` aggregation function to tally up the number of rows in a table related to airplanes.\n",
      "\n",
      "Given this result, we can confidently answer the original question:\n",
      "\n",
      "**The total count of airplanes is 20.**\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schema=table_schema_airplanes\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e9395-5c48-4880-a80e-4874786b7ab1",
   "metadata": {},
   "source": [
    "## Analyzing Multiple Table with Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad7c5d-98a8-4079-b668-29347c563bef",
   "metadata": {},
   "source": [
    "### Step 1: Create a Few-Shot Prompt\n",
    "Now, let's try the same approach using two tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea14d6-539f-442a-85fd-e32dd02abb44",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing the same placeholders as before and including two table schemas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92b4a07c-3762-411b-a0ab-a94c8df3d96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a mysql query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schemas:\n",
    "<table_schemas>\n",
    "<table_schema>\n",
    "{table_schema1}\n",
    "<table_schema>\n",
    "\n",
    "<table_schema>\n",
    "{table_schema2}\n",
    "<table_schema>\n",
    "<table_schemas>\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "tmp_sql_sys_prompt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cead15-002f-4b53-9d9f-da3b4ac94db8",
   "metadata": {},
   "source": [
    "### Step 2: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abce7627-60c2-432b-af9c-beabbe86be54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM SQL Query: \n",
      "\n",
      "SELECT a.Producer, COUNT(f.Flight_number) AS Total_Flights\n",
      "FROM airline_db.airplanes a\n",
      "JOIN airline_db.flights f ON a.Airplane_id = f.Airplane_id\n",
      "GROUP BY a.Producer;\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can analyze and interpret the data to answer the original question:\n",
      "\n",
      "**Original Question:** What is the total count of flights per producer?\n",
      "\n",
      "**Results:**\n",
      "\n",
      "1. Boeing: 4 flights\n",
      "2. Airbus: 8 flights\n",
      "3. Embraer: 5 flights\n",
      "4. Bombardier: 3 flights\n",
      "\n",
      "**Analysis and Interpretation:**\n",
      "\n",
      "The results show the count of flights for each aircraft producer. To answer the original question, we can simply add up the counts for each producer to get the total count of flights:\n",
      "\n",
      "**Total Count of Flights:** 4 (Boeing) + 8 (Airbus) + 5 (Embraer) + 3 (Bombardier) = **20 flights**\n",
      "\n",
      "Therefore, the total count of flights per producer is 20 flights.\n",
      "\n",
      "Additionally, we can observe the following insights from the results:\n",
      "\n",
      "* Airbus has the highest number of flights (8), followed by Embraer (5) and Boeing (4).\n",
      "* Bombardier has the lowest number of flights (3).\n",
      "\n",
      "These insights can be useful for further analysis or decision-making related to the aircraft producers and their flight operations.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of flights per producer?\"\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schema1=table_schema_airplanes,\n",
    "    table_schema2=table_schema_flights\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518e52c-5ac3-4682-8cb6-921039ffa2d0",
   "metadata": {},
   "source": [
    "## Limitations of Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfcd94-8b32-4cc3-b0cc-7425105958a7",
   "metadata": {},
   "source": [
    "Few-Shot Learning for text-to-SQL tasks, where a language model is trained on a limited number of examples to translate natural language queries into SQL queries, faces significant limitations. One of the key challenges is selecting the appropriate table schema that aligns with the user's question.\n",
    "\n",
    "In a real-world scenario, databases often consist of numerous tables with intricate relationships, making it difficult for the model to identify the relevant tables and columns required to answer a given query accurately. \n",
    "\n",
    "To address this issue, we propose incorporating ChromaDB to facilitate the retrieval of table schemas that are tailored to the user's question.\n",
    "\n",
    "Here's how ChromaDB can help overcome the table schema selection challenge:\n",
    "\n",
    "**Table Schema Retrieval**: Each table schema in the database can be converted into a dense vector embedding, capturing its structural information and relationships. The top-ranked table schemas are retrieved and provided as input to the text-to-SQL model, significantly increasing the likelihood of generating accurate SQL queries.\n",
    "\n",
    "We will review this approach further in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366f9d5-f0ca-4008-a8be-04ab47b22779",
   "metadata": {},
   "source": [
    "## Few-shot text-to-SQL powered by ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73cdbb-e062-4d04-981d-ae92ec7e71fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, we will use ChromaDB and the few-shot technique to effeciently retrieve table schemas for better performance and generalization across different databases and query types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765c200-7f94-4044-97ca-4681d5058d6b",
   "metadata": {},
   "source": [
    "## Schema Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf41750-066b-40f5-a4f2-407acec7da60",
   "metadata": {},
   "source": [
    "In this approach, we will store only the table schemas in ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70751dc4-6b3d-45b8-838d-908cd26684ab",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing\n",
    "\n",
    "The first step is to preprocess the data and create a document that will be ingested into ChromaDB. The final doc clearly separates the table schemas by using XML tags such as `<table_schema></table_schema>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8f8888c-2a37-4a0c-8949-baaa24815ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc1 = \"<table_schemas>\\n\"\n",
    "doc1 += f\"<table_schema>\\n {settings_airplanes['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "doc1 += \"\\n</table_schemas>\"\n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d550e81-9156-4d78-b5f6-661f8e065000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc2 = \"<table_schemas>\\n\"\n",
    "doc2 += f\"<table_schema>\\n {settings_flights['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "doc2 += \"\\n</table_schemas>\"\n",
    "print(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "083c5523-020d-46c4-a2fa-2dcc4dd4a1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc3 = \"<table_schemas>\\n\"\n",
    "for table_schema in settings_airplane_flights['table_schemas']:\n",
    "    doc3 += f\"<table_schema>\\n {table_schema} \\n</table_schema>\\n\"\n",
    "doc3 += \"\\n</table_schemas>\".strip()\n",
    "print(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad09a7-e39e-48fe-a4af-e4e573aa8d24",
   "metadata": {},
   "source": [
    "### Step 2: Ingest docs into ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b088a-846e-4ca2-842f-5ff1c6897b26",
   "metadata": {},
   "source": [
    "After the data is preprocessed, the next step is to ingest all `docs` into ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cea1d14-515d-483c-83a5-ac7a5d0f0c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Chroma in-memory, for easy prototyping.\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa0f60b6-e292-4a6c-b900-bcb2ab4e54b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create collection using ChromaDB's internal embedding function\n",
    "collection1 = chroma_client.create_collection(name=\"table-schemas-default-embedding\", metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "619eb8a2-dc67-42ec-8156-408117e8253d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 58.6MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Add docs to the collection.\n",
    "collection1.add(\n",
    "    documents=[\n",
    "        doc1,\n",
    "        doc2,\n",
    "        doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_airplanes},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_flights},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": f\"{table_airplanes}-{table_flights}\" }\n",
    "    ],\n",
    "    ids=[table_airplanes, table_flights, f\"{table_airplanes}-{table_flights}\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7669-6cd2-485f-8d41-44fb3526c86e",
   "metadata": {},
   "source": [
    "### Step 3: Create a Few-Shot Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588156e2-5b35-4828-a3ca-e077f2c542ac",
   "metadata": {},
   "source": [
    "Now, we'll use a few-shot approach using the retrieved tables from ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbb802-9437-47b5-b728-9e2e7c9a64df",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing a placeholder including any number of table schemas for ChromaDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc0758c4-7710-43af-ad4f-e1a3123f685a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a mysql query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schemas:\n",
    "<table_schemas>\n",
    "{table_schemas}\n",
    "<table_schemas>\n",
    "\n",
    "Always combine the database name and table name to build your queries. You must identify these two values before proving a valid SQL query.\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "tmp_sql_sys_prompt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc134b9c-96de-47b7-a182-664024d0b2a8",
   "metadata": {},
   "source": [
    "### Step 4: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977f101-cd0b-4ab4-bc6e-85bf3d759f1d",
   "metadata": {},
   "source": [
    "In this example, we expect the table `airplanes` to be used for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8853827-1d81-4ef4-befc-d2f55d52314a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(DISTINCT Airplane_id) FROM airline_db.flights;\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, we can see that the output is a single row with a single column containing the value 12.\n",
      "\n",
      "This suggests that the SQL query was designed to count the total number of airplanes in the database, and the result is 12.\n",
      "\n",
      "Therefore, the answer to the original question \"What is the total count of airplanes?\" is:\n",
      "\n",
      "There are 12 airplanes.\n",
      "\n",
      "In other words, the database contains 12 records or entries related to airplanes.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection1.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d524f72-c687-49a0-8dbc-21476fbcedcd",
   "metadata": {},
   "source": [
    "### Step 5: Insights and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2970425-61a7-489d-b133-3cbf0d6e85b9",
   "metadata": {},
   "source": [
    "We can observe that ChromaDB was unable to retrieve the correct table schema for the \"airplanes\" table. The issue arose due to a confusion caused by a foreign key reference. Specifically, ChromaDB retrieved the \"flights\" table instead of the \"airplanes\" table because the \"flights\" table contains a field called \"Airplane_id\" which references the \"airplanes\" table as a foreign key. This foreign key reference led to the confusion, resulting in ChromaDB retrieving the wrong table.\n",
    "\n",
    "To mitigate this issue, we will use a more robust embedding model like the `Amazon Titan Embedding Model`.\n",
    "\n",
    "We will see this in action in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a5731-2f4c-46f0-b03a-c417338064ed",
   "metadata": {},
   "source": [
    "## Enhanced Schema Retrieval with an Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c58d4-9330-438a-9aa6-72340fdc4b64",
   "metadata": {},
   "source": [
    "In this approach, we will use an embedding model from AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee69c27-b639-4380-9f32-356f18b55584",
   "metadata": {},
   "source": [
    "### Step 1: Ingest docs into ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746786d7-8ab0-4b99-b57e-efdba7f1131c",
   "metadata": {
    "tags": []
   },
   "source": [
    "After the data is preprocessed, the next step is to ingest all `docs` into ChromaDB using your selected embedding model (`Amazon SageMaker BGE Large English` or `Amazon Titan Embedding V2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ea54fec-5074-44bc-bff5-b5b1e7e4a4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create embedding function with AWS\n",
    "if embedding_selected_service == \"Amazon SageMaker\":\n",
    "    aws_ef = AmazonSageMakerEmbeddingFunction()\n",
    "else:\n",
    "    session = boto3.Session()\n",
    "    aws_ef = AmazonBedrockEmbeddingFunction(\n",
    "        session=session,\n",
    "        model_name=DEFAULT_EMBEDDING_MODEL_ID\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3ca323c-68c2-41cb-afbc-03fece3db46b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create collection using Amazon Titan Embedding model\n",
    "collection2 = chroma_client.create_collection(name=\"table-schemas-aws-embedding-model\", embedding_function=aws_ef, metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa251e61-7f75-4c96-9faf-397a785fdcc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add docs to the collection.\n",
    "collection2.add(\n",
    "    documents=[\n",
    "        doc1,\n",
    "        doc2,\n",
    "        doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_airplanes},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": table_flights},\n",
    "        {\"source\": \"mysql\", \"database\": db_name, \"table_name\": f\"{table_airplanes}-{table_flights}\" }\n",
    "    ],\n",
    "    ids=[table_airplanes, table_flights, f\"{table_airplanes}-{table_flights}\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec741334-b2ac-4d27-b11e-ee365dadf0fe",
   "metadata": {},
   "source": [
    "### Step 2: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265c0a3-40d9-482b-98ff-1077b358cecd",
   "metadata": {},
   "source": [
    "In this example, we expect the table `airplanes` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2b9a734-4898-4e00-9df1-af448acb5424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(*) FROM airline_db.airplanes;\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, we can see that the output is a single value: `(20)`.\n",
      "\n",
      "This suggests that the SQL query was designed to count the total number of airplanes in a database table. The result `(20)` indicates that there are **20 airplanes** in the table.\n",
      "\n",
      "Therefore, the answer to the original question \"What is the total count of airplanes?\" is **20**.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86a1b-087f-46c8-8509-5385299e9832",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this second example, we expect the table `airplanes` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0a9fffb-4ebb-4c89-a41f-6e74dc214bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(DISTINCT Producer) FROM airline_db.airplanes;\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, which show a single value of `(4)`, we can conclude that there are **4 unique airplane producers** represented in the database.\n",
      "\n",
      "This result suggests that the database contains information about airplanes from 4 distinct manufacturers or producers. This could be useful information for various purposes, such as market analysis, sales tracking, or maintenance planning.\n",
      "\n",
      "In summary, the answer to the original question is: there are 4 unique airplane producers represented in the database.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"How many unique airplane producers are represented in the database?\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ab7a3-bb1b-4f1b-82d1-4e02f8d40848",
   "metadata": {},
   "source": [
    "For this third example, we expect the table `flights` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd806b74-efe4-4701-8a3e-480e8a456074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT \n",
      "    Arrival_date, \n",
      "    Destination, \n",
      "    COUNT(Flight_number) as total_flights\n",
      "FROM \n",
      "    airline_db.flights\n",
      "GROUP BY \n",
      "    Arrival_date, \n",
      "    Destination\n",
      "ORDER BY \n",
      "    Arrival_date;\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can analyze and interpret the data to answer the original question.\n",
      "\n",
      "**Results Analysis:**\n",
      "\n",
      "The results show a list of 30 records, each representing a single flight scheduled for a specific arrival date and destination. The columns are:\n",
      "\n",
      "1. `Arrival Date`: The date when the flight is scheduled to arrive.\n",
      "2. `Destination`: The city where the flight is scheduled to land.\n",
      "3. `Flights`: The number of flights scheduled for each destination on the given arrival date.\n",
      "\n",
      "**Interpretation:**\n",
      "\n",
      "Since each record represents a single flight, the `Flights` column always has a value of 1. This means that there is only one flight scheduled for each destination on each arrival date.\n",
      "\n",
      "To answer the original question, \"Get the total number of flights scheduled for each destination, grouped by arrival date,\" we can conclude that:\n",
      "\n",
      "* For each arrival date, there is only one flight scheduled for each destination.\n",
      "* Therefore, the total number of flights scheduled for each destination on a given arrival date is always 1.\n",
      "\n",
      "In other words, the results show that there is no duplication of flights for the same destination on the same arrival date. If we were to group the results by arrival date and destination, the count of flights for each group would always be 1.\n",
      "\n",
      "For example, on `2023-06-15`, there is one flight scheduled for `Los Angeles`. On `2023-06-16`, there is one flight scheduled for `New York`, and so on.\n",
      "\n",
      "If you need to further aggregate the data or perform additional analysis, please let me know, and I'll be happy to help!\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"Get the total number of flights scheduled for each destination, grouped by arrival date\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199367e-7117-4553-b2f6-47073cb17769",
   "metadata": {},
   "source": [
    "For this fourth example, we expect the table `airplanes` and `flights` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a62f3823-367d-47a1-a0de-e4babe42ef08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT a.Airplane_id, a.Producer\n",
      "FROM airline_db.airplanes a\n",
      "JOIN airline_db.flights f ON a.Airplane_id = f.Airplane_id\n",
      "WHERE f.Destination = 'New York';\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can analyze and interpret the results as follows:\n",
      "\n",
      "The result shows that there is one airplane with an ID of 6, and its producer is Airbus.\n",
      "\n",
      "To answer the original question, \"Find the airplane IDs and producers for airplanes that have flown to New York\", we can conclude that:\n",
      "\n",
      "* There is at least one airplane that has flown to New York, which is identified by its ID, 6.\n",
      "* The producer of this airplane is Airbus.\n",
      "\n",
      "However, it's important to note that the result only shows one airplane that has flown to New York. It's possible that there are other airplanes that have also flown to New York, but they are not included in this result. To get a complete answer, we would need to examine the entire dataset or modify the SQL query to retrieve all relevant results.\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"Find the airplane IDs and producers for airplanes that have flown to New York\"\n",
    "\n",
    "# Query/search 1 most similar results.\n",
    "docs = collection2.query(\n",
    "    query_texts=[question],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "\n",
    "# Generate a prompt to get the LLM to provide an SQL query\n",
    "SQL_SYS_PROMPT = PromptTemplate.from_template(tmp_sql_sys_prompt).format(\n",
    "    question=question,\n",
    "    table_schemas=table_schemas,\n",
    ")\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT,\n",
    "    qna_sys_prompt=QNA_SYS_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce768358-c208-4c81-acff-ecb39b904b91",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "We can observe that ChromaDB and `Amazon Titan Embedding` model were able to retrieve the correct table schemas for the previous examples.  After successfully implementing these solutions, the issue of incorrectly retrieved table schemas due to foreign key confusions was effectively addressed. The data retrieval process became more accurate and reliable, ensuring that the correct table schemas were consistently retrieved, even in the presence of complex table relationships and foreign key references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5c40f-5e79-4b0a-9c0a-fa16b8195b6b",
   "metadata": {},
   "source": [
    "## Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b500a5c-16cc-4d23-9d06-8666928daa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete resources\n",
    "if llm_selected_service == 'Amazon SageMaker':\n",
    "    llm_predictor.delete_model()\n",
    "    llm_predictor.delete_endpoint()\n",
    "\n",
    "if embedding_selected_service == 'Amazon SageMaker':\n",
    "    embedding_predictor.delete_model()\n",
    "    embedding_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015474d-4387-447d-97a9-e4ae662d49d4",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea39284-8d33-440f-acb7-c33732544e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
