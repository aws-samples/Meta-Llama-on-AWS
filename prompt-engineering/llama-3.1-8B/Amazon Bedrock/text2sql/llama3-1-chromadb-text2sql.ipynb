{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4901509a-8316-47a3-879b-544a43b37ef3",
   "metadata": {},
   "source": [
    "# Best-practices for prompt engineering Text-to-SQL on Llama3.1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa596a49-ce47-4053-a93d-699bdef52426",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b488b5-d05b-45d2-84fb-6bc80cc30241",
   "metadata": {},
   "source": [
    "This notebook introduces a versatile approach that leverages Llama 3.1 models on Amazon Bedrock/Amazon SageMaker JumpStart, including advanced prompt engineering, to convert natural language questions into executable SQL queries. Our approach generates SQL queries capable of joining data from multiple tables, enabling information retrieval from complex database structures. This multi-table capability is crucial in real-world scenarios where data is often distributed across various tables with intricate relationships, and queries need to combine information from multiple sources to provide comprehensive insights.\n",
    "\n",
    "Moreover, our approach demonstrates high scalability through dynamically selecting and retrieving the most relevant table schemas based on the given natural language question. This scalability is achieved by employing intelligent schema matching algorithms powered by ChromaDB. ChromaDB analyzes the question and automatically identifies the appropriate tables and relationships required to construct the SQL query, eliminating the need for manual intervention.\n",
    "\n",
    "Our solution can be applied in practical scenarios where companies manage numerous databases with intricate table relationships, such as in the finance industry for analyzing customer transactions across multiple accounts and products, or in healthcare for integrating patient records from various systems and data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126d29c-4748-4831-8aff-60d71c61462e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "## Llama 3.1 Model Selection\n",
    "\n",
    "There are THREE Llama 3.1 models available on Amazon Bedrock:\n",
    "\n",
    "### 1. Llama 3.1 8B\n",
    "\n",
    "- **Description:** Ideal for limited computational power and resources, faster training times, and edge devices. The model excels at text summarization, text classification, sentiment analysis, and language translation.\n",
    "- **Context Window:** 128k\n",
    "- **Languages:** English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n",
    "- **Supported Use Cases:** Synthetic Text Generation, Text Classification, and Sentiment Analysis.\n",
    "\n",
    "### 2. Llama 3.1 70B\n",
    "\n",
    "- **Description:** Ideal for content creation, conversational AI, language understanding, research development, and enterprise applications. The model excels at text summarization and accuracy, text classification and nuance, sentiment analysis and nuance reasoning, language modeling, dialogue systems, code generation, and following instructions.\n",
    "- **Context Window:** 128k\n",
    "- **Languages:** English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n",
    "- **Supported Use Cases:** Synthetic Text Generation and Accuracy, Text Classification and Nuance, Sentiment Analysis and Nuance Reasoning, Language Modeling, Dialogue Systems, and Code Generation.\n",
    "\n",
    "### 2. Llama 3.1 405B\n",
    "\n",
    "- **Description:** Ideal for enterprise level applications, research and development, synthetic data generation, and model distillation. The model excels at general knowledge, long-form text generation, machine translation, enhanced contextual understanding, advanced reasoning and decision making, better handling of ambiguity and uncertainty, increased creativity and diversity, steerability, math, tool use, multilingual translation, and coding.\n",
    "- **Context Window:** 128k\n",
    "- **Languages:** English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n",
    "- **Supported Use Cases:** Synthetic Text Generation and Accuracy, Text Classification and Nuance, Sentiment Analysis and Nuance Reasoning, Language Modeling, Dialogue Systems, and Code Generation.\n",
    "\n",
    "\n",
    "### Performance and Cost Trade-offs\n",
    "\n",
    "The table below summarizes the model performance on the Massive Multitask Language Understanding ([MMLU](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md#instruction-tuned-models)) benchmark and their on-demand pricing on Amazon Bedrock.\n",
    "\n",
    "| Model           | MMLU Score | Price per 1,000 Input Tokens | Price per 1,000 Output Tokens |\n",
    "|-----------------|------------|------------------------------|-------------------------------|\n",
    "| Llama 3.1 8B | 69.4%      | \\$0.0003                   | \\$0.0006                    |\n",
    "| Llama 3.1 70B | 83.6%      | \\$0.00265                   | \\$0.0035                     |\n",
    "| Llama 3.1 405B | 87.3%      | \\$0.00532                   | \\$0.016                     |\n",
    "\n",
    "For more information, refer to the following links:\n",
    "\n",
    "1. [Llama 3.1 Model Cards and Prompt Formats](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1)\n",
    "2. [Amazon Bedrock Pricing Page](https://aws.amazon.com/bedrock/pricing/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd85684",
   "metadata": {},
   "source": [
    "## The Approach to the Text-to-SQL Problem\n",
    "This notebook covers the following approaches\n",
    "\n",
    "### Few-shot text-to-SQL (Single Table vs Multiple Tables)\n",
    "Few-shot text-to-SQL is an approach for querying databases by translating natural language questions into SQL queries, using only a few training examples. Providing just a few examples of natural language questions paired with the equivalent SQL queries allows models to learn the mapping from natural language to SQL. Reference : https://arxiv.org/abs/2305.12586\n",
    "\n",
    "### Few-shot text-to-SQL powered by ChromaDB (Schema Retrieval vs Enhance Schema Retrieval with Sample Questions)\n",
    "\n",
    "This approach leverages ChromaDB, a vector database, to assist the few-shot text-to-SQL translation process. ChromaDB can be used in two ways:\n",
    "\n",
    "1. **Schema Retrieval**: In this method, we provide manually the table schema within the prompt. When a natural language question is provided, the model uses the schema information to aid in generating the SQL query.\n",
    "\n",
    "2. **Schema Retrieval powered by ChromaDB**: In this method, ChromaDB stores the database schema information, which includes table names, column names, and their descriptions. When a natural language question is provided, the model can retrieve relevant schema information from ChromaDB to aid in generating the SQL query.\n",
    "\n",
    "By leveraging ChromaDB, the few-shot text-to-SQL translation process can benefit from efficient schema and sample data retrieval, potentially leading to better performance and generalization across different databases and query types.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058dceec",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "This notebook will provide code snippets to assist with implementing two differents approaches to converting a natural language question into a SQL query that would answer it.\n",
    "\n",
    "For accessing LLMs the following code snippets are provided:\n",
    "1. [Amazon Bedrock Invoke API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html)\n",
    "2. [Amazon Bedrock Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html)\n",
    "3. [SageMaker Jumpstart](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.jumpstart.model.JumpStartModel)\n",
    "\n",
    "In addition, you have the option of running the SQL on MySQL or PostgreSQL database.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b33e6",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Getting Started](#Getting-Started)\n",
    "    + [Install Dependencies](#Step-0:-Install-Dependencies)\n",
    "    + [Select Model Hosting Service](#Step-1:-Select-Hosting-Model-Service)\n",
    "    + [Get Database and Schema details](Step-2:-Get-Database-and-Schema-details)\n",
    "    + [Create helper functions](Step-3:-Create-helper-functions)\n",
    "1. [Few-Shot Text-to-SQL](#Few-Shot-Text-to-SQL)\n",
    "1. [Analyzing a Single Table with Few-Shot Learning](#Analyzing-a-Single-Table-with-Few-Shot-Learning)\n",
    "    + [Create a Few-Shot Prompt](#Step-1:-Create-a-Few-Shot-Prompt)\n",
    "    + [Execute Few-Shot Prompts](#Step-2:-Execute-Few-Shot-Prompts)\n",
    "1. [Analyzing Multiple Table with Few-Shot Learning](#Analyzing-Multiple-Table-with-Few-Shot-Learning)\n",
    "    + [Create a Few-Shot Prompt](#Step-1:-Create-a-Few-Shot-Prompt)\n",
    "    + [Execute Few-Shot Prompts](#Step-2:-Execute-Few-Shot-Prompts)\n",
    "1. [Limitations of Few-Shot Learning](#Limitations-of-Few-Shot-Learning)\n",
    "1. [Few-shot text-to-SQL powered by ChromaDB](#Few-shot-text-to-SQL-powered-by-ChromaDB)\n",
    "1. [Schema Retrieval](#Schema-Retrieval)\n",
    "    + [Data Preprocessing](#Step-1:-Data-Preprocessing)\n",
    "    + [Ingest docs into ChromaDB](#Step-2:-Ingest-docs-into-ChromaDB)\n",
    "    + [Create a Few-Shot Prompt](#Step-3:-Create-a-Few-Shot-Prompt)\n",
    "    + [Execute Few-Shot Prompts](#Step-4:-Execute-Few-Shot-Prompts)\n",
    "    + [Conclusion](#Step-5-Conclusion)\n",
    "1. [Enhanced Schema Retrieval with an Embedding Model](#Enhanced-Schema-Retrieval-with-an-Embedding-Model)\n",
    "    + [Ingest docs into ChromaDB](#Step-1:-Ingest-docs-into-ChromaDB)\n",
    "    + [Execute Few-Shot Prompts](#Step-2:-Execute-Few-Shot-Prompts)\n",
    "    + [Conclusion](#Step-3-Conclusion)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a20c2",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "+ AWS Python SDKs [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) to be able to submit API calls to [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "+ [LangChain](https://python.langchain.com/v0.1/docs/get_started/introduction/) is a framework that provides off the shelf components to make it easier to build applications with large language models. It is supported in multiple programming languages, such as Python, JavaScript, Java and Go. In this notebook, LangChain is used to build a prompt template.\n",
    "\n",
    "+ [ChromaDB](https://www.trychroma.com/) is a vector database that enables efficient semantic search, storage, and retrieval of unstructured data like text, images, and audio. It's designed to work well with large language models (LLMs) and provides a simple and scalable way to build applications that can search and retrieve relevant information from vast amounts of data.\n",
    "\n",
    "+ RDS (Relational Database Service) for [MySQL](https://aws.amazon.com/rds/mysql/) is a managed database service provided by Amazon Web Services (AWS). RDS for MySQL simplifies the setup, operation, and scaling of MySQL databases.\n",
    "\n",
    "+ [PostgreSQL](https://aws.amazon.com/rds/postgresql/what-is-postgresql/) has become the preferred open source relational database for many enterprise developers and startups, powering leading business and mobile applications. With [Amazon RDS for PostgreSQL](https://aws.amazon.com/rds/postgresql/), you can deploy scalable PostgreSQL deployments in minutes with cost-efficient and resizable hardware capacity.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a6bb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-requisites:\n",
    "\n",
    "1. It is mandatory to have set up the database and sample data prior to using [this notebook](llama3-1-chromadb-text2sql-DB-Setup.ipynb).\n",
    "2. Use kernel either `conda_python3`, `conda_pytorch_p310` or `conda_tensorflow2_p310`.\n",
    "3. Install the required packages.\n",
    "4. Access to the LLM API. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd282c-e45f-463e-9f68-f80176f4f0af",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92d068-da09-4d98-97f6-d14e7b0b8f6f",
   "metadata": {},
   "source": [
    "In this notebook, Llama 3.1 70B and 8B are used. You can easily switch between the two to evaluate the responses. By deploying the notebook through our cloudformation template, it is granted the appropriate IAM permissions to send API request to Bedrock. Refer [here](https://aws.amazon.com/blogs/aws/announcing-llama-3-1-405b-70b-and-8b-models-from-meta-in-amazon-bedrock/) for details on how Amazon Bedrock provides access to Meta’s Llama 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae4171-4f20-4a68-b6e1-0a40a3854de5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465f181-b661-4f59-bdac-92ed0e164203",
   "metadata": {},
   "source": [
    "#### Changing instance type\n",
    "---\n",
    "Models are supported on the following instance types:\n",
    "\n",
    " - Llama3.1 8B Text Generation: `ml.g5.4xlarge`, `ml.g5.8xlarge`, `ml.g5.12xlarge`, `ml.g5.24xlarge`, `ml.g5.48xlarge`, `ml.g6.4xlarge`, `ml.g6.8xlarge`, `ml.g6.12xlarge`, `ml.g6.24xlarge`, `ml.g6.48xlarge`, and `ml.p4d.24xlarge`\n",
    " - Llama3.1 70B Text Generation: `ml.g5.48xlarge`, `ml.g6.48xlarge`, `ml.p5.48xlarge` and `ml.p4d.24xlarge`\n",
    " - BGE Large En v1.5: `ml.g5.2xlarge`, `ml.c6i.xlarge`,`ml.g5.4xlarge`, `ml.g5.8xlarge`, `ml.p3.2xlarge`, and `ml.g4dn.2xlarge`\n",
    "\n",
    "By default, the JumpStartModel class selects a default instance type available in your region. If you would like to use a different instance type, you can do so by specifying instance type in the JumpStartModel class.\n",
    "\n",
    "`my_model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.12xlarge\")`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b2317-d90d-481f-8d51-464a93650978",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd1931-c19d-4c30-bfef-19cbc59724f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 0: Install Dependencies\n",
    "\n",
    "Here, we will install all the required dependencies to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d52454-073b-4a5a-b293-924419e1c8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3==1.34.127 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install mysql-connector-python==8.4.0 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install langchain==0.2.5 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install chromadb==0.5.0 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install numpy==1.26.4 -qU --force --quiet --no-warn-conflicts\n",
    "!pip install psycopg2==2.9.9 -qU --force --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097885d-9818-4015-b273-4fe30415cdfd",
   "metadata": {},
   "source": [
    "**Note:** *When installing libraries using the pip, you may encounter errors or warnings during the installation process. These are generally not critical and can be safely ignored. However, after installing the libraries, it is recommended to restart the kernel or computing environment you are working in. Restarting the kernel ensures that the newly installed libraries are loaded properly and available for use in your code or workflow.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea1457-e5a3-46b1-870f-ba7e73662ec2",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'><b>NOTE:</b> Restart the kernel with the updated packages that are installed through the dependencies above</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7518a54-885b-4403-ac4b-d5aab2ebb3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restart the kernel\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afba42-5061-4464-9ec9-8641992a7d66",
   "metadata": {},
   "source": [
    "#### Import the required modules to run the notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756999dd-ac11-4b3a-8e43-2c4cdc2ad9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import chromadb\n",
    "from chromadb.api.types import (\n",
    "    Documents,\n",
    "    EmbeddingFunction,\n",
    "    Embeddings,\n",
    ")\n",
    "import json\n",
    "from langchain import PromptTemplate\n",
    "import mysql.connector as MySQLdb\n",
    "import re\n",
    "from typing import Dict, List, Any\n",
    "import yaml\n",
    "\n",
    "import psycopg2 as PGdb\n",
    "# from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "703c9333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Bedrock Client\n",
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1f1bb-966d-4726-804c-b0d1f9108d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Select Hosting Model Service\n",
    "\n",
    "Here, you can select to run this notebook using SageMaker JumpStart or Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9f9044-79b0-4f76-9085-0f8c28568f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to run the LLM for this notebook using Amazon Bedrock (B) or Amazon Bedrock Converse API (C) or Amazon SageMaker JumpStart (S)? (default: B)  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the LLM for this notebook using [Amazon Bedrock].\n"
     ]
    }
   ],
   "source": [
    "def ask_for_service():\n",
    "    service = input(\"Do you want to run the LLM for this notebook using Amazon Bedrock (B) or Amazon Bedrock Converse API (C) or Amazon SageMaker JumpStart (S)? (default: B) \").strip().upper()\n",
    "    if service in ['S', 'SAGEMAKER']:\n",
    "        return 'Amazon SageMaker'\n",
    "    elif service in ['B', 'BEDROCK (Invoke API)', '']:\n",
    "        return 'Amazon Bedrock'\n",
    "    elif service in  ['C', 'BEDROCK (Converse API)']:\n",
    "        return 'Amazon Bedrock Converse API'\n",
    "    else:\n",
    "        print(\"Invalid input. Using Amazon Bedrock by default.\")\n",
    "        return 'Amazon Bedrock'\n",
    "\n",
    "# Call the function and get the selected service\n",
    "llm_selected_service = ask_for_service()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the LLM for this notebook using [{llm_selected_service}].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516b0617-6f4b-4344-b44d-8abf090b9c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to run the Embedding for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B)  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the Embedding for this notebook using [Amazon Bedrock].\n"
     ]
    }
   ],
   "source": [
    "def ask_for_service():\n",
    "    service = input(\"Do you want to run the Embedding for this notebook using Amazon Bedrock (B) or Amazon SageMaker JumpStart (S)? (default: B) \").strip().upper()\n",
    "    if service in ['S', 'SAGEMAKER']:\n",
    "        return 'Amazon SageMaker'\n",
    "    elif service in ['B', 'BEDROCK', '']:\n",
    "        return 'Amazon Bedrock'\n",
    "    else:\n",
    "        print(\"Invalid input. Using Amazon Bedrock by default.\")\n",
    "        return 'Amazon Bedrock'\n",
    "\n",
    "# Call the function and get the selected service\n",
    "embedding_selected_service = ask_for_service()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the Embedding for this notebook using [{embedding_selected_service}].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c904c9df-7245-4c3b-98af-96298a61d1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 μs, sys: 0 ns, total: 4 μs\n",
      "Wall time: 7.15 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if llm_selected_service == 'Amazon SageMaker':\n",
    "    \n",
    "    # Import the JumpStartModel class from the SageMaker JumpStart library\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "    # Specify the model ID for the Meta Llama 3 Instruct LLM model\n",
    "    llama3_1_8b_id = \"meta-textgeneration-llama-3-1-8b-instruct\"\n",
    "    llama3_1_70b_id = \"meta-textgeneration-llama-3-1-70b-instruct\"\n",
    "\n",
    "    DEFULT_LLM_MODEL_ID = llama3_1_8b_id\n",
    "    \n",
    "    model = JumpStartModel(model_id=DEFULT_LLM_MODEL_ID)\n",
    "    \n",
    "    llm_predictor = model.deploy(accept_eula=True)\n",
    "    \n",
    "    print(f\"LLM SageMaker Endpoint Name: [{llm_predictor.endpoint_name}].\")\n",
    "else:\n",
    "    llm_predictor = None\n",
    "    \n",
    "    llama3_1_8b_id = \"meta.llama3-1-8b-instruct-v1:0\"\n",
    "    llama3_1_70b_id = \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "    DEFULT_LLM_MODEL_ID = llama3_1_8b_id\n",
    "    \n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "if embedding_selected_service == 'Amazon SageMaker':\n",
    "    # Import the JumpStartModel class from the SageMaker JumpStart library\n",
    "    from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "    # Deploy BGE Large EN embedding model on Amazon SageMaker JumpStart:\n",
    "    # Specify the model ID for the HuggingFace BGE Large EN Embedding model\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"huggingface-sentencesimilarity-bge-large-en\"\n",
    "\n",
    "    text_embedding_model = JumpStartModel(model_id=DEFAULT_EMBEDDING_MODEL_ID)\n",
    "    \n",
    "    embedding_predictor = text_embedding_model.deploy()\n",
    "    \n",
    "    print(f\"LLM SageMaker Endpoint Name: [{embedding_predictor.endpoint_name}].\")\n",
    "else:\n",
    "    embedding_predictor = None\n",
    "    DEFAULT_EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631526fb-ab24-47a6-9a65-a871d7011370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to run the LLM example for this notebook using MySQL (M) or PostgreSQL (P)? (default: M)  M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to run the LLM example for this notebook using [mysql].\n"
     ]
    }
   ],
   "source": [
    "def ask_for_db():\n",
    "    service = input(\"Do you want to run the LLM example for this notebook using MySQL (M) or PostgreSQL (P)? (default: M) \").strip().upper()\n",
    "    if service in ['M', 'MYSQL']:\n",
    "        return 'mysql'\n",
    "    elif service in ['P', 'POSTGRESQL', '']:\n",
    "        return 'postgresql'\n",
    "    else:\n",
    "        print(\"Invalid input. Using MySQL by default.\")\n",
    "        return 'mysql'\n",
    "\n",
    "# Call the function and get the selected DB\n",
    "llm_selected_db = ask_for_db()\n",
    "\n",
    "# Print the selected service\n",
    "print(f\"You have chosen to run the LLM example for this notebook using [{llm_selected_db}].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12765f-10a8-4aae-9e62-4ee7f4e526cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Get Database and Schema details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2493f9-833f-40ff-a9db-b81f47e37c66",
   "metadata": {},
   "source": [
    "Here, we retrieve the services that are already deployed as a part of the cloudformation template to be used in building the application. The services include,\n",
    "\n",
    "+ Secret ARN with RDS for MySQL and RDS for PostgreSQL Database credentials\n",
    "+ Database Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d355be7-9365-41d5-8f63-153898c7c169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackname = \"text2sql\"  # If your stack name differs from \"text2sql\", please modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca002c7-3416-4ac5-b9a1-2b730557fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "response = cfn.describe_stack_resources(\n",
    "    StackName=stackname\n",
    ")\n",
    "cfn_outputs = cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']\n",
    "\n",
    "# Get rds secret arn and database endpoint from cloudformation outputs\n",
    "for output in cfn_outputs:\n",
    "    if 'SecretArnMySQL' in output['OutputKey']:\n",
    "        mySQL_secret_id = output['OutputValue']\n",
    "\n",
    "    if 'DatabaseEndpointMySQL' in output['OutputKey']:\n",
    "        mySQL_db_host = output['OutputValue']\n",
    "\n",
    "    if 'SecretArnPG' in output['OutputKey']:\n",
    "        pg_secret_id = output['OutputValue']\n",
    "\n",
    "    if 'DatabaseEndpointPG' in output['OutputKey']:\n",
    "        pg_db_host = output['OutputValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e5601b-287b-421e-8711-ef73d5c09cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secrets_client = boto3.client('secretsmanager')\n",
    "\n",
    "# Get MySQL credentials from Secrets Manager\n",
    "credentials = json.loads(secrets_client.get_secret_value(SecretId=mySQL_secret_id)['SecretString'])\n",
    "\n",
    "# Get password and username from secrets\n",
    "mySQL_db_password = credentials['password']\n",
    "mySQL_db_user = credentials['username']\n",
    "mySQL_db_name = \"airline_db\"\n",
    "\n",
    "# Get PostgreSQL credentials from Secrets Manager\n",
    "credentials = json.loads(secrets_client.get_secret_value(SecretId=pg_secret_id)['SecretString'])\n",
    "\n",
    "# Get password and username from secrets\n",
    "pg_db_password = credentials['password']\n",
    "pg_db_user = credentials['username']\n",
    "pg_db_name = \"airline_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c970c8c-f566-430f-b12b-e669cc7241eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Establish the database connection (MySQL DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705ab665-9b2e-4141-b7fb-df3329ac61c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mySQL_db_conn = MySQLdb.connect(\n",
    "    host=mySQL_db_host,\n",
    "    user=mySQL_db_user,\n",
    "    password=mySQL_db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f0a9b-337c-4679-a8f5-de9cde93c778",
   "metadata": {
    "tags": []
   },
   "source": [
    "Establish the database connection (PostgresSQL DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a5f172-4e80-4f36-9fe5-2f3527ec071b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg_db_conn = PGdb.connect(\n",
    "    host=pg_db_host,\n",
    "    database=pg_db_name,\n",
    "    user=pg_db_user,\n",
    "    password=pg_db_password\n",
    ")\n",
    "\n",
    "# PostgreSQL DB Setup\n",
    "pg_db_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cb5ef-41ea-43d9-ace9-8ca9c2dda260",
   "metadata": {},
   "source": [
    "#### Load table schema settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2579b20a-eb9c-4146-88e7-d4936d8d3038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_settings(file_path):\n",
    "    \"\"\"\n",
    "    Reads a YAML file and returns its contents as a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the YAML file.\n",
    "\n",
    "    Returns:\n",
    "        obj: The contents of the YAML file as a Python object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(f\"Error: Failed to parse the YAML file '{file_path}': {exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcf569e-6c76-4eee-8be7-cc0ab13a3802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MySQL Table Setup\n",
    "\n",
    "# Load table settings\n",
    "settings_airplanes = load_settings('schemas/airplanes.yml')\n",
    "table_airplanes = settings_airplanes['table_name']\n",
    "table_schema_airplanes = settings_airplanes['table_schema']\n",
    "\n",
    "# Load table settings\n",
    "settings_flights = load_settings('schemas/flights.yml')\n",
    "table_flights = settings_flights['table_name']\n",
    "table_schema_flights = settings_flights['table_schema']\n",
    "\n",
    "# Load table settings\n",
    "settings_airplane_flights = load_settings('schemas/airplanes-flights.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eced0d7d-b30b-4763-8a25-9d731cd9ba36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PostgreSQL Table Setup\n",
    "\n",
    "# Load table settings\n",
    "pg_settings_airplanes = load_settings('schemas/airplanes-pg.yml')\n",
    "pg_table_airplanes = pg_settings_airplanes['table_name']\n",
    "pg_table_schema_airplanes = pg_settings_airplanes['table_schema']\n",
    "\n",
    "# Load table settings\n",
    "pg_settings_flights = load_settings('schemas/flights-pg.yml')\n",
    "pg_table_flights = pg_settings_flights['table_name']\n",
    "pg_table_schema_flights = pg_settings_flights['table_schema']\n",
    "\n",
    "# Load table settings\n",
    "pg_settings_airplane_flights = load_settings('schemas/airplanes-flights-pg.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf28a8-0d22-4223-989b-243431149e22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Create helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae6aca-18fb-4beb-a6ae-caaeea512d1e",
   "metadata": {},
   "source": [
    "To facilate the usability and readability of the SQL Query Analysis made by Llama 3.1, let's create a suite of helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85e516-6344-41c7-90c8-0bdbd219ace8",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Chat Completion (Invoke LLM and Return response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaedc7-f395-4d92-9809-8f7b71baa42f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `sagemaker_chat_completion` function uses the SageMaker Endpoint to invoke the LLMs. The response from the LLM is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62b4863f-ff81-4f02-8c25-7f0d50f99d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sagemaker_chat_completion(\n",
    "    prompt: str,\n",
    "    max_gen_len: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a prompt using the llama3 model via Amazon SageMaker JumpStart.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text to generate completions for.\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": max_gen_len,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"stop\": [\"<|eot_id|>\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Call the model API to generate the completion\n",
    "    response = llm_predictor.predict(body)\n",
    "    completion = response.get('generated_text', '')\n",
    "\n",
    "    return completion.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6babb4b-812d-415f-b666-b1f69fc28706",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `bedrock_chat_completion` function uses the Bedrock client to invoke the LLMs. The response from the LLM is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c11b382-cf2d-4df9-971c-dc92c9a13043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bedrock_chat_completion(\n",
    "    model_id: str,\n",
    "    prompt: str,\n",
    "    max_gen_len: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a prompt using the llama3 model via Amazon Bedrock.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The ID of the llama3 model to use for completion.\n",
    "        prompt (str): The prompt text to generate completions for.\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_gen_len\": max_gen_len,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "    }\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    # Convert the body dictionary to JSON string and encode it as bytes\n",
    "    body_json = json.dumps(body)\n",
    "    body_bytes = body_json.encode('utf-8')\n",
    "\n",
    "    # Call the model API to generate the completion\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body_bytes, modelId=model_id, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = response[\"body\"].read()\n",
    "    response_body = json.loads(response_body)\n",
    "    completion = response_body.get(\"generation\", \"\")\n",
    "\n",
    "    return completion.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ca1db-a4aa-418e-a9aa-998e4a07b0ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Function `bedrock_converseapi_completion` generates and executes an SQL query for a given question, and returns a comprehensive analyzes based on the sql query results. This uses the Amazon Bedrock Converse API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b83956d-6d31-4e2a-bc9a-dacf6b0515e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bedrock_converseapi_completion(\n",
    "    model_id: str,\n",
    "    conversation,\n",
    "    max_tokens: int = 512,\n",
    "    temperature: float = 0.5,\n",
    "    top_p: float = 0.999,\n",
    "    system_prompt=\"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a chat completion from a conversation using the llama3.1 model via \n",
    "    Amazon Bedrock Converse API.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The ID of the llama3 model to use for completion.\n",
    "        conversation (object): The conversation so far user/assistant/user/...\n",
    "        max_gen_len (int, optional): The maximum length of the completion.\n",
    "        temperature (float, optional): Sampling temperature for the model.\n",
    "        top_p (float, optional): Top p sampling ratio for the model.\n",
    "        system_prompt: Any instructions to regulate the LLM behaviour.\n",
    "\n",
    "    Returns:\n",
    "        response: Object containing the assistant's response\n",
    "    \"\"\"  \n",
    "    try:\n",
    "        if system_prompt == \"\":\n",
    "            # Send the message to the model, using the provided inference configuration.\n",
    "            response = bedrock_client.converse(\n",
    "                modelId=model_id,\n",
    "                messages=conversation,\n",
    "                inferenceConfig={\n",
    "                    \"maxTokens\": max_tokens,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"topP\": top_p\n",
    "                },\n",
    "            )\n",
    "        else:\n",
    "            # Send the message to the model, using the provided inference configuration.\n",
    "            response = bedrock_client.converse(\n",
    "                modelId=model_id,\n",
    "                messages=conversation,\n",
    "                inferenceConfig={\n",
    "                    \"maxTokens\": max_tokens,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"topP\": top_p\n",
    "                },\n",
    "                system=[{\"text\": system_prompt}],\n",
    "            )\n",
    "\n",
    "        return response\n",
    "    \n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698ed84-c952-42f2-8fbc-2f73233725ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Instruction formatting, Query execution and LLM calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae9ae6-fcd2-4734-a655-be6a854b7224",
   "metadata": {},
   "source": [
    "The `format_instructions` function is designed to process the input from Llama 3 models, allowing a conversation between roles such as `system`, `user`, and `assistant`. To see more details about Llama 3 prompt formats, click [here](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7912ce9e-598c-47db-9780-b1cc95408f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_instructions(instructions: List[Dict[str, str]]) -> List[str]:\n",
    "    \"\"\"Format instructions where conversation roles must alternate system/user/assistant/user/assistant/...\n",
    "    Formats the prompt. Returns as a native prompt for Llama and also returns the System and User Prompt \n",
    "    texts that can be used with Bedrock Converse API.\n",
    "\n",
    "    Args:\n",
    "        instructions (List): A Dictionary of user and system instructions\n",
    "    Returns:\n",
    "        str: A formatted string containing the prompt, plaintext system prompt and plaintext user prompt.\n",
    "    \"\"\"\n",
    "    systemPrompt = userPrompt = \"\"\n",
    "    prompt: List[str] = []\n",
    "    \n",
    "    for instruction in instructions:\n",
    "        if instruction[\"role\"] == \"system\":\n",
    "            prompt.extend([\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \"<|eot_id|>\"])\n",
    "            systemPrompt = instruction[\"content\"].strip()\n",
    "        elif instruction[\"role\"] == \"user\":\n",
    "            prompt.extend([\"<|start_header_id|>user<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \"<|eot_id|>\"])\n",
    "            userPrompt = instruction[\"content\"].strip()\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid role: {instruction['role']}. Role must be either 'user' or 'system'.\")\n",
    "    prompt.extend([\"<|start_header_id|>assistant<|end_header_id|>\\n\"])\n",
    "    return \"\".join(prompt), \"\".join(systemPrompt), \"\".join(userPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ed73f-1ea7-4a5f-91be-e5217701dc7c",
   "metadata": {},
   "source": [
    "The `execute_query` function will execute SQL queries, typically for retrieving data from a database, and format the results as a string for further processing or display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9401ba7a-de43-410d-8015-a38a60f2b6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query: str, db_conn) -> str:\n",
    "    \"\"\"Execute an SQL query on the database connection and return the results as a string.\n",
    "\n",
    "    Args:\n",
    "        query (str): SQL query to execute\n",
    "        db_conn (Connection object): Connection object to the database where the query needs to be executed.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the SQL results.\n",
    "    \"\"\"\n",
    "    # Get a cursor from the database connection\n",
    "    mycursor = db_conn.cursor()\n",
    "\n",
    "    # Execute the SQL query\n",
    "    mycursor.execute(query)\n",
    "\n",
    "    # Fetch all result rows\n",
    "    result_rows = mycursor.fetchall()\n",
    "\n",
    "    # Convert result to string with newline between rows\n",
    "    output_text = '\\n'.join([str(x) for x in result_rows])\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997f36-a08b-4189-ba98-a410d9063e41",
   "metadata": {},
   "source": [
    "The Function `get_llm_sql_analysis` generates and executes an SQL query for a given question, and returns a comprehensive analyzes based on the sql query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e8610a-69e9-452b-a3cc-42f6e3129709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_llm_sql_analysis(question: str, sql_sys_prompt: str, qna_sys_prompt: str, DatabaseType: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an SQL query based on the given question, executes it, and returns an analysis of the results using Llama 3.\n",
    "\n",
    "    Args:\n",
    "        question (str): The input question for which an SQL query needs to be generated.\n",
    "        sql_sys_prompt (str): The prompt to be used for generating the SQL query using Llama 3.\n",
    "        qna_sys_prompt (str): The prompt to be used for analyzing the SQL query results using Llama 3.\n",
    "        DatabaseType (enum): The type of database on which query needs to be executed. E.g. MySQL / PostgreSQL etc\n",
    "\n",
    "    Returns:\n",
    "        str: The analysis of the SQL query results provided by the language model.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # *****************************************************************************************\n",
    "        # 1. Generate SQL Query\n",
    "        # *****************************************************************************************\n",
    "        print(f\"\\nUsing [{llm_selected_service}] to generate SQL for [{DatabaseType}]\\n\")\n",
    "        \n",
    "        if llm_selected_service == 'Amazon SageMaker':\n",
    "            # Generates SQL query\n",
    "            completion = sagemaker_chat_completion(\n",
    "                prompt=sql_sys_prompt\n",
    "            )\n",
    "        elif llm_selected_service == 'Amazon Bedrock Converse API':\n",
    "            # *****************************************************************************************\n",
    "            # TODO: Perform additional steps for converse API\n",
    "            conversation = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"text\": question}],\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            response = bedrock_converseapi_completion(\n",
    "                model_id=DEFULT_LLM_MODEL_ID, \n",
    "                conversation=conversation, \n",
    "                system_prompt=sql_sys_prompt)\n",
    "\n",
    "            completion=response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "            # *****************************************************************************************\n",
    "\n",
    "        else:\n",
    "            # Generates SQL query\n",
    "            completion = bedrock_chat_completion(\n",
    "                model_id=DEFULT_LLM_MODEL_ID,\n",
    "                prompt=sql_sys_prompt\n",
    "            )\n",
    "\n",
    "        # *****************************************************************************************\n",
    "        # 2. Extract SQL and Execute\n",
    "        # *****************************************************************************************\n",
    "\n",
    "        # Extract the SQL query from the completion returned from the first LLM call.\n",
    "        pattern = r\"<sql>(.*)</sql>\"\n",
    "        llm_sql_query = re.search(pattern, completion, re.DOTALL).group(1)\n",
    "        print(f\"\\nLLM SQL Query: \\n{llm_sql_query}\")\n",
    "\n",
    "        # Route the query according to the database passed. Connection object will vary.\n",
    "        match DatabaseType:\n",
    "            case \"mysql\":\n",
    "                db_conn=mySQL_db_conn\n",
    "            case \"postgresql\":\n",
    "                db_conn=pg_db_conn\n",
    "\n",
    "        # Execute SQL query based on the database provided.\n",
    "        sql_results = execute_query(llm_sql_query, db_conn)\n",
    "\n",
    "        print(f\"\\nsql_results = \\n{sql_results}\")\n",
    "\n",
    "        # *****************************************************************************************\n",
    "        # 3. Evaluate the response\n",
    "        # *****************************************************************************************\n",
    "        \n",
    "        print(f\"\\nCalling LLM on [{llm_selected_service}] to Analyze and interpret the results from SQL query in relation to the original question.\\n\")\n",
    "        \n",
    "        # Now we will use a second LLM call to analyse the result of the query.\n",
    "        if llm_selected_service == 'Amazon SageMaker':\n",
    "            # Generates SQL analysis\n",
    "            llm_sql_analysis = sagemaker_chat_completion(\n",
    "                prompt=qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "            )\n",
    "        elif llm_selected_service == 'Amazon Bedrock Converse API':\n",
    "            # *****************************************************************************************\n",
    "            # TODO: Append Assistant response.\n",
    "\n",
    "            # Append user's next question\n",
    "            # Create a conversation object\n",
    "            queryAnalyseResults = qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "\n",
    "            conversation = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"text\": queryAnalyseResults}],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            # Now we will use a second llM call to analyse the result of the query.\n",
    "            response = bedrock_converseapi_completion(\n",
    "                model_id=DEFULT_LLM_MODEL_ID, \n",
    "                conversation=conversation)\n",
    "\n",
    "            llm_sql_analysis = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "            # *****************************************************************************************\n",
    "        else:\n",
    "            # Generates SQL analysis\n",
    "            llm_sql_analysis = bedrock_chat_completion(\n",
    "                model_id=DEFULT_LLM_MODEL_ID,\n",
    "                prompt=qna_sys_prompt.format(query_results=sql_results, question=question)\n",
    "            )\n",
    "\n",
    "        print(f\"\\nLLM SQL Analysis: \\n{llm_sql_analysis}\")\n",
    "\n",
    "        return llm_sql_analysis\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af419b-9bdd-4899-a187-c5865f71a9f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Embedding Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb825ee-8996-433b-b879-0f2581055ec4",
   "metadata": {},
   "source": [
    "The Class `AmazonBedrockEmbeddingFunction` initializes an embedding function with `Amazon Titan Embedding Model V2` that integrates with ChromaDB . This class can be further extended to add support for other embedding models available on Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8dfb0a-0b02-444b-b8a1-67ec98772a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonBedrockEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        session: \"boto3.Session\",\n",
    "        model_name: str = \"amazon.titan-embed-text-v2:0\",\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize AmazonBedrockEmbeddingFunction.\n",
    "\n",
    "        Args:\n",
    "            session (boto3.Session): The boto3 session to use.\n",
    "            model_name (str, optional): Identifier of the model, defaults to \"amazon.titan-embed-text-v1\"\n",
    "            **kwargs: Additional arguments to pass to the boto3 client.\n",
    "\n",
    "        Example:\n",
    "            >>> import boto3\n",
    "            >>> session = boto3.Session(profile_name=\"profile\", region_name=\"us-east-1\")\n",
    "            >>> bedrock = AmazonBedrockEmbeddingFunction(session=session)\n",
    "            >>> texts = [\"Hello, world!\", \"How are you?\"]\n",
    "            >>> embeddings = bedrock(texts)\n",
    "        \"\"\"\n",
    "\n",
    "        self._model_name = model_name\n",
    "\n",
    "        self._client = session.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        accept = \"*/*\"\n",
    "        content_type = \"application/json\"\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            input_body = {\"inputText\": text, \"dimensions\": 512, \"normalize\": True}\n",
    "            body = json.dumps(input_body)\n",
    "            response = self._client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=self._model_name,\n",
    "                accept=accept,\n",
    "                contentType=content_type,\n",
    "            )\n",
    "            embedding = json.load(response.get(\"body\")).get(\"embedding\")\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47479bba-58f5-4906-89d7-9eb688588192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmazonSageMakerEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Initialize AmazonSageMakerEmbeddingFunction.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Additional arguments to pass to the sagemaker embedding function.\n",
    "\n",
    "        Example:\n",
    "            >>> sagemaker = AmazonBedrockEmbeddingFunction()\n",
    "            >>> text_inputs = [\"Hello, world!\", \"How are you?\"]\n",
    "            >>> embeddings = sagemaker(texts)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        accept = \"application/json\"\n",
    "        content_type = \"application/json\"\n",
    "\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            input_body = {\"text_inputs\": text, \"mode\": \"embedding\"}\n",
    "            body = json.dumps(input_body).encode('utf-8')\n",
    "            response = embedding_predictor.predict(\n",
    "                body,\n",
    "                {\n",
    "                    \"ContentType\": content_type,\n",
    "                    \"Accept\": accept,\n",
    "                }\n",
    "            )\n",
    "            embedding = response.get(\"embedding\")\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909b559-22a3-41ff-99d3-96796458dd44",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Few-Shot Text-to-SQL\n",
    "With our database and tables filled with data, we're now ready to walk through the Few-Shot Text-to-SQL approach. We'll start by building some helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccf1fe-ed1a-42f7-885c-8f12a8d15aca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyzing a Single Table with Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e4c5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Create a Few-Shot Prompt\n",
    "Here, we design our prompt template that will account for our question and answer, and formatted correctly for use with Llama 3.1 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ea8a0-61e8-4eee-a14a-71e9d6ec303d",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing two parts:\n",
    "\n",
    "1. `table_schema`. This is a description of the structure of the database table, including the name of the table, the names of the columns within each table, and the data types of each column. This information helps Llama 3.1 to understand the organization and contents of the table.\n",
    "\n",
    "2. `question`. This is the specific request or information that the user wants to obtain from the table.\n",
    "\n",
    "By including both the table schema and the user's question in the system prompt, we provide Llama 3.1 model a complete understanding of the table structure and the user's desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9528d11-a02e-436d-a06c-b40639dce4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a {dbtype} query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schema:\n",
    "<table_schema>\n",
    "{table_schema}\n",
    "<table_schema>\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the {dbtype} query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Format instructions in LLM specific format\n",
    "# Call the format instructions to get System Prompt and User Prompt into separate variables.\n",
    "# For Converse API we don't need to provide inputs in a model specific format\n",
    "tmp_sql_sys_prompt, sysPt, userPt = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb4eb9-d15c-4453-8053-4d80813794c0",
   "metadata": {},
   "source": [
    "Next, we create a new `system prompt` containing two parts:\n",
    "\n",
    "1. `query_results` represents the SQL query results after executing the prompt `tmp_sql_sys_prompt`. This is the raw data that Llama 3 model will use to generate its analysis.\n",
    "\n",
    "2. `question`. This specifies the type of analysis or insight that the user wants Llama 3 model to provide based on the SQL query results.\n",
    "\n",
    "By combining the SQL query results and the user's question into a single system prompt, we provide Llama 3 model all the information it needs to understand the context and provide a comprehensive analysis tailored to the user's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c5e5b2-13b1-4f70-9484-56b2ef618cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Given the following SQL query results:\n",
    "{query_results}\n",
    "\n",
    "And the original question:\n",
    "{question}\n",
    "\n",
    "Please provide an analysis and interpretation of the results to answer the original question.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "QNA_SYS_PROMPT, sysPtI, userPtI = format_instructions(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97db613",
   "metadata": {},
   "source": [
    "Building on our last prompt, we'll now add a Single Shot example to our context to better hint the model what we expect for a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de41022-e8fa-423e-a35b-92537e8dfd21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Execute Few Shot Prompts\n",
    "The following cells will demonstrate different questions asked in natural language and the SQL generated by the LLM. The output is contained between the `<sql>` and `</sql>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a573a90-de5d-4fa3-8319-22f67784218e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Switch_DB_Schema(DatabaseType: str, SchemaNeeded: str):\n",
    "    \"\"\"\n",
    "    Baesd on the database provided, returns the schema appropriate to the object provided\n",
    "\n",
    "    Args:\n",
    "        DatabaseType (str): mysql / postgresql\n",
    "        SchemaNeeded (str): table_schema_airplanes / \n",
    "\n",
    "    Returns:\n",
    "        str: The analysis of the SQL query results provided by the language model.\n",
    "    \"\"\"\n",
    "    match DatabaseType:\n",
    "        case \"mysql\":\n",
    "            match SchemaNeeded:\n",
    "                case \"table_schema_airplanes\":\n",
    "                    schema_for_object = table_schema_airplanes\n",
    "                case \"table_schema_flights\":\n",
    "                    schema_for_object = table_schema_flights\n",
    "        case \"postgresql\":\n",
    "            match SchemaNeeded:\n",
    "                case \"table_schema_airplanes\":\n",
    "                    schema_for_object = pg_table_schema_airplanes\n",
    "                case \"table_schema_flights\":\n",
    "                    schema_for_object = pg_table_schema_flights\n",
    "    return schema_for_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6617123b-78ea-4631-9871-30c01c7a888a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a mysql query expert whose output is a valid sql query.\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "It has the following schema:\n",
      "<table_schema>\n",
      "CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      "\n",
      "<table_schema>\n",
      "\n",
      "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "What is the total count of airplanes?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(Airplane_id) FROM airline_db.airplanes;\n",
      "\n",
      "sql_results = \n",
      "(20,)\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "To answer the original question, \"What is the total count of airplanes?\", we need to analyze the given SQL query results.\n",
      "\n",
      "The result (20,) indicates that the total count of airplanes is 20.\n",
      "\n",
      "Here's a breakdown of the result:\n",
      "\n",
      "* The number 20 represents the count of airplanes.\n",
      "* The comma (,) is a common notation in SQL to indicate that the result is a single value, rather than a tuple or a list.\n",
      "\n",
      "Therefore, based on the given SQL query results, the total count of airplanes is 20.\n",
      "CPU times: user 10.6 ms, sys: 0 ns, total: 10.6 ms\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "# Amazon Bedrock Invoke API expects a fully formatted prompt.\n",
    "# Amazon Bedrock Converse API expects regular text\n",
    "if (llm_selected_service == 'Amazon Bedrock') or (llm_selected_service == 'Amazon SageMaker'):\n",
    "    tmp_sql_sys_prompt1 = tmp_sql_sys_prompt\n",
    "    qna_sys_prompt1 = QNA_SYS_PROMPT\n",
    "elif llm_selected_service == 'Amazon Bedrock Converse API':\n",
    "    tmp_sql_sys_prompt1 = sysPt\n",
    "    qna_sys_prompt1 = userPtI\n",
    "\n",
    "SQL_SYS_PROMPT_s1 = PromptTemplate.from_template(tmp_sql_sys_prompt1).format(\n",
    "    question=question,\n",
    "    table_schema=Switch_DB_Schema(llm_selected_db, \"table_schema_airplanes\"),\n",
    "    dbtype=llm_selected_db\n",
    ")\n",
    "print(SQL_SYS_PROMPT_s1)\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT_s1,\n",
    "    qna_sys_prompt=qna_sys_prompt1,\n",
    "    DatabaseType=llm_selected_db\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e9395-5c48-4880-a80e-4874786b7ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyzing Multiple Table with Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad7c5d-98a8-4079-b668-29347c563bef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Create a Few-Shot Prompt\n",
    "Now, let's try the same approach using two tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea14d6-539f-442a-85fd-e32dd02abb44",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing the same placeholders as before and including two table schemas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92b4a07c-3762-411b-a0ab-a94c8df3d96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a {dbtype} query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schemas:\n",
    "<table_schemas>\n",
    "<table_schema>\n",
    "{table_schema1}\n",
    "<table_schema>\n",
    "\n",
    "<table_schema>\n",
    "{table_schema2}\n",
    "<table_schema>\n",
    "<table_schemas>\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the {dbtype} query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tmp_sql_sys_prompt, sysPt, userPt = format_instructions(instructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cead15-002f-4b53-9d9f-da3b4ac94db8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abce7627-60c2-432b-af9c-beabbe86be54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a mysql query expert whose output is a valid sql query.\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "It has the following schemas:\n",
      "<table_schemas>\n",
      "<table_schema>\n",
      "CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      "\n",
      "<table_schema>\n",
      "\n",
      "<table_schema>\n",
      "CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      "\n",
      "<table_schema>\n",
      "<table_schemas>\n",
      "\n",
      "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "What is the total count of flights per producer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT Producer, COUNT(*) as total_flights\n",
      "FROM flights\n",
      "GROUP BY Producer;\n",
      "\n",
      "1046 (3D000): No database selected\n"
     ]
    }
   ],
   "source": [
    "# Business question\n",
    "question = \"What is the total count of flights per producer?\"\n",
    "\n",
    "# Amazon Bedrock Invoke API expects a fully formatted prompt.\n",
    "# Amazon Bedrock Converse API expects regular text\n",
    "if (llm_selected_service == 'Amazon Bedrock') or (llm_selected_service == 'Amazon SageMaker'):\n",
    "    tmp_sql_sys_prompt1 = tmp_sql_sys_prompt\n",
    "    qna_sys_prompt1 = QNA_SYS_PROMPT\n",
    "elif llm_selected_service == 'Amazon Bedrock Converse API':\n",
    "    tmp_sql_sys_prompt1 = sysPt\n",
    "    qna_sys_prompt1 = userPtI\n",
    "\n",
    "SQL_SYS_PROMPT_s1 = PromptTemplate.from_template(tmp_sql_sys_prompt1).format(\n",
    "    question=question,\n",
    "    table_schema1=Switch_DB_Schema(llm_selected_db, \"table_schema_airplanes\"),\n",
    "    table_schema2=Switch_DB_Schema(llm_selected_db, \"table_schema_flights\"),\n",
    "    dbtype=llm_selected_db\n",
    ")\n",
    "\n",
    "print(SQL_SYS_PROMPT_s1)\n",
    "\n",
    "results = get_llm_sql_analysis(\n",
    "    question=question,\n",
    "    sql_sys_prompt=SQL_SYS_PROMPT_s1,\n",
    "    qna_sys_prompt=qna_sys_prompt1,\n",
    "    DatabaseType=llm_selected_db\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518e52c-5ac3-4682-8cb6-921039ffa2d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Limitations of Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfcd94-8b32-4cc3-b0cc-7425105958a7",
   "metadata": {},
   "source": [
    "Few-Shot Learning for text-to-SQL tasks, where a language model is trained on a limited number of examples to translate natural language queries into SQL queries, faces significant limitations. One of the key challenges is selecting the appropriate table schema that aligns with the user's question.\n",
    "\n",
    "In a real-world scenario, databases often consist of numerous tables with intricate relationships, making it difficult for the model to identify the relevant tables and columns required to answer a given query accurately. \n",
    "\n",
    "To address this issue, we propose incorporating ChromaDB to facilitate the retrieval of table schemas that are tailored to the user's question.\n",
    "\n",
    "Here's how ChromaDB can help overcome the table schema selection challenge:\n",
    "\n",
    "**Table Schema Retrieval**: Each table schema in the database can be converted into a dense vector embedding, capturing its structural information and relationships. The top-ranked table schemas are retrieved and provided as input to the text-to-SQL model, significantly increasing the likelihood of generating accurate SQL queries.\n",
    "\n",
    "We will review this approach further in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366f9d5-f0ca-4008-a8be-04ab47b22779",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Few-shot text-to-SQL powered by ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73cdbb-e062-4d04-981d-ae92ec7e71fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, we will use ChromaDB and the few-shot technique to effeciently retrieve table schemas for better performance and generalization across different databases and query types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765c200-7f94-4044-97ca-4681d5058d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Schema Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf41750-066b-40f5-a4f2-407acec7da60",
   "metadata": {},
   "source": [
    "In this approach, we will store only the table schemas in ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70751dc4-6b3d-45b8-838d-908cd26684ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Data Preprocessing\n",
    "\n",
    "The first step is to preprocess the data and create a document that will be ingested into ChromaDB. The final doc clearly separates the table schemas by using XML tags such as `<table_schema></table_schema>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8f8888c-2a37-4a0c-8949-baaa24815ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# For MySQL\n",
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc1 = \"<table_schemas>\\n\"\n",
    "doc1 += f\"<table_schema>\\n {settings_airplanes['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "doc1 += \"\\n</table_schemas>\"\n",
    "print(doc1)\n",
    "\n",
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc2 = \"<table_schemas>\\n\"\n",
    "doc2 += f\"<table_schema>\\n {settings_flights['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "doc2 += \"\\n</table_schemas>\"\n",
    "print(doc2)\n",
    "\n",
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "doc3 = \"<table_schemas>\\n\"\n",
    "for table_schema in settings_airplane_flights['table_schemas']:\n",
    "    doc3 += f\"<table_schema>\\n {table_schema} \\n</table_schema>\\n\"\n",
    "doc3 += \"\\n</table_schemas>\".strip()\n",
    "print(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d28f566-85c6-40b3-b69b-5bfdd50c7db2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airplanes -- Table name\n",
      "(\n",
      "Airplane_id INTEGER, -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INTEGER, -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n",
      "<table_schemas>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "</table_schemas>\n"
     ]
    }
   ],
   "source": [
    "# For PostgreSQL\n",
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "pg_doc1 = \"<table_schemas>\\n\"\n",
    "pg_doc1 += f\"<table_schema>\\n {pg_settings_airplanes['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "pg_doc1 += \"\\n</table_schemas>\"\n",
    "print(pg_doc1)\n",
    "\n",
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "pg_doc2 = \"<table_schemas>\\n\"\n",
    "pg_doc2 += f\"<table_schema>\\n {pg_settings_flights['table_schema']} \\n</table_schema>\\n\".strip()\n",
    "pg_doc2 += \"\\n</table_schemas>\"\n",
    "print(pg_doc2)\n",
    "\n",
    "# The doc includes a structure format for clearly identifying the table schemas\n",
    "pg_doc3 = \"<table_schemas>\\n\"\n",
    "for table_schema in pg_settings_airplane_flights['table_schemas']:\n",
    "    pg_doc3 += f\"<table_schema>\\n {table_schema} \\n</table_schema>\\n\"\n",
    "pg_doc3 += \"\\n</table_schemas>\".strip()\n",
    "print(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad09a7-e39e-48fe-a4af-e4e573aa8d24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Ingest docs into ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b088a-846e-4ca2-842f-5ff1c6897b26",
   "metadata": {},
   "source": [
    "After the data is preprocessed, the next step is to ingest all `docs` into ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cea1d14-515d-483c-83a5-ac7a5d0f0c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Chroma in-memory, for easy prototyping.\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "619eb8a2-dc67-42ec-8156-408117e8253d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 30.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# For MySQL\n",
    "# Create collection using ChromaDB's internal embedding function\n",
    "collection1 = chroma_client.get_or_create_collection(name=\"table-schemas-default-embedding\", \n",
    "                                                     metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "# Add docs to the collection.\n",
    "collection1.add(\n",
    "    documents=[\n",
    "        doc1,\n",
    "        doc2,\n",
    "        doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"mysql\", \"database\": mySQL_db_name, \"table_name\": table_airplanes},\n",
    "        {\"source\": \"mysql\", \"database\": mySQL_db_name, \"table_name\": table_flights},\n",
    "        {\"source\": \"mysql\", \"database\": mySQL_db_name, \"table_name\": f\"{table_airplanes}-{table_flights}\" }\n",
    "    ],\n",
    "    ids=[table_airplanes, table_flights, f\"{table_airplanes}-{table_flights}\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad1a7d32-b5d4-42a9-b695-487f2e41db4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For PostgreSQL\n",
    "# Create collection using ChromaDB's internal embedding function\n",
    "# Make sure Modify the Collection name for each new Database\n",
    "pg_collection1 = chroma_client.get_or_create_collection(name=\"pg-table-schemas-default-embedding\", \n",
    "                                                        metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "# Add docs to the collection.\n",
    "pg_collection1.add(\n",
    "    documents=[\n",
    "        pg_doc1,\n",
    "        pg_doc2,\n",
    "        pg_doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"postgresql\", \"database\": pg_db_name, \"table_name\": pg_table_airplanes},\n",
    "        {\"source\": \"postgresql\", \"database\": pg_db_name, \"table_name\": pg_table_flights},\n",
    "        {\"source\": \"postgresql\", \"database\": pg_db_name, \"table_name\": f\"{pg_table_airplanes}-{pg_table_flights}\" }\n",
    "    ],\n",
    "    ids=[pg_table_airplanes, pg_table_flights, f\"{pg_table_airplanes}-{pg_table_flights}\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff502167-2453-4eb5-9b29-0babf1ed0a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RunPrompts(DatabaseType: str, ServiceType: str, question: str, mySQLCol, pgCol):\n",
    "    \"\"\"\n",
    "    Helper function that does the following:\n",
    "    - Picks up the ChromaDB collection (passed as input parameters) based on the DatabaseType\n",
    "    - Retrieves relevant table schemas from ChromaDB based on the Business Question.\n",
    "    - Invoke the LLM to return the SQL query for the table schemas retrieved.\n",
    "    - Run the query against the database.\n",
    "    - Invoke the LLM to analyse results of the query execution against the Business Question.\n",
    "\n",
    "    Args:\n",
    "        DatabaseType (str): mysql / postgresql\n",
    "        ServiceType (str): 'Amazon Bedrock' / 'Amazon Bedrock Converse API'\n",
    "        question (str): User's business question\n",
    "        mySQLCol (object): ChromadB collection for mySQL Database\n",
    "        pgCol (object): ChromadB collection for mySQL Database\n",
    "\n",
    "    Returns:\n",
    "        str: The analysis of the SQL query results provided by the language model.\n",
    "    \"\"\"\n",
    "    # Route the query according to the database passed\n",
    "    if DatabaseType == \"mysql\":\n",
    "        # For MySQL DB\n",
    "        collection_to_use = mySQLCol\n",
    "    elif DatabaseType == \"postgresql\":\n",
    "        # For PostgreSQL DB\n",
    "        collection_to_use = pgCol\n",
    "    \n",
    "    # Query/search 1 most similar results.\n",
    "    docs = collection_to_use.query(\n",
    "        query_texts=[question],\n",
    "        n_results=1\n",
    "    )\n",
    "\n",
    "    pattern = r\"<table_schemas>(.*)</table_schemas>\"\n",
    "    table_schemas = re.search(pattern, docs[\"documents\"][0][0], re.DOTALL).group(1)\n",
    "    print(f\"ChromaDB - Schema Retrieval: \\n{table_schemas.strip()}\")\n",
    "    \n",
    "    # Amazon Bedrock Invoke API expects a fully formatted prompt.\n",
    "    # Amazon Bedrock Converse API expects regular text\n",
    "    if (llm_selected_service == 'Amazon Bedrock') or (llm_selected_service == 'Amazon SageMaker'):\n",
    "        tmp_sql_sys_prompt1 = tmp_sql_sys_prompt\n",
    "        qna_sys_prompt1 = QNA_SYS_PROMPT\n",
    "    elif ServiceType == 'Amazon Bedrock Converse API':\n",
    "        tmp_sql_sys_prompt1 = sysPt\n",
    "        qna_sys_prompt1 = userPtI\n",
    "\n",
    "    SQL_SYS_PROMPT_s1 = PromptTemplate.from_template(tmp_sql_sys_prompt1).format(\n",
    "        question=question,\n",
    "        table_schemas=table_schemas,\n",
    "        dbtype=DatabaseType\n",
    "    )\n",
    "\n",
    "    results = get_llm_sql_analysis(\n",
    "        question=question,\n",
    "        sql_sys_prompt=SQL_SYS_PROMPT_s1,\n",
    "        qna_sys_prompt=qna_sys_prompt1,\n",
    "        DatabaseType=DatabaseType\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d7669-6cd2-485f-8d41-44fb3526c86e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Create a Few-Shot Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588156e2-5b35-4828-a3ca-e077f2c542ac",
   "metadata": {},
   "source": [
    "Now, we'll use a few-shot approach using the retrieved tables from ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbb802-9437-47b5-b728-9e2e7c9a64df",
   "metadata": {},
   "source": [
    "First, we create a `system prompt` containing a placeholder including any number of table schemas for ChromaDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc0758c4-7710-43af-ad4f-e1a3123f685a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \n",
    "        \"\"\"You are a {dbtype} query expert whose output is a valid sql query.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schemas:\n",
    "<table_schemas>\n",
    "{table_schemas}\n",
    "<table_schemas>\n",
    "\n",
    "Always combine the database name and table name to build your queries. You must identify these two values before proving a valid SQL query.\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the {dbtype} query in between <sql></sql>.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{question}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tmp_sql_sys_prompt, sysPt, userPt = format_instructions(instructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc134b9c-96de-47b7-a182-664024d0b2a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 4: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977f101-cd0b-4ab4-bc6e-85bf3d759f1d",
   "metadata": {},
   "source": [
    "In this example, we expect the table `airplanes` to be used for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8853827-1d81-4ef4-befc-d2f55d52314a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT COUNT(Airplane_id) AS total_airplanes\n",
      "FROM airline_db.airplanes;\n",
      "\n",
      "\n",
      "sql_results = \n",
      "(20,)\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Unfortunately, the provided SQL query result doesn't contain enough information to directly answer the original question, \"What is the total count of airplanes?\".\n",
      "\n",
      "However, I can guide you through a possible analysis and interpretation of the result.\n",
      "\n",
      "The result `(20,)` appears to be a tuple with a single value, which is `20`. In the context of a SQL query, this could be interpreted as the count of airplanes in a specific database table or result set.\n",
      "\n",
      "To determine if this is indeed the total count of airplanes, we would need to know more about the query that generated this result. Here are some possible scenarios:\n",
      "\n",
      "1. **Count of a specific table**: If the query was a simple `SELECT COUNT(*)` statement on a table named `airplanes`, then `20` might be the total count of airplanes in that table.\n",
      "2. **Filtered count**: If the query had a `WHERE` clause that filtered the results to a specific subset of airplanes (e.g., by manufacturer, model, or status), then `20` might be the count of airplanes that match those criteria.\n",
      "3. **Derived count**: If the query performed some calculations or aggregations on the data, then `20` might be a derived count, such as the number of airplanes with a specific characteristic (e.g., the number of airplanes with a certain feature or option).\n",
      "\n",
      "Without more information about the query or the database schema, it's difficult to provide a definitive answer to the original question. If you have more context or details about the query, I'd be happy to help you analyze and interpret the result.\n",
      "CPU times: user 110 ms, sys: 3.59 ms, total: 114 ms\n",
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection1, pg_collection1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bf51591-ba4f-43b6-9c63-e70df33b578f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT Producer, COUNT(*) as Total_Flights \n",
      "FROM airline_db.flights \n",
      "GROUP BY Producer;\n",
      "\n",
      "1054 (42S22): Unknown column 'Producer' in 'field list'\n",
      "CPU times: user 112 ms, sys: 6.4 ms, total: 119 ms\n",
      "Wall time: 607 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"What is the total count of flights per producer?\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection1, pg_collection1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d524f72-c687-49a0-8dbc-21476fbcedcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2970425-61a7-489d-b133-3cbf0d6e85b9",
   "metadata": {},
   "source": [
    "We can observe that ChromaDB was unable to retrieve the correct table schema for the \"airplanes\" table. The issue arose due to a confusion caused by a foreign key reference. Specifically, ChromaDB retrieved the \"flights\" table instead of the \"airplanes\" table because the \"flights\" table contains a field called \"Airplane_id\" which references the \"airplanes\" table as a foreign key. This foreign key reference led to the confusion, resulting in ChromaDB retrieving the wrong table.\n",
    "\n",
    "To mitigate this issue, we will use a more robust embedding model like the `Amazon Titan Embedding Model`.\n",
    "\n",
    "We will see this in action in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a5731-2f4c-46f0-b03a-c417338064ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enhanced Schema Retrieval with an Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c58d4-9330-438a-9aa6-72340fdc4b64",
   "metadata": {},
   "source": [
    "In this approach, we will use an embedding model from AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee69c27-b639-4380-9f32-356f18b55584",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Ingest docs into ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746786d7-8ab0-4b99-b57e-efdba7f1131c",
   "metadata": {
    "tags": []
   },
   "source": [
    "After the data is preprocessed, the next step is to ingest all `docs` into ChromaDB using your selected embedding model (`Amazon SageMaker BGE Large English` or `Amazon Titan Embedding V2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ea54fec-5074-44bc-bff5-b5b1e7e4a4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create embedding function with AWS\n",
    "if embedding_selected_service == \"Amazon SageMaker\":\n",
    "    aws_ef = AmazonSageMakerEmbeddingFunction()\n",
    "else:\n",
    "    session = boto3.Session()\n",
    "    aws_ef = AmazonBedrockEmbeddingFunction(\n",
    "        session=session,\n",
    "        model_name=DEFAULT_EMBEDDING_MODEL_ID\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3ca323c-68c2-41cb-afbc-03fece3db46b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create collection using Amazon Titan Embedding model\n",
    "collection2 = chroma_client.get_or_create_collection(name=\"table-schemas-aws-embedding-model\", \n",
    "                                                     embedding_function=aws_ef, \n",
    "                                                     metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "# Add docs to the collection.\n",
    "collection2.add(\n",
    "    documents=[\n",
    "        doc1,\n",
    "        doc2,\n",
    "        doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"mysql\", \"database\": mySQL_db_name, \"table_name\": table_airplanes},\n",
    "        {\"source\": \"mysql\", \"database\": mySQL_db_name, \"table_name\": table_flights},\n",
    "        {\"source\": \"mysql\", \"database\": mySQL_db_name, \"table_name\": f\"{table_airplanes}-{table_flights}\" }\n",
    "    ],\n",
    "    ids=[table_airplanes, table_flights, f\"{table_airplanes}-{table_flights}\"], # unique for each doc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aed642b4-3e28-4674-9a02-66db7734b28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create collection using Amazon Titan Embedding model\n",
    "pg_collection2 = chroma_client.get_or_create_collection(name=\"pg-table-schemas-aws-embedding-model\", \n",
    "                                                        embedding_function=aws_ef, \n",
    "                                                        metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "# Add docs to the collection.\n",
    "pg_collection2.add(\n",
    "    documents=[\n",
    "        pg_doc1,\n",
    "        pg_doc2,\n",
    "        pg_doc3\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"postgresql\", \"database\": pg_db_name, \"table_name\": pg_table_airplanes},\n",
    "        {\"source\": \"postgresql\", \"database\": pg_db_name, \"table_name\": pg_table_flights},\n",
    "        {\"source\": \"postgresql\", \"database\": pg_db_name, \"table_name\": f\"{pg_table_airplanes}-{pg_table_flights}\" }\n",
    "    ],\n",
    "    ids=[pg_table_airplanes, pg_table_flights, f\"{pg_table_airplanes}-{pg_table_flights}\"], # unique for each doc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec741334-b2ac-4d27-b11e-ee365dadf0fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Execute Few Shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265c0a3-40d9-482b-98ff-1077b358cecd",
   "metadata": {},
   "source": [
    "In this example, we expect the table `airplanes` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2b9a734-4898-4e00-9df1-af448acb5424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "SELECT COUNT(Airplane_id) FROM airline_db.airplanes;\n",
      "\n",
      "sql_results = \n",
      "(20,)\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Unfortunately, the provided SQL query result `(20,)` is not a complete or meaningful result set. It appears to be a single value enclosed in parentheses, which is not a typical format for SQL query results.\n",
      "\n",
      "However, assuming the result is a single value representing the count of airplanes, I'll provide an analysis and interpretation.\n",
      "\n",
      "**Analysis:**\n",
      "\n",
      "The result `(20,)` suggests that the SQL query has returned a single value, which is `20`. This value likely represents the total count of airplanes in the database.\n",
      "\n",
      "**Interpretation:**\n",
      "\n",
      "Based on the result, we can conclude that there are **20** airplanes in the database. This count may include all types of airplanes, such as commercial airliners, private jets, or military aircraft.\n",
      "\n",
      "**Answer to the original question:**\n",
      "\n",
      "What is the total count of airplanes?\n",
      "\n",
      "The total count of airplanes is **20**.\n",
      "CPU times: user 17.5 ms, sys: 200 μs, total: 17.7 ms\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"What is the total count of airplanes?\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection2, pg_collection2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98128cd2-4164-4c8e-a534-d41521a9390a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT Producer, COUNT(*) as Total_flights\n",
      "FROM airline_db.flights\n",
      "JOIN airline_db.airplanes ON flights.Airplane_id = airplanes.Airplane_id\n",
      "GROUP BY Producer\n",
      "\n",
      "\n",
      "sql_results = \n",
      "('Boeing', 4)\n",
      "('Airbus', 8)\n",
      "('Embraer', 5)\n",
      "('Bombardier', 3)\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query results, we can see that the total count of flights per producer is:\n",
      "\n",
      "* Boeing: 4\n",
      "* Airbus: 8\n",
      "* Embraer: 5\n",
      "* Bombardier: 3\n",
      "\n",
      "To answer the original question, we can interpret these results as follows:\n",
      "\n",
      "* Boeing has the highest total count of flights with 4, indicating that they have the most flights among the four producers.\n",
      "* Airbus has the highest total count of flights with 8, indicating that they have the most flights among the four producers.\n",
      "* Embraer has a moderate total count of flights with 5, indicating that they have a decent number of flights, but not as many as Airbus or Boeing.\n",
      "* Bombardier has the lowest total count of flights with 3, indicating that they have the fewest flights among the four producers.\n",
      "\n",
      "Overall, the results suggest that Airbus has the largest market share in terms of flights, followed by Boeing, Embraer, and then Bombardier.\n",
      "CPU times: user 18.3 ms, sys: 0 ns, total: 18.3 ms\n",
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"What is the total count of flights per producer?\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection2, pg_collection2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86a1b-087f-46c8-8509-5385299e9832",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this second example, we expect the table `airplanes` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0a9fffb-4ebb-4c89-a41f-6e74dc214bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT COUNT(DISTINCT Producer) FROM airline_db.airplanes\n",
      "\n",
      "\n",
      "sql_results = \n",
      "(4,)\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the SQL query result `(4,)`, it appears that the query is returning a single value, which is `4`.\n",
      "\n",
      "In the context of the original question, \"How many unique airplane producers are represented in the database?\", the result suggests that there are 4 unique airplane producers in the database.\n",
      "\n",
      "This means that the database contains information about 4 different airplane manufacturers, and these are the only unique producers represented in the database.\n",
      "CPU times: user 12.2 ms, sys: 2.51 ms, total: 14.7 ms\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"How many unique airplane producers are represented in the database?\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection2, pg_collection2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ab7a3-bb1b-4f1b-82d1-4e02f8d40848",
   "metadata": {},
   "source": [
    "For this third example, we expect the table `flights` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd806b74-efe4-4701-8a3e-480e8a456074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT Arrival_date, COUNT(Destination) as Total_flights\n",
      "FROM airline_db.flights\n",
      "GROUP BY Arrival_date, Destination\n",
      "\n",
      "\n",
      "sql_results = \n",
      "('2023-06-15', 1)\n",
      "('2023-07-02', 1)\n",
      "('2023-06-24', 1)\n",
      "('2023-06-19', 1)\n",
      "('2023-06-27', 1)\n",
      "('2023-06-25', 1)\n",
      "('2023-06-29', 1)\n",
      "('2023-07-03', 1)\n",
      "('2023-06-17', 1)\n",
      "('2023-06-21', 1)\n",
      "('2023-06-28', 1)\n",
      "('2023-06-20', 1)\n",
      "('2023-06-22', 1)\n",
      "('2023-06-30', 1)\n",
      "('2023-06-16', 1)\n",
      "('2023-06-23', 1)\n",
      "('2023-07-01', 1)\n",
      "('2023-06-18', 1)\n",
      "('2023-06-26', 1)\n",
      "('2023-07-04', 1)\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, it appears that the query is attempting to group flights by arrival date and count the total number of flights for each destination.\n",
      "\n",
      "However, the results do not seem to match the expected output, as the query results only contain a single column with a date and a count of 1 for each row. This suggests that the query is not correctly grouping the flights by destination.\n",
      "\n",
      "To answer the original question, we would need to see the actual query and the correct results. However, based on the provided results, it seems that the query is not correctly grouping the flights by destination.\n",
      "\n",
      "Here is an example of how the query could be modified to correctly group the flights by destination and arrival date:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "    arrival_date,\n",
      "    destination,\n",
      "    COUNT(*) as total_flights\n",
      "FROM \n",
      "    flights\n",
      "GROUP BY \n",
      "    arrival_date,\n",
      "    destination\n",
      "ORDER BY \n",
      "    arrival_date,\n",
      "    destination;\n",
      "```\n",
      "\n",
      "This query would group the flights by both arrival date and destination, and count the total number of flights for each group. The results would show the arrival date, destination, and total number of flights for each group.\n",
      "\n",
      "Without the actual query and results, it's difficult to provide a more detailed analysis and interpretation. However, based on the provided results, it seems that the query is not correctly grouping the flights by destination.\n",
      "CPU times: user 14.5 ms, sys: 648 μs, total: 15.2 ms\n",
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"Get the total number of flights scheduled for each destination, grouped by arrival date\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection2, pg_collection2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199367e-7117-4553-b2f6-47073cb17769",
   "metadata": {},
   "source": [
    "For this fourth example, we expect the table `airplanes` and `flights` to be included for the SQL llm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a62f3823-367d-47a1-a0de-e4babe42ef08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB - Schema Retrieval: \n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.airplanes -- Table name\n",
      "(\n",
      "Airplane_id INT(10), -- airplane id\n",
      "Producer VARCHAR(20), -- name of the producer\n",
      "Type VARCHAR(10), -- airplane type\n",
      "PRIMARY KEY (Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "<table_schema>\n",
      " CREATE TABLE airline_db.flights -- Table name\n",
      "(\n",
      "Flight_number VARCHAR(10), -- flight id\n",
      "Arrival_time VARCHAR(20), -- arrival time (YYYY-MM-DDTH:M:S)\n",
      "Arrival_date VARCHAR(20), -- arrival date (YYYY-MM-DD)\n",
      "Departure_time VARCHAR(20), -- departure time (YYYY-MM-DDTH:M:S)\n",
      "Departure_date VARCHAR(20), -- departure date (YYYY-MM-DD)\n",
      "Destination VARCHAR(20), -- destination\n",
      "Airplane_id INT(10), -- airplane id\n",
      "PRIMARY KEY (Flight_number),\n",
      "FOREIGN KEY (Airplane_id) REFERENCES airplanes(Airplane_id)\n",
      ")\n",
      " \n",
      "</table_schema>\n",
      "\n",
      "Using [Amazon Bedrock] to generate SQL for [mysql]\n",
      "\n",
      "\n",
      "LLM SQL Query: \n",
      "\n",
      "SELECT A.Airplane_id, A.Producer \n",
      "FROM airline_db.airplanes A \n",
      "JOIN airline_db.flights F ON A.Airplane_id = F.Airplane_id \n",
      "WHERE F.Destination = 'New York';\n",
      "\n",
      "\n",
      "sql_results = \n",
      "(6, 'Airbus')\n",
      "\n",
      "Calling LLM on [Amazon Bedrock] to Analyze and interpret the results from SQL query in relation to the original question.\n",
      "\n",
      "\n",
      "LLM SQL Analysis: \n",
      "Based on the provided SQL query results, we can see that there is only one airplane ID and producer listed: (6, 'Airbus').\n",
      "\n",
      "To answer the original question, \"Find the airplane IDs and producers for airplanes that have flown to New York,\" we can infer that the airplane with ID 6 and producer 'Airbus' has flown to New York.\n",
      "\n",
      "However, without more information or context about the original query or the database schema, it's difficult to provide a more detailed analysis or interpretation of the results. If you could provide more context or information about the original query, I'd be happy to try and help further.\n",
      "CPU times: user 10.9 ms, sys: 3.97 ms, total: 14.9 ms\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Business question\n",
    "question = \"Find the airplane IDs and producers for airplanes that have flown to New York\"\n",
    "\n",
    "RunPrompts(llm_selected_db, llm_selected_service, question, collection2, pg_collection2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce768358-c208-4c81-acff-ecb39b904b91",
   "metadata": {},
   "source": [
    "### Step 3: Conclusion\n",
    "\n",
    "We can observe that ChromaDB and `Amazon Titan Embedding` model were able to retrieve the correct table schemas for the previous examples.  After successfully implementing these solutions, the issue of incorrectly retrieved table schemas due to foreign key confusions was effectively addressed. The data retrieval process became more accurate and reliable, ensuring that the correct table schemas were consistently retrieved, even in the presence of complex table relationships and foreign key references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5c40f-5e79-4b0a-9c0a-fa16b8195b6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b500a5c-16cc-4d23-9d06-8666928daa6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 μs, sys: 0 ns, total: 4 μs\n",
      "Wall time: 6.91 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Delete resources\n",
    "if llm_selected_service == 'Amazon SageMaker':\n",
    "    llm_predictor.delete_model()\n",
    "    llm_predictor.delete_endpoint()\n",
    "\n",
    "if embedding_selected_service == 'Amazon SageMaker':\n",
    "    embedding_predictor.delete_model()\n",
    "    embedding_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015474d-4387-447d-97a9-e4ae662d49d4",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
