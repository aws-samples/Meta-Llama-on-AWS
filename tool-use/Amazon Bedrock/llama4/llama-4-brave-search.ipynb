{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function Calling with Llama 4 Models**\n",
    "Welcome to this notebook exploring function calling capabilities with Meta's Llama 4 models. Llama 4, the latest iteration in the Llama family, introduces native support for function calling, marking a significant advancement in the model's capabilities and potential applications.\n",
    "\n",
    "![Llamas](imgs/llama-pic.jpeg)\n",
    "\n",
    "\n",
    "### **Function Calling Overview**\n",
    "Function calling, also known as tool use, allows Llama 4 to interact with external tools or APIs by generating structured outputs. This capability enables more complex, multi-step interactions between the model and available tools, enhancing its problem-solving abilities and practical applications.\n",
    "\n",
    "### **Amazon Bedrock**\n",
    "![bedrock](imgs/bedrock-img.png)\n",
    "\n",
    "Amazon Bedrock is a fully managed service that provides access to a wide range of powerful foundation models (FMs) through a unified API. It offers models from leading AI companies like Mistral, Anthropic, AI21 Labs, Cohere, Stability AI, and Amazon's own Titan models.\n",
    "\n",
    "- **Unified API**: Bedrock provides a single API endpoint to access different models, simplifying integration and allowing developers to experiment with or switch between models with minimal code changes.\n",
    "- **Serverless and Fully Managed**: As a fully managed service, Bedrock eliminates the need for users to handle infrastructure management, making it easier to build and deploy generative AI applications.\n",
    "- **Model Customization**: Users can customize models with their own data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG).\n",
    "- **Security and Privacy**: Bedrock offers built-in security features, ensuring data privacy and compliance with various standards. It follows best practices like encrypting all data and preventing third parties from accessing user data.\n",
    "- **Agents for Complex Tasks**: Bedrock allows the creation of agents that can plan and execute multi-step tasks using enterprise systems and data sources.\n",
    "- **Integration with AWS Services**: Bedrock can be easily integrated with other AWS services and existing applications.\n",
    "- **Model Evaluation**: A new capability that helps customers assess, compare, and select the best model for their application.\n",
    "- **Guardrails**: Bedrock provides tools to implement safeguards tailored to application needs and aligned with responsible AI policies.\n",
    "- **Custom Model Import**: A new feature that allows customers to import and access their own custom models as a fully managed API in Bedrock.\n",
    "- **Playground Environment**: Bedrock offers Playgrounds (text, chat, and image) to compare models and experiment with different options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview in the Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Amazon Bedrock chat playground with Llama 4 17B Scout and Maverick Instruct models as a quick way to demonstrate function calling.  There are two ways of invoking function calling: one is the ```Python``` way and the other is the ```JSON``` way.  The essential difference between the two is that in the ```Python``` method, the Llama 4 models have been trained to recognize a small number of functions natively.  These functions are: ```wolfram_alpha```, ```brave_search``` and ```code_interpreter```.  In other words the models have been trained to recognize when they should call and how to call functions for computation, internet search and code.  They also have been trained to respond in a **zero shot** fashion to tool definitions they have not seen before.  This is the ```JSON``` method.  Both methods will be demonstrated in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brave Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brave Search is an independent browser which does not track user activity.  Brave Search API's have free tiers, although you must provide payment details. In order to send requests to the API, we need to create an account and get the API token.\n",
    "\n",
    "1) To get API key we will first register for an account [Register for an Account](https://api.search.brave.com/register). \n",
    "2) After the account is created, you can navigate to the [Subscriptions page](https://api.search.brave.com/app/subscriptions/subscribe?tab=ai) where you should select the **Free AI** subscription.  You are required to enter payment details.\n",
    "3) Having created a subscription then navigate to the [API Keys](https://api.search.brave.com/app/keys) and generate an API Key, selecting the **Free AI** subscription you just created. After that you will have access to a token, which you will use for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To begin with, let's check that we can call the Brave Search API and familiarise ourselves with the structure of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U boto3 colorama==0.4.6 brave-search==0.1.8 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import boto3\n",
    "import getpass\n",
    "import requests\n",
    "import urllib.parse\n",
    "from PIL import Image\n",
    "from colorama import Fore\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError\n",
    "from brave import Brave\n",
    "\n",
    "\n",
    "session = boto3.Session()\n",
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Before you continue, please add your Brave Search API token below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your brave-search-api-token········\n"
     ]
    }
   ],
   "source": [
    "api_token = getpass.getpass('Please enter your brave-search-api-token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mQuestion: What are the top 10 albums of 2025\n",
      "\u001b[94m==================\n",
      "Title: The Best Albums of 2025 - Album of The Year\n",
      "URL: https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1\n",
      "Description: The best music <strong>of</strong> <strong>2025</strong>. Music reviews, ratings, news and more.\n",
      "\u001b[94m==================\n",
      "Title: Best Albums of 2025 (So Far): Album of the Year Contenders\n",
      "URL: https://www.vulture.com/article/best-albums-of-the-year-2025.html\n",
      "Description: A candid posthumous release plus a soundtrack for bedrooms and basements.\n"
     ]
    }
   ],
   "source": [
    "# We intend to ask the model a question where the knowledge cannot be in the model's training data.\n",
    "# In other words, something that has changed recently.\n",
    "# We will use that question, un-modified, as the query to the search engine.\n",
    "# You will notice when we integrate with Bedrock that the model will decide the exact search engine query text.\n",
    "#question = \"What are the names of the candidates who will contest the US Presidential Election on Tuesday November 5 2024?\"\n",
    "question = \"What are the top 10 albums of 2025\"\n",
    "\n",
    "print(f\"{Fore.YELLOW}Question: {question}\")\n",
    "\n",
    "query = urllib.parse.quote_plus(question)\n",
    "safesearch=urllib.parse.quote_plus('strict')\n",
    "limit_results = 2\n",
    "query_url = f\"https://api.search.brave.com/res/v1/web/search?q={query}&count={limit_results}&safesearch={safesearch}\"\n",
    "headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Accept-Encoding\": \"gzip\",\n",
    "        \"X-Subscription-Token\": api_token\n",
    "    }\n",
    "\n",
    "request = requests.get(query_url, headers=headers)\n",
    "content = request.content\n",
    "\n",
    "# Check if the content starts with the gzip magic number\n",
    "if content.startswith(b'\\x1f\\x8b'):\n",
    "    try:\n",
    "        decompressed_response = gzip.decompress(content)\n",
    "    except gzip.BadGzipFile:\n",
    "        # If decompression fails, use the original content\n",
    "        decompressed_response = content\n",
    "else:\n",
    "    # If it's not gzip, use the original content\n",
    "    decompressed_response = content\n",
    "\n",
    "# Parse the JSON response\n",
    "try:\n",
    "    search_results = json.loads(decompressed_response)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse JSON response\")\n",
    "    search_results = None\n",
    "\n",
    "# Check if we have valid results\n",
    "if search_results and 'web' in search_results and 'results' in search_results['web']:\n",
    "    # Iterate through the search results\n",
    "    for result in search_results['web']['results']:\n",
    "        # Access different fields of each result\n",
    "        title = result.get('title', 'No title')\n",
    "        url = result.get('url', 'No URL')\n",
    "        description = result.get('description', 'No description')\n",
    "\n",
    "        # Print or process the data as needed\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}==================\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"Description: {description}\")\n",
    "\n",
    "else:\n",
    "    print(f\"{Fore.LIGHTRED_EX}===============\")\n",
    "    print(\"No valid search results found in the response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a Python package for the Brave Search API which helps to make the request and parse the results.  The following code snippet shows the use of that library to display the same information as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mQuestion: What are the top 10 albums of 2025\n",
      "\u001b[94m==================\n",
      "Title: The Best Albums of 2025 - Album of The Year\n",
      "URL: https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1\n",
      "Description: The best music <strong>of</strong> <strong>2025</strong>. Music reviews, ratings, news and more.\n",
      "\u001b[94m==================\n",
      "Title: Best Albums of 2025 (So Far): Album of the Year Contenders\n",
      "URL: https://www.vulture.com/article/best-albums-of-the-year-2025.html\n",
      "Description: A candid posthumous release plus a soundtrack for bedrooms and basements.\n"
     ]
    }
   ],
   "source": [
    "brave = Brave(api_token)\n",
    "\n",
    "#question = \"What are the names of the candidates who will contest the US Presidential Election on Tuesday November 5 2024?\"\n",
    "question = \"What are the top 10 albums of 2025\"\n",
    "\n",
    "print(f\"{Fore.YELLOW}Question: {question}\")\n",
    "\n",
    "limit_results = 2\n",
    "\n",
    "search_results = brave.search(q=question, count=limit_results)\n",
    "\n",
    "for result in search_results.web_results:\n",
    "    # Access different fields of each result\n",
    "    title = result[\"title\"]\n",
    "    url = result[\"url\"]\n",
    "    description = result[\"description\"]\n",
    "\n",
    "    # Print or process the data as needed\n",
    "    print(f\"{Fore.LIGHTBLUE_EX}==================\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Description: {description}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for the Web Search can be found here: https://api.search.brave.com/app/documentation/web-search/get-started.\n",
    "\n",
    "For the avoidance of doubt, Brave Search is returning a set of results from which we are extracting: title; url and description.  This is not a coherent natural language response to our question but rather, information which will augment the foundation model's answer.  Let's integrate the use of Brave Search into Amazon Bedrock to see how the model uses the tool.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating into Bedrock\n",
    "\n",
    "Now that we know how to use the Brave Search API we can integrate it into Amazon Bedrock using the [Amazon Bedrock Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html). We will do this in 2 ways. Firstly, we will use the ```function``` calling capability inherent in the Llama 4 models.  We've previously referred to this as the ```Python``` method.  Secondly, we will use the Bedrock ```tool``` calling method and rely on the **zero shot** capability of the model.  We've previously referred to this as the ```JSON``` method.\n",
    "\n",
    "The essential difference is how the LLM notifies the executor that it would like to call a function and then how the executor threads the function call completion back into the conversation.\n",
    "\n",
    "Let's go ahead and set up the conversation with the model in Amazon Bedrock.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelId = 'meta.llama4-maverick-17b-instruct-v1:0'\n",
    "#modelId = 'meta.llama4-scout-17b-instruct-v1:0'\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url='https://preprod.us-east-1.dataplane.bedrock.aws.dev'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama Function Calling - Python Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mResponse: <|python_start|>brave_search.call(query=\"top 10 albums of 2025\")<|python_end|>\n"
     ]
    }
   ],
   "source": [
    "#question = \"What are the names of the candidates who will contest the US Presidential Election on Tuesday November 5 2024?\"\n",
    "question = \"What are the top 10 albums of 2025\"\n",
    "\n",
    "system_prompt = \"Environment: ipython /r/n \" \\\n",
    "                \"Tools: brave_search /r/n\" \\\n",
    "                \"Cutting Knowledge Date: August 2024 /r/n\" \\\n",
    "                \"Today Date: 22 April 2025 /r/n\" \\\n",
    "                \"You are a helpful assistant.\" \n",
    "    \n",
    "system = [{\"text\": system_prompt}]\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": question}]}]\n",
    "\n",
    "converse_api_params = {\n",
    "    \"modelId\": modelId,\n",
    "    \"system\": system,\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": {\"temperature\": 0.0, \"maxTokens\": 2048},\n",
    "}\n",
    "\n",
    "response = bedrock_client.converse(**converse_api_params)\n",
    "print(f\"{Fore.GREEN}Response: {response['output']['message']['content'][0]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can parse the text of the response, recognize the ```<|python_start|>``` and ```<|python_end|>``` and forward the call to the ```executor```.  Let's write a simple ```executor``` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Writing the executor\n",
    "The ```executor``` will parse the string response from the LLM which represents a function call and map it to the internal executable representation which will make the call and return the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BraveSearchPython:\n",
    "    api_token = None\n",
    "    args = {}\n",
    "    \n",
    "    def __init__(self, token, function_call):\n",
    "        self.api_token = token\n",
    "        string = function_call.split(\"(\")[1].split(\")\")[0]\n",
    "        for match in re.findall(r\"(\\w+)=(?:'((?:[^'\\\\]|\\\\.)*)'\"\n",
    "                                r\"|\\\"((?:[^\\\"\\\\]|\\\\.)*)\\\"|(\\d+))\", string):\n",
    "            key = match[0]\n",
    "            value = match[1] if match[1] else match[2] if match[2] else int(match[3])\n",
    "            if value and \"'\" in value:\n",
    "                value = value.replace(\"\\\\'\", \"'\")\n",
    "            if value and '\"' in value:\n",
    "                value = value.replace('\\\\\"', '\"')\n",
    "            self.args[key] = value\n",
    "        self.args[\"count\"] = 2\n",
    "        \n",
    "    def call(self, query, count) -> []:\n",
    "\n",
    "        brave = Brave(self.api_token)\n",
    "        search_results = brave.search(q=query, count=count)\n",
    "        results = []\n",
    "        \n",
    "        for result in search_results.web_results:\n",
    "            results.append({'title': result[\"title\"], 'url': result[\"url\"], 'description': result[\"description\"][:200]})\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialising the executor and calling Amazon Bedrock\n",
    "If the response begins with ```<|python_start|>, <|python_end|>``` then gather the function call and pass it to the ```executor```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_search_between(text, start, end):\n",
    "    pattern = re.escape(start) + \"(.*?)\" + re.escape(end)\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"\"\n",
    "\n",
    "#re_search_between(function_invocation_response, \"<|python_start|>\", \"<|python_end|>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mMessages:\n",
      "\n",
      "{'role': 'user', 'content': [{'text': 'What are the top 10 albums of 2025'}]}\n",
      "{'role': 'assistant', 'content': [{'text': '<|python_start|>brave_search.call(query=\"top 10 albums of 2025\")<|python_end|>'}]}\n",
      "{'role': 'user', 'content': [{'text': \"[{'title': 'The Best Albums of 2025 - Album of The Year', 'url': HttpUrl('https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1'), 'description': 'The best music <strong>of</strong> <strong>2025</strong>. Music reviews, ratings, news and more.'}, {'title': 'Best Albums of 2025 (So Far): Album of the Year Contenders', 'url': HttpUrl('https://www.vulture.com/article/best-albums-of-the-year-2025.html'), 'description': 'A candid posthumous release plus a soundtrack for bedrooms and basements.'}]\"}]}\n",
      "\u001b[32mResponse: The top 10 albums of 2025 are not available as the year is still ongoing. However, you can check the following websites for the latest updates on the best albums of 2025:\n",
      "\n",
      "1. Album of the Year - https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1\n",
      "2. Vulture - https://www.vulture.com/article/best-albums-of-the-year-2025.html\n",
      "\n",
      "These websites provide ratings, reviews, and news about the latest music releases. You can visit them to stay updated on the top albums of 2025.\n"
     ]
    }
   ],
   "source": [
    "function_invocation_response = (response['output']['message']['content'][0]['text'])\n",
    "messages.append(response['output']['message'])\n",
    "\n",
    "if re_search_between(function_invocation_response, \"<|python_start|>\", \"<|python_end|>\"):\n",
    "    function_call = re_search_between(function_invocation_response, \"<|python_start|>\", \"<|python_end|>\")\n",
    "else:\n",
    "    function_call = None\n",
    "\n",
    "if function_call:\n",
    "    pythonsearch = BraveSearchPython(api_token, function_call)\n",
    "    \n",
    "    tool_response = getattr(pythonsearch, 'call')(**pythonsearch.args)\n",
    "    # note the use of the user role here when it is actually the assistant\n",
    "    messages.append({\"role\": \"user\", \"content\": [{\"text\": str(tool_response)}]})\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE}Messages:\\n\")\n",
    "for m in messages:\n",
    "    print(f\"{m}\")\n",
    "\n",
    "response = bedrock_client.converse(**converse_api_params)\n",
    "\n",
    "print(f\"{Fore.GREEN}Response: {response['output']['message']['content'][0]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can see there are some implementation details that are sub-optimal using this method.  Firstly, parsing the ```<|python_start|>, <|python_end|>``` is inelegant and the code is difficult to understand.  Secondly, the turn choreography forces us to either mis-represent the tool results as having been provided by the ```user``` or not append the message with the ```function_invocation_response``` to the messages collection, mis-representing the flow of the conversation.  Neither of which are ideal.  We can try again by injecting Llama 4 special tokens into the messages.  In particular we will use the ```<eom>``` [end of message](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/#built-in-python-based-tool-calling) tag which indicates the ```assistant``` is engaged in multi-step reasoning and therefore can support multiple contiguous ```assistant``` messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Threading the Llama 4 Special Tokens\n",
    "We will clear out all but the original ```user``` message from the message collection and add an edited first ```assistant``` message: the message invoking the tool.  We'll edit that by adding the ```<eom>``` tag and then play the conversation forward but, faithfully adding the result of calling the tool as an ```assistant``` message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mMessages:\n",
      "\n",
      "{'role': 'user', 'content': [{'text': 'What are the top 10 albums of 2025'}]}\n",
      "{'role': 'assistant', 'content': [{'text': '<|python_start|>brave_search.call(query=\"top 10 albums of 2025\")<|python_end|><|eom|>'}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"[{'title': 'The Best Albums of 2025 - Album of The Year', 'url': HttpUrl('https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1'), 'description': 'The best music <strong>of</strong> <strong>2025</strong>. Music reviews, ratings, news and more.'}, {'title': 'Best Albums of 2025 (So Far): Album of the Year Contenders', 'url': HttpUrl('https://www.vulture.com/article/best-albums-of-the-year-2025.html'), 'description': 'A candid posthumous release plus a soundtrack for bedrooms and basements.'}]\"}]}\n",
      "\u001b[32mResponse: The top 10 albums of 2025 are not available as the year is still ongoing. However, you can check the following websites for the latest updates on the best albums of 2025:\n",
      "\n",
      "1. Album of the Year - https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1\n",
      "2. Vulture - https://www.vulture.com/article/best-albums-of-the-year-2025.html\n",
      "\n",
      "These websites provide ratings, reviews, and news about the latest music releases. You can visit them to stay updated on the top albums of 2025.\n"
     ]
    }
   ],
   "source": [
    "messages = messages[:1]\n",
    "special_message = function_invocation_response + '<|eom|>'\n",
    "messages.append({\"role\": \"assistant\", \"content\": [{\"text\": special_message}]})\n",
    "\n",
    "function_call = re_search_between(function_invocation_response, \"<|python_start|>\", \"<|python_end|>\")\n",
    "pythonsearch = BraveSearchPython(api_token, function_call)\n",
    "tool_response = getattr(pythonsearch, 'call')(**pythonsearch.args)\n",
    "messages.append({\"role\": \"assistant\", \"content\": [{\"text\": str(tool_response)}]})\n",
    "\n",
    "print(f\"{Fore.BLUE}Messages:\\n\")\n",
    "for m in messages:\n",
    "    print(f\"{m}\")\n",
    "\n",
    "response = bedrock_client.converse(**converse_api_params)\n",
    "\n",
    "print(f\"{Fore.GREEN}Response: {response['output']['message']['content'][0]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Llama Function Calling - JSON Method\n",
    "\n",
    "The other way to use function calling in Llama 4 is the JSON method.  When we previewed in the console we provided a JSON structure in the user message which described the tool use.  The Amazon Bedrock native way of doing this is to provide the JSON definition in the ```toolConfig``` and make use of the [Amazon Bedrock Tool Use capability](https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html) in the Amazon Bedrock Converse API.  That is what we will do now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Writing the tool definition\n",
    "Amazon Bedrock tool use requires a JSON Schema file which describes the function which can be called and its arguments.  In this definition there is a single required argument and a single optional argument.  Note that there are a lot of similarities between the [JSON that Amazon Bedrock requires](https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use-inference-call.html) to recognize the tool and the [JSON that Llama 3.1 models require](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#json-based-tool-calling) but, they are not exactly the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toolConfig = {\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"toolSpec\": {\n",
    "        \"name\": \"brave_search\",\n",
    "        \"description\": \"search the internet using the brave web search api\",\n",
    "        \"inputSchema\": {\n",
    "          \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"User's question\"\n",
    "              },\n",
    "                \"count\" : {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"the maximum number of results to return\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Passing the tool definition to Amazon Bedrock\n",
    "Passing the tool to Amazon Bedrock is a matter of including the ```toolConfig``` in the parameters for the Converse API.  In the presence of the tool, the model formulates a response to the question that is effectively metadata which will be converted to use of the tool by the executor.  Note that the query passed to the tool is not the question the user asked the foundation model.  The model has extracted the salient details for the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mResponse: {'toolUse': {'toolUseId': 'tooluse_KKxkNMwARDa_0zqip5kl9Q', 'name': 'brave_search', 'input': {'count': 10, 'query': 'top albums 2025'}}}\n"
     ]
    }
   ],
   "source": [
    "#question = 'What are the names of the candidates who will contest the US Presidential Election on Tuesday November 5 2024?'\n",
    "question = \"What are the top 10 albums of 2025\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert in composing functions. You are given a question and a set of possible functions.\n",
    "Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\n",
    "If none of the functions can be used, point it out. If the given question lacks the parameters required by the function, also\n",
    "point it out. You should only return the function call in tools call sections.\n",
    "If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1,\n",
    "params_name2=params_value2...), func_name2(params)] \n",
    "\n",
    "You SHOULD NOT include any other text in the response.\n",
    "\n",
    "Here is a list of functions in JSON format that you can invoke.\n",
    "\n",
    "\"\"\"\n",
    "system = [{\"text\": system_prompt}]\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": question}]}]\n",
    "\n",
    "converse_api_params = {\n",
    "    \"modelId\": modelId,\n",
    "    \"system\": system,\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": {\"temperature\": 0.0, \"maxTokens\": 2048},\n",
    "    \"toolConfig\": toolConfig\n",
    "}\n",
    "'''\n",
    "converse_api_params = {\n",
    "    \"modelId\": modelId,\n",
    "    \"system\": system,\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": {\"temperature\": 0.0, \"maxTokens\": 2048}\n",
    "}\n",
    "'''\n",
    "response = bedrock_client.converse(**converse_api_params)\n",
    "print(f\"{Fore.GREEN}Response: {response['output']['message']['content'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Writing the executor\n",
    "The ```executor``` will parse the JSON response from the LLM which represents a function call and map it to the internal executable representation which will make the call and return the results. We've already written one for the ```Python``` method so we are familiar with the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BraveSearchJson:\n",
    "    api_token = None\n",
    "    toolUseId = None\n",
    "    args = {}\n",
    "    \n",
    "    def __init__(self, token, function_call):\n",
    "        self.api_token = token\n",
    "        self.toolUseId = function_call['toolUseId']\n",
    "        self.args = function_call['input']\n",
    "        \n",
    "    def call(self, query, count) -> []:\n",
    "\n",
    "        brave = Brave(self.api_token)\n",
    "        search_results = brave.search(q=query, count=int(count))\n",
    "        results = []\n",
    "        \n",
    "        for result in search_results.web_results:\n",
    "            results.append({'title': result[\"title\"], 'url': result[\"url\"], 'description': result[\"description\"][:200]})\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initialising the executor and calling Amazon Bedrock\n",
    "If the response is of type ```toolUse``` then gather the function call and pass it to the ```executor```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tooluse_KKxkNMwARDa_0zqip5kl9Q\n",
      "\u001b[34mMessages:\n",
      "\n",
      "{'role': 'user', 'content': [{'text': 'What are the top 10 albums of 2025'}]}\n",
      "{'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_KKxkNMwARDa_0zqip5kl9Q', 'name': 'brave_search', 'input': {'count': 10, 'query': 'top albums 2025'}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_KKxkNMwARDa_0zqip5kl9Q', 'content': [{'text': \"[{'title': 'The Best Albums of 2025 - Album of The Year', 'url': HttpUrl('https://www.albumoftheyear.org/ratings/6-highest-rated/2025/1'), 'description': 'The best music of <strong>2025</strong>. Music reviews, ratings, news and more.'}, {'title': 'The 20 Best Albums of 2025 So Far', 'url': HttpUrl('https://pitchfork.com/features/lists-and-guides/best-music-2025-so-far/'), 'description': 'A rolling list of our favorite <strong>albums</strong> of the year, updated somewhat frequently.'}, {'title': 'r/fantanoforever on Reddit: What are your top albums of 2025 so far?', 'url': HttpUrl('https://www.reddit.com/r/fantanoforever/comments/1iye68a/what_are_your_top_albums_of_2025_so_far/'), 'description': '58 votes, 75 comments. 191K subscribers in the fantanoforever community. The Internet&#x27;s Busiest Music Nerd&#x27;s Subreddit!'}, {'title': 'Looking Ahead: A Release Calendar of Upcoming Albums in 2025', 'url': HttpUrl('https://www.billboard.com/lists/new-albums-2025-calendar-new-music-releases-this-year/'), 'description': 'With surprise <strong>album</strong> news, moving release dates and the sheer number of <strong>album</strong> announcements, it can be hard to stay on <strong>top</strong> of when new music by favori'}, {'title': 'BILLBOARD 200 | Best Selling Music Albums 2025 | Album 200 Chart Best Popular Global TOP Music Hits', 'url': HttpUrl('https://open.spotify.com/playlist/02OPkJckPEPzMwkDmUsA9Y'), 'description': 'Playlist · BILLBOARD 200 | Best Selling Music <strong>Albums</strong> <strong>2025</strong> <strong>|</strong> <strong>Album</strong> 200 Chart Best Popular Global <strong>TOP</strong> Music Hits · 14'}, {'title': 'ARIA Top 50 Albums for week of 21 April 2025', 'url': HttpUrl('https://www.aria.com.au/charts/albums-chart/2025-04-21'), 'description': 'ARIA brings the latest and hottest news about the music industry in and out of Australia. Check out the ARIA <strong>Top</strong> 50 <strong>Albums</strong> Chart of the Week here.'}, {'title': 'Best Music and Albums for 2025 - Metacritic', 'url': HttpUrl('https://www.metacritic.com/browse/albums/score/metascore/year/filtered'), 'description': 'See how well critics are rating the Best Music and <strong>Albums</strong> <strong>for</strong> <strong>2025</strong>'}, {'title': 'Best albums of 2025', 'url': HttpUrl('https://rateyourmusic.com/charts/'), 'description': 'The greatest <strong>albums</strong> of 2024, as voted by RYM/Sonemic users'}, {'title': '25 Great Albums from 2025 So Far (1st Quarter)', 'url': HttpUrl('https://www.brooklynvegan.com/25-great-albums-from-1st-quarter-2025/'), 'description': '25 <strong>albums</strong> we love from the first quarter of <strong>2025</strong>, including FKA twigs, Deafheaven, Great Grandpa, Horsegirl, John Glacier, Jason Isbell, and more.'}, {'title': 'Best new / most anticipated albums of 2025!!! - Page 6 - Sonic Youth Gossip', 'url': HttpUrl('http://www.sonicyouth.com/gossip/showthread.php?t=131964&page=6'), 'description': 'Page 6-Best new / most anticipated <strong>albums</strong> <strong>of</strong> <strong>2025</strong>!!! Non-Sonic Sounds'}]\"}]}}]}\n",
      "\u001b[32mResponse: <|python_start|>{\"type\": \"function\", \"name\": \"brave_search\", \"parameters\": {\"count\": \"10\", \"query\": \"top albums 2025\"}}<|python_end|>\n"
     ]
    }
   ],
   "source": [
    "tool_invocation_response = (response['output']['message']['content'][0]['toolUse'])\n",
    "messages.append(response['output']['message'])\n",
    "\n",
    "#print(tool_invocation_response)\n",
    "if tool_invocation_response:\n",
    "    jsonsearch = BraveSearchJson(api_token, tool_invocation_response)\n",
    "else:\n",
    "    jsonsearch = None\n",
    "\n",
    "print(jsonsearch.toolUseId)\n",
    "\n",
    "if jsonsearch:    \n",
    "    tool_response = getattr(jsonsearch, 'call')(**jsonsearch.args)\n",
    "    #note the use of the user role to return the tool use result\n",
    "\n",
    "    messages.append(\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                'toolResult': {\n",
    "                                    'toolUseId': jsonsearch.toolUseId,\n",
    "                                    'content': [\n",
    "                                        {\n",
    "                                            \"text\": str(tool_response)\n",
    "                                        }\n",
    "                                    ]\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                )\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE}Messages:\\n\")\n",
    "for m in messages:\n",
    "    print(f\"{m}\")\n",
    "\n",
    "response = bedrock_client.converse(**converse_api_params)\n",
    "\n",
    "print(f\"{Fore.GREEN}Response: {response['output']['message']['content'][0]['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of things to note here.  Firstly, there appears to be the same problem with turn choreography as we encountered before.  Unfortunately it is not possible to add the ```<|eom|>``` tag in the ```toolUse``` response and so we must live with the mis-representation of the ```toolResult``` coming from the user.  What's also interesting to note is that we seem to be able to specify the number of results we would like back from Brave Search by using the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
