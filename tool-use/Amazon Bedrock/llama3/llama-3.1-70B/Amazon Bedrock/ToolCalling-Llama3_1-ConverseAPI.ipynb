{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a611416f-45b7-4f5e-b7a5-fa1b1cb0b6a3",
   "metadata": {},
   "source": [
    "## Llama 3.1: Prompt Engineering Guide - Bedrock Converse API Best-Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd2fe9-ded1-4682-9347-6486d1bf5dbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook should work well with the Data Science 3.0 kernel in SageMaker Studio.\n",
    "\n",
    "This guide is designed to assist you in transitioning your Message API prompts to work well with Llama 3.1 and the Bedrock Converse API. Our goal is to demonstrate how Llama 3.1 can is similar to the Messages API formatting for handling specific tasks. While this notebook may not cover every edge case or unique use case scenario, it will provide a strong foundation for starting your journey with Llama 3.1.\n",
    "\n",
    "We will begin by reviewing how to format prompts and create a chat completion interface. Additionally, we will highlight the performance and efficiency of Llama 3.1 through a few examples, illustrating its effectiveness in different applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf1453-083b-4001-8b0e-2eb53f4fd30d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Llama 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464111b1-8c95-4bce-9345-421a60af527f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Llama 3.1 is a high-quality open-source language model developed by Meta. It is designed for a wide range of natural language processing tasks, including text generation, question answering, and more.\n",
    "Llama 3.1 has the following key features:\n",
    "    \n",
    "- Proficient in several languages, including English, French, Italian, German, Spanish, and others.\n",
    "- Context window of up to 128k tokens, allowing for long-form text processing.\n",
    "- Capable of handling various tasks, such as text generation, summarization, and question answering.\n",
    "- Generates coherent and fluent responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2c034-a9b7-4ba8-b4db-2eb03f54f99e",
   "metadata": {},
   "source": [
    "## How to Format Prompts for Llama 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9105c8a-0734-47a2-8e95-7e6671022f63",
   "metadata": {},
   "source": [
    "Here we will describe the prompt format for Llama 3.1 with it's emphasis on new features.\n",
    "\n",
    "- **<|begin_of_text|> Token:** This token denotes the beginning of a prompt. Llama 3.1 will understand that there will be no other tokens before this special beginning of sequence token.\n",
    "- **<|end_of_text|> Token:** This token denotes the end of a prompt. Llama 3.1 will understand that there will be no other tokens after this special end of sequence token.\n",
    "- **<|start_header_id|> and <|end_header_id|> Tokens:** These tokens enclose the role for a particular message. The possible roles are system, user, assistant, and ipython.\n",
    "- **<|eot_id|> Token:** End of turn. Represents when the model has determined that it has finished interacting with the user message that initiated its response.\n",
    "- **<|eom_id|> Token:** End of message. Represents a possible stopping point for execution where the model can inform the executor that a tool call needs to be made.\n",
    "- **<|python_tag|> Token:** Used in the modelâ€™s response to signify a tool call.\n",
    "\n",
    "When invoking the Amazon Bedrock Converse API, these tokens are extracted to ensure that you can run inference without needing to use the special tokens ingested into the prompt. We will take a look in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b739f86-d0fc-4264-afea-f3cdf6d1927c",
   "metadata": {},
   "source": [
    "## Comparison with the Messages API format\n",
    "\n",
    "If you have used OpenAI models and other platforms that use the messages API format for chat completion API, you will see that instructions for the model go into a system/user/assistant format:\n",
    "\n",
    "- System Role: This role sets the context or instructions for the model.\n",
    "- User Role: This role includes the specific task or question posed to the model.\n",
    "- Assistant Role: This role is the model's response.\n",
    "\n",
    "Llama models on Bedrock when using the Converse API behave very similar having the same assigned roles for llama 3.1.\n",
    "\n",
    "Additionally, Llama 3.1 now supports tool calling - introducing a new ipython role semantically used to mark messages with the output of a tool call when sent back to the model form the executor. With the Bedrock converse API, we can focus on the JSON formatting and outputting of the JSON syntax, rather than focusing specifically on the <ipython> role tag. For more information on the Llama 3.1 supported roles, feel free to check out the [Llama 3.1 model card](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61225d7f-b887-47ee-9f52-3455b4a5ba11",
   "metadata": {},
   "source": [
    "## Prerequisites:\n",
    "- AWS SDK for Python (Boto3): Ensure you have the Boto3 library installed.\n",
    "- Amazon Bedrock Model ID: Obtain the model ID for the conversational AI model you wish to use.\n",
    "- AWS Credentials: Configure your AWS credentials to authenticate API requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488c400-9fbd-4ffc-812f-bbdd1d83b6f1",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "In the next cell, we will set up our environment by importing the boto3 library and necessary libraries that we will need to confiure our bedrock client to invoke our llama 3.1 model within the Amazon Bedrock Converse API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d837fe60-6869-4430-8457-342ca9492bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb76dfbe-83b8-4855-a197-5a1f0303e8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "config = Config(read_timeout=2000)\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=\"us-west-2\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc6873-974e-498b-b7c0-bdb3bb29b01d",
   "metadata": {},
   "source": [
    "## Instantiate llama 3.1 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097393a5-c646-4102-9210-61e1b20eb9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_llama_3_70b = 'meta.llama3-1-70b-instruct-v1:0'\n",
    "\n",
    "model_id = meta_llama_3_70b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6dd3d2-c7b9-4850-a65a-f63326506418",
   "metadata": {},
   "source": [
    "## Prompting with Amazon Bedrock Converse API\n",
    "\n",
    "The Amazon Bedrock Converse API can be used to invoke large language models on Amazon Bedrock by extracting away the special stop tokens and facilitate the creation of conversational applications by enabling the exchange of messages between users and Amazon Bedrock models.\n",
    "\n",
    "**Key features include:**\n",
    "- **Consistent Interface:**\n",
    "The Converse API provides a uniform interface that works across all Amazon Bedrock models supporting messages. This consistency allows developers to write code once and use it with different models without needing to adjust for model-specific differences.\n",
    "\n",
    "- **Turn-Based Conversations:**\n",
    "The API supports multi-turn conversations, where a series of messages are exchanged between the user (acting as the user role) and the model (acting as the assistant role). This enables the development of chatbots and other conversational agents that can maintain context over multiple interactions.\n",
    "\n",
    "- **Tool Use (Function Calling):**\n",
    "The Converse API supports tool use, allowing models to request the invocation of external functions or tools. This is particularly useful for tasks that require interaction with external APIs or services. The model generates a JSON structure with the necessary parameters, which the calling application then uses to invoke the specified tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155dc769-4221-4355-b9fe-23f1ef468a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prompting with the Bedrock Converse API\n",
    "\n",
    "Very similar to OpenAI API Messages format, where you define roles to have a conversational interface - Amazon Bedrock Converse API uses the same concept.\n",
    "\n",
    "#### Prompting with OpenAI API\n",
    "\n",
    "```\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a LLM?\"}\n",
    "  ]\n",
    ")\n",
    "```\n",
    "\n",
    "After setting your model ID as llama 3.1 8b model, to start interfacing with the converse API - you can put the prompt input inside the content \n",
    "\n",
    "Listed below is an example of how you can change / assign the different roles and add input to the role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4445564-13a7-4710-a206-a2a3f75246a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Prompting with Converse API on Bedrock\n",
    "\n",
    "```\n",
    "{\n",
    "    \"role\": \"user | assistant\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"text\": \"string\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13bd9c4-7dd1-4ca8-8008-807b7e380400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the message with content as a list\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"text\": \"Write me a story of a fairytale fable\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17569f02-2fa8-4cac-bdf1-c23f4e656ac4",
   "metadata": {},
   "source": [
    "## Calling the Bedrock Converse API \n",
    "\n",
    "The Amazon Bedrock Converse API allows you to interact with conversational AI models. Below is a step-by-step guide on how to call this API using the bedrock_client.converse method in Python.\n",
    "\n",
    "Parameters:\n",
    "- modelId: This parameter specifies the ID of the conversational AI model you want to use. Replace model_id with your actual model ID.\n",
    "- messages: This parameter contains the conversation history. It should be a list of message objects. Each message object typically includes the role (e.g., \"user\" or \"assistant\") and the content of the message. In this example, message is wrapped in a list to form the conversation history.\n",
    "- inferenceConfig: This parameter configures the inference settings for the API call. It includes:\n",
    "maxTokens: The maximum number of tokens (words or subwords) to generate in the response. In this example, it is set to 2000.\n",
    "- temperature: Controls the randomness of the output. Lower values make the output more deterministic. Here, it is set to 0, making the output as deterministic as possible.\n",
    "- topP: Controls nucleus sampling, where the model considers the smallest set of tokens whose cumulative probability is greater than or equal to topP. Here, it is set to 0.5, balancing between diversity and focus.\n",
    "\n",
    "The bedrock_client.converse method is called with the specified parameters. The response from the API call is stored in the response variable. For more information on calling the Converse API, please feel free to follow the [Amazon Bedrock Converse API documenation](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6edcfac6-2df4-4343-bfe2-94995ba8e434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_client.converse(\n",
    "    modelId=model_id,\n",
    "    messages=[message],  # Wrap the message in a list\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 2000,\n",
    "        \"temperature\": 0,\n",
    "        \"topP\": .5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbc540d-b09e-444f-96e1-2c890fb8fdab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Response:\n",
      "{\n",
      "    \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"6335488c-c096-4b4e-a316-08488ef85f55\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "            \"date\": \"Wed, 14 Aug 2024 01:29:13 GMT\",\n",
      "            \"content-type\": \"application/json\",\n",
      "            \"content-length\": \"3618\",\n",
      "            \"connection\": \"keep-alive\",\n",
      "            \"x-amzn-requestid\": \"6335488c-c096-4b4e-a316-08488ef85f55\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "    },\n",
      "    \"output\": {\n",
      "        \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"\\n\\nOnce upon a time, in a land far, far away, there was a tiny village nestled in the heart of a dense forest. The villagers lived simple lives, tending to their gardens, raising their animals, and relying on the forest for their livelihood.\\n\\nIn the center of the village stood an enormous tree, its trunk as wide as a house and its branches stretching up towards the sky like giant arms. The tree was said to be magical, and the villagers believed that it held the secrets of the forest and the power to grant wishes.\\n\\nOne day, a young girl named Luna wandered into the forest, searching for a rare herb to heal her ailing mother. As she wandered deeper into the woods, she stumbled upon a hidden clearing and in the center of it stood the enormous tree.\\n\\nLuna approached the tree, feeling an strange energy emanating from it. She reached out to touch the trunk, and as she did, a soft, whispery voice spoke to her.\\n\\n\\\"What is it that you desire, little one?\\\" the voice asked.\\n\\nLuna thought for a moment before answering. \\\"I wish for my mother to be healed,\\\" she said.\\n\\nThe tree rustled its leaves and a small door materialized on the trunk. The door creaked open, revealing a tiny room inside the tree.\\n\\n\\\"Enter, little one,\\\" the voice said. \\\"But be warned, the price of your wish may be more than you are willing to pay.\\\"\\n\\nLuna hesitated, but her love for her mother drove her forward. She stepped inside the room, and the door closed behind her.\\n\\n Inside, she found a small, glowing crystal nestled in a bed of soft, green moss. The crystal pulsed with an otherworldly energy, and Luna felt its power coursing through her veins.\\n\\nSuddenly, a figure appeared before her. It was an old woman, dressed in a long, flowing cloak, with eyes that shone like the stars.\\n\\n\\\"I am the guardian of the tree,\\\" the old woman said. \\\"And I will grant your wish, but at a price. You must give up something precious to you, something that will change the course of your life forever.\\\"\\n\\nLuna thought of all the things she could give up, but nothing seemed precious enough to trade for her mother's health. And then, she remembered the locket her mother had given her, the one with the photo of her father, who had passed away when she was just a baby.\\n\\nShe hesitated, but the old woman's eyes seemed to bore into her soul, and she knew that she had to make a choice. She took off the locket and handed it to the old woman.\\n\\nThe old woman nodded, and the crystal began to glow even brighter. Luna felt a strange sensation, as if her heart was being pulled apart and put back together again.\\n\\nWhen she emerged from the tree, she found her mother standing before her, smiling and healthy. But as she looked down at her chest, she realized that the locket was gone, and with it, the only memory she had of her father.\\n\\nLuna learned a valuable lesson that day. She realized that the price of her wish had been higher than she had ever imagined, and that sometimes, the things we desire most come with a cost that we may not be willing to pay.\\n\\nFrom that day on, Luna lived with the knowledge that her mother's health had come at the cost of her own memories, and she made a promise to herself to always be mindful of the consequences of her desires. The tree, sensing her newfound wisdom, rustled its leaves in approval, and the villagers whispered that the tree's magic had been tempered by Luna's sacrifice.\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"stopReason\": \"end_turn\",\n",
      "    \"usage\": {\n",
      "        \"inputTokens\": 25,\n",
      "        \"outputTokens\": 750,\n",
      "        \"totalTokens\": 775\n",
      "    },\n",
      "    \"metrics\": {\n",
      "        \"latencyMs\": 24249\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the response\n",
    "print(\"Full Response:\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0537429-244f-47d7-807f-35075321d60a",
   "metadata": {},
   "source": [
    "## Code Generation: One-shot Prompting with Roles\n",
    "\n",
    "The provided code demonstrates how to structure a conversation for code generation tasks using one-shot prompting approach using the Amazon Bedrock Converse API with Llama 3.1. Here's a breakdown of the process:\n",
    "\n",
    "- **Conversation Structure:**\n",
    "The chat_convo list contains a series of messages that alternate between user and assistant roles. This structure mimics a real conversation, providing context for the model.\n",
    "- **Initial User Query:**\n",
    "The conversation starts with a user request for a specific coding task:\n",
    "- **Assistant's Response with Code:**\n",
    "The model responds with an explanation and a code snippet. Note that in this example, the assistant mistakenly provided code for S3 instead of RDS, which highlights the importance of clear prompts and potentially multiple conversation turns for complex tasks.\n",
    "- **User Feedback and Clarification:**\n",
    "The user provides additional context about the assistant's expertise:\n",
    "- **Assistant Acknowledgment:**\n",
    "The assistant acknowledges the user's statement, maintaining the conversational flow.\n",
    "- **Final User Prompt:**\n",
    "The user asks for help, which serves as a prompt for the model to generate or refine the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c41da3-fd87-4e69-9253-8c3de4a16fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_convo = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Can you write me a Python script to upload a file to Amazon RDS using a lambda function?\"},\n",
    "                    {\"text\": \"\"\"\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        s3_client.upload_file(file_name, bucket, object_name)\n",
    "        print(f\"File {file_name} uploaded to {bucket}/{object_name}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {file_name} was not found\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "\n",
    "# Example usage\n",
    "upload_to_s3('my_file.txt', 'my_bucket')\n",
    "\"\"\" }]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"text\": \"Sure, I can help with that.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"You are an expert at writing Python code for AWS services.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"text\": \"Thank you! If you have any more questions or need further assistance, feel free to ask.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Can you help with that?\"}]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0c23ee-cc4b-4e1c-90a5-a5582c80bb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_client.converse(\n",
    "    modelId=model_id,\n",
    "    messages=chat_convo,  # Wrap the message in a list\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 2000,\n",
    "        \"temperature\": 0,\n",
    "        \"topP\": .5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7a56e5-8963-45b1-922c-7a5485ce691b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant's Response:\n",
      "To upload a file to Amazon RDS using a Lambda function, you'll need to use the `boto3` library to interact with the RDS service. However, RDS is a relational database service, and it's not designed for storing files. Instead, you can store files in Amazon S3 and then use the Lambda function to upload the file to S3.\n",
      "\n",
      "But if you want to store the file in RDS, you can store it as a BLOB (Binary Large OBject) in a database table. Here's an example of how you can modify the script to upload a file to RDS using a Lambda function:\n",
      "```\n",
      "import boto3\n",
      "import psycopg2\n",
      "\n",
      "def upload_to_rds(file_name, db_instance_identifier, db_name, db_username, db_password, table_name):\n",
      "    # Create a connection to the RDS instance\n",
      "    rds_client = boto3.client('rds')\n",
      "    db_instance = rds_client.describe_db_instances(DBInstanceIdentifier=db_instance_identifier)\n",
      "    db_endpoint = db_instance['DBInstances'][0]['Endpoint']['Address']\n",
      "    db_port = db_instance['DBInstances'][0]['Endpoint']['Port']\n",
      "\n",
      "    # Connect to the PostgreSQL database\n",
      "    conn = psycopg2.connect(\n",
      "        host=db_endpoint,\n",
      "        port=db_port,\n",
      "        database=db_name,\n",
      "        user=db_username,\n",
      "        password=db_password\n",
      "    )\n",
      "\n",
      "    # Create a cursor object\n",
      "    cur = conn.cursor()\n",
      "\n",
      "    # Read the file\n",
      "    with open(file_name, 'rb') as f:\n",
      "        file_data = f.read()\n",
      "\n",
      "    # Insert the file data into the table\n",
      "    cur.execute(\"INSERT INTO {} (file_data) VALUES (%s)\".format(table_name), (file_data,))\n",
      "\n",
      "    # Commit the changes\n",
      "    conn.commit()\n",
      "\n",
      "    # Close the cursor and connection\n",
      "    cur.close()\n",
      "    conn.close()\n",
      "\n",
      "    print(f\"File {file_name} uploaded to RDS instance {db_instance_identifier}\")\n",
      "\n",
      "# Example usage\n",
      "upload_to_rds('my_file.txt', 'my-rds-instance', 'mydb', 'myuser', 'mypassword', 'mytable')\n",
      "```\n",
      "Note that this script assumes you have a PostgreSQL database running on your RDS instance, and that you have a table created with a column to store the file data. You'll need to modify the script to match your specific database schema and credentials.\n",
      "\n",
      "Also, keep in mind that storing large files in a relational database can be inefficient and may impact performance. It's generally recommended to store files in a dedicated file storage service like S3 instead.\n",
      "\n",
      "Response Metrics:\n",
      "Input Tokens: 255\n",
      "Output Tokens: 522\n",
      "Total Tokens: 777\n",
      "Latency: 17435 ms\n"
     ]
    }
   ],
   "source": [
    "# Extract the assistant's message\n",
    "assistant_message = response['output']['message']['content'][0]['text']\n",
    "\n",
    "# Print the response in a human-readable format\n",
    "print(\"Assistant's Response:\")\n",
    "print(assistant_message.strip())\n",
    "\n",
    "# Print the response metrics\n",
    "print(\"\\nResponse Metrics:\")\n",
    "print(f\"Input Tokens: {response['usage']['inputTokens']}\")\n",
    "print(f\"Output Tokens: {response['usage']['outputTokens']}\")\n",
    "print(f\"Total Tokens: {response['usage']['totalTokens']}\")\n",
    "print(f\"Latency: {response['metrics']['latencyMs']} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef34616-04b2-4e7d-b715-aaa805050303",
   "metadata": {},
   "source": [
    "In the cell above, we can see that Llama 3.1 was able to successfully provide a pyhton script for lambda to get data into RDS. With the help of the assistant, the model was able to produce a response similar to the provided python script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29688e-0d07-417c-85f0-413b747c23ed",
   "metadata": {},
   "source": [
    "## Tool Calling with Llama 3.1\n",
    "\n",
    "The llama 3.1 Instruct models are recommended for applications combing chat conversation and tool calling. With OpenAI models, an API call can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The Chat Completions API does not call the function; instead, the model generates JSON that you can use to call the function in your code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617acaf1-a939-4416-97c6-4549ad3a32aa",
   "metadata": {},
   "source": [
    "### JSON Generation and Outputting\n",
    "\n",
    "LLaMA 3.1 models have built-in capabilities to generate structured JSON outputs, which can be used for various applications, including tool calling and data extraction. This functionality is particularly useful for integrating AI models with other systems and APIs that require structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37252cb-02b2-4e51-9dfc-d2b2312d93f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"create_support_ticket\",\n",
    "            \"description\": \"Create a support ticket based on email content.\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ticket_id\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"A unique identifier for the support ticket.\"\n",
    "                        },\n",
    "                        \"issue_summary\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"A brief summary of the issue described in the email.\"\n",
    "                        },\n",
    "                        \"issue_description\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"A detailed description of the issue.\"\n",
    "                        },\n",
    "                        \"priority_level\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The priority level of the issue on a scale from 1-5\",\n",
    "                            \"minimum\": 1,\n",
    "                            \"maximum\": 5\n",
    "                        },\n",
    "                        \"customer_contact_info\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"name\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The name of the customer.\"\n",
    "                                },\n",
    "                                \"email\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The email address of the customer.\"\n",
    "                                },\n",
    "                                \"phone\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The phone number of the customer.\"\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"assigned_department\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The department to which the ticket should be assigned.\",\n",
    "                            \"enum\": [\"Technical Support\", \"Customer Service\", \"Billing\", \"Sales\"]\n",
    "                        },\n",
    "                        \"attachments\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"description\": \"An array of file attachments related to the issue.\",\n",
    "                            \"items\": { \"type\": \"string\" }\n",
    "                        },\n",
    "                        \"related_tickets\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"description\": \"An array of related ticket IDs.\",\n",
    "                            \"items\": { \"type\": \"string\" }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"ticket_id\",\n",
    "                        \"issue_summary\",\n",
    "                        \"issue_description\",\n",
    "                        \"priority_level\",\n",
    "                        \"customer_contact_info\",\n",
    "                        \"assigned_department\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15b6d0ec-3ff8-4ce3-8b32-ec49b9604a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = \"\"\"Dear Support Team,\n",
    "\n",
    "I am experiencing an issue with my account login. Every time I try to log in, I receive an error message saying \"Invalid credentials.\" I have tried resetting my password multiple times, but the issue persists. This is causing a significant disruption to my work.\n",
    "\n",
    "Please find attached screenshots of the error messages.\n",
    "\n",
    "Regards,\n",
    "Jane Doe\n",
    "Email: janedoe@example.com\n",
    "Phone: 123-456-7890\n",
    "\"\"\"\n",
    "\n",
    "# Define the message to be sent to the model\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        { \"text\": f\"<content>{content}</content>\" },\n",
    "        { \"text\": \"Please use the create_support_ticket tool to generate a support ticket JSON based on the content within the <content> tags.\" }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8f1822-2d89-46a6-bb82-5ce1f5747294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Response:\n",
      "{\n",
      "    \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"aa4a57c3-64ca-49a4-8527-e8ffdb1c4278\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "            \"date\": \"Wed, 14 Aug 2024 01:29:35 GMT\",\n",
      "            \"content-type\": \"application/json\",\n",
      "            \"content-length\": \"906\",\n",
      "            \"connection\": \"keep-alive\",\n",
      "            \"x-amzn-requestid\": \"aa4a57c3-64ca-49a4-8527-e8ffdb1c4278\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "    },\n",
      "    \"output\": {\n",
      "        \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": \"\\n\\n<|python_tag|>{\\\"type\\\":\\\"function\\\",\\\"name\\\":\\\"create_support_ticket\\\",\\\"parameters\\\":{\\\"customer_contact_info\\\":{\\\"name\\\":\\\"Jane Doe\\\",\\\"phone\\\":\\\"123-456-7890\\\",\\\"email\\\":\\\"janedoe@example.com\\\"},\\\"issue_description\\\":\\\"I am experiencing an issue with my account login. Every time I try to log in, I receive an error message saying \\\\\\\\\\\"Invalid credentials.\\\\\\\\\\\" I have tried resetting my password multiple times, but the issue persists. This is causing a significant disruption to my work.\\\",\\\"assigned_department\\\":\\\"Technical Support\\\",\\\"attachments\\\":[\\\"screenshot1.png\\\",\\\"screenshot2.png\\\"],\\\"related_tickets\\\":[],\\\"ticket_id\\\":\\\"12345\\\",\\\"priority_level\\\":\\\"3\\\",\\\"issue_summary\\\":\\\"Account login issue\\\"}}\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"stopReason\": \"end_turn\",\n",
      "    \"usage\": {\n",
      "        \"inputTokens\": 413,\n",
      "        \"outputTokens\": 139,\n",
      "        \"totalTokens\": 552\n",
      "    },\n",
      "    \"metrics\": {\n",
      "        \"latencyMs\": 4999\n",
      "    }\n",
      "}\n",
      "Raw JSON string:\n",
      "{\"type\":\"function\",\"name\":\"create_support_ticket\",\"parameters\":{\"customer_contact_info\":{\"name\":\"Jane Doe\",\"phone\":\"123-456-7890\",\"email\":\"janedoe@example.com\"},\"issue_description\":\"I am experiencing an issue with my account login. Every time I try to log in, I receive an error message saying \\\\\"Invalid credentials.\\\\\" I have tried resetting my password multiple times, but the issue persists. This is causing a significant disruption to my work.\",\"assigned_department\":\"Technical Support\",\"attachments\":[\"screenshot1.png\",\"screenshot2.png\"],\"related_tickets\":[],\"ticket_id\":\"12345\",\"priority_level\":\"3\",\"issue_summary\":\"Account login issue\"}}\n",
      "\n",
      "Parsed JSON:\n",
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"name\": \"create_support_ticket\",\n",
      "    \"parameters\": {\n",
      "        \"customer_contact_info\": {\n",
      "            \"name\": \"Jane Doe\",\n",
      "            \"phone\": \"123-456-7890\",\n",
      "            \"email\": \"janedoe@example.com\"\n",
      "        },\n",
      "        \"issue_description\": \"I am experiencing an issue with my account login. Every time I try to log in, I receive an error message saying \\\"Invalid credentials.\\\" I have tried resetting my password multiple times, but the issue persists. This is causing a significant disruption to my work.\",\n",
      "        \"assigned_department\": \"Technical Support\",\n",
      "        \"attachments\": [\n",
      "            \"screenshot1.png\",\n",
      "            \"screenshot2.png\"\n",
      "        ],\n",
      "        \"related_tickets\": [],\n",
      "        \"ticket_id\": \"12345\",\n",
      "        \"priority_level\": \"3\",\n",
      "        \"issue_summary\": \"Account login issue\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_client.converse(\n",
    "    modelId=model_id,\n",
    "    messages=[message],\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 2000,\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    toolConfig={\n",
    "        \"tools\": tools  # Correct parameter name and value\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the entire response for debugging\n",
    "print(\"Full Response:\")\n",
    "print(json.dumps(response, indent=4))\n",
    "\n",
    "# Process the response\n",
    "response_message = response['output']['message']\n",
    "response_content_blocks = response_message['content']\n",
    "\n",
    "# Look for the function call structure instead of 'toolUse'\n",
    "function_call_block = next((block for block in response_content_blocks if 'text' in block and '<|python_tag|>' in block['text']), None)\n",
    "\n",
    "if function_call_block:\n",
    "    # Extract the JSON string from the function call block\n",
    "    json_string = function_call_block['text'].split('<|python_tag|>')[1]\n",
    "    \n",
    "    # Print the raw JSON string for debugging\n",
    "    print(\"Raw JSON string:\")\n",
    "    print(json_string)\n",
    "    \n",
    "    # Try to clean up the JSON string\n",
    "    try:\n",
    "        # Remove any leading/trailing whitespace\n",
    "        json_string = json_string.strip()\n",
    "        # Use regex to extract the JSON object\n",
    "        match = re.search(r'\\{.*\\}', json_string, re.DOTALL)\n",
    "        if match:\n",
    "            json_string = match.group(0)\n",
    "        \n",
    "        # Replace escaped quotes with actual quotes\n",
    "        json_string = json_string.replace('\\\\\"', '\"')\n",
    "        \n",
    "        # Parse the JSON string\n",
    "        tool_result_dict = json.loads(json_string)\n",
    "        print(\"\\nParsed JSON:\")\n",
    "        print(json.dumps(tool_result_dict, indent=4))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\nError parsing JSON: {e}\")\n",
    "        print(\"JSON string causing the error:\")\n",
    "        print(json_string)\n",
    "else:\n",
    "    print(\"No function call block found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b8197-347b-470a-a032-f278420201ad",
   "metadata": {},
   "source": [
    "### Output \n",
    "\n",
    "Here we can see that Llama 3.1 was able to successfully use the toolConfiguration of the expected JSON formatting to create JSON of the support ticket to be created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a434a3-16ad-4d4e-b053-dff664e36756",
   "metadata": {},
   "source": [
    "## Llama 3.1 Tool usage with Converse API\n",
    "\n",
    "Amazon Bedrock's Converse API allows you to create conversational applications that can interact with LLaMA 3.1 models for various purposes, including tool usage. This functionality enables the model to call external tools or APIs to fetch real-time data or perform specific tasks, enhancing the model's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4992e24-3cdc-414c-9d83-bcad579b32f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the tool configuration\n",
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"movie_showtimes\",\n",
    "                \"description\": \"Fetches movie showtimes for a specified theater and movie.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"theater\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The theater name.\"\n",
    "                            },\n",
    "                            \"movie\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The movie title.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"theater\", \"movie\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97aab312-2512-4498-b4ef-d0c8837a90cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def movie_showtimes(theater, movie):\n",
    "    showtimes = {\n",
    "        \"Cineplex\": {\n",
    "            \"Inception\": [\"14:00\", \"17:30\", \"21:00\"],\n",
    "            \"The Godfather\": [\"15:00\", \"19:00\"],\n",
    "            \"Pulp Fiction\": [\"16:30\", \"20:30\"]\n",
    "        },\n",
    "        \"AMC\": {\n",
    "            \"Inception\": [\"13:30\", \"16:45\", \"20:15\"],\n",
    "            \"The Godfather\": [\"14:45\", \"18:30\"],\n",
    "            \"Pulp Fiction\": [\"15:15\", \"19:45\"]\n",
    "        }\n",
    "    }\n",
    "    return showtimes.get(theater, {}).get(movie, \"No showtimes found\")\n",
    "\n",
    "def prompt_llama3_1_8b(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    converse_api_params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"toolConfig\": toolConfig,  \n",
    "        \"inferenceConfig\": {\"temperature\": 0.0, \"maxTokens\": 400},\n",
    "    }\n",
    "\n",
    "    response = bedrock_client.converse(**converse_api_params)\n",
    "    \n",
    "    if response['output']['message']['content'][0].get('toolUse'):\n",
    "        tool_use = response['output']['message']['content'][0]['toolUse']\n",
    "        tool_name = tool_use['name']\n",
    "        tool_inputs = tool_use['input']\n",
    "\n",
    "        if tool_name == \"movie_showtimes\":\n",
    "            print(\"Llama 3.1 wants to use the movie_showtimes tool\")\n",
    "            theater = tool_inputs[\"theater\"]\n",
    "            movie = tool_inputs[\"movie\"]\n",
    "            \n",
    "            try:\n",
    "                result = movie_showtimes(theater, movie)\n",
    "                print(f\"Showtimes for {movie} at {theater}:\", result)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Llama 3.1 8b responded with:\")\n",
    "        print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8edce61f-49b2-40b8-922d-d72fb09f1d65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3.1 wants to use the movie_showtimes tool\n",
      "Showtimes for Inception at Cineplex: ['14:00', '17:30', '21:00']\n"
     ]
    }
   ],
   "source": [
    "prompt_llama3_1_8b(\"What are the showtimes for Inception at Cineplex?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cb635-c9d0-46d4-bbae-bb0f673a1257",
   "metadata": {},
   "source": [
    "---\n",
    "## Distributors\n",
    "- Amazon Web Services\n",
    "- Meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
