{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149cbb30-b95e-4dc8-b9ad-db8d4dea09cb",
   "metadata": {},
   "source": [
    "# Prerequisite Step: Set up vector database and evaluation dataset\n",
    "---\n",
    "\n",
    "This notebook is requisite step for all the RAG evaluation task in this repository. It covers the aspects of;\n",
    "- Download the sample dataset, we will utilize Amazon Shareholder letters as our data sources.\n",
    "- Set up **Chroma** database as our vector database.\n",
    "- Use **DeepEval** library to generate the **golden or evaluation** dataset for our RAG application.\n",
    "\n",
    "\n",
    "You will need to have access to **Amazon Bedrock** foundation model for embedding the documents, please refer to the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html) for more details.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note</b>: We will be using <b>Amazon Titan Text Embedding v2 model</b> (<i>amazon.titan-embed-text-v2:0</i>). Please refer to its capability <a href='https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html'>here</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a88a1e-9c4b-443a-94cb-10756050052b",
   "metadata": {},
   "source": [
    "## Set up\n",
    "---\n",
    "\n",
    "Install the dependency libraries for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbba30a4-7906-496a-b191-6beef6bd4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b17c44-7867-4480-a387-085ebad2aef4",
   "metadata": {},
   "source": [
    "## Set up Vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e4393-a14b-4f35-823e-8b4a078d46d8",
   "metadata": {},
   "source": [
    "### Download the dataset\n",
    "---\n",
    "\n",
    "We will be using Amazon shareholder letter from 2021 to 2023 as our datasources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fafe11-3bf1-4ed0-a5e1-737ac9f7d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url_file_map = {\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2024/ar/Amazon-com-Inc-2023-Shareholder-Letter.pdf': 'AMZN-2023-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf': 'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf': 'AMZN-2021-Shareholder-Letter.pdf',\n",
    "}\n",
    "data_dir = './_raw_data/'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "for _key in url_file_map.keys():\n",
    "    urlretrieve(_key, os.path.join(data_dir, url_file_map.get(_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ee8bd-9645-4598-9ef8-3a33c07e9c47",
   "metadata": {},
   "source": [
    "### Chunking strategy\n",
    "---\n",
    "\n",
    "**Chunking data** before loading it into a vector database is often necessary because vector databases are optimized for **efficient similarity search and retrieval operations on high-dimensional vector data**. These databases typically have limitations on the maximum size or dimensionality of vectors they can store and process efficiently. \n",
    "\n",
    "By chunking or splitting large datasets into smaller, manageable chunks, it becomes easier to load and index the data within the vector database's constraints. Chunking also facilitates parallel processing, allowing multiple chunks to be loaded concurrently, improving overall performance and scalability. Additionally, it provides a way to manage and update the data incrementally, as new chunks can be added or existing ones can be modified without requiring a complete reload of the entire dataset.\n",
    "\n",
    "There are multiple chunking strategy, however for simplicity, we will use [`RecursiveCharacterTextSplitter()` as our chunking strategy](https://python.langchain.com/docs/how_to/recursive_text_splitter/).\n",
    "\n",
    "\n",
    "There are a few parameters we can configure for our `RecursiveCharacterTextSplitter`:\n",
    "\n",
    "- `chunk_size`: The maximum size of a chunk, where size is determined by the length_function.\n",
    "- `chunk_overlap`: Target overlap between chunks. Overlapping chunks helps to mitigate loss of information when context is divided between chunks.\n",
    "- `length_function`: Function determining the chunk size.\n",
    "- `is_separator_regex`: Whether the separator list (defaulting to [\"\\n\\n\", \"\\n\", \" \", \"\"]) should be interpreted as regex.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note</b>: You must take the <b>chunk_size</b> into account as each embedding model will have limitation on the length of input token.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49e656e-a239-4688-8dba-242f8bd49249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total document pages: 48\n",
      "Sample data load: Dear Shareholders:\n",
      "Last year at this time, I shared my enthusiasm and optimism for Amazon’s future. \n",
      " ----- \n",
      "Total chunks: 380\n",
      "Sample chunk:\n",
      "available, tens of millions added last year alone, and several premium brands starting to list on Amazon(e.g. Coach, Victoria’s Secret, Pit Viper, Martha Stewart, Clinique, Lancôme, and Urban Decay).\n",
      "Being sharp on price is always important, but particularly in an uncertain economy, where customers are\n",
      "careful about how much they’re spending. As a result, in Q4 2023, we kicked off the holiday season with Prime\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = PyPDFDirectoryLoader(data_dir)\n",
    "pages = loader.load_and_split()\n",
    "print('Total document pages: {}'.format(len(pages)))\n",
    "print('Sample data load: {}'.format(pages[0].page_content[:100]))\n",
    "\n",
    "rec_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=102\n",
    ")\n",
    "rec_docs_splitted = rec_splitter.split_documents(pages)\n",
    "print(' ----- ')\n",
    "print('Total chunks: {}'.format(len(rec_docs_splitted)))\n",
    "print('Sample chunk:\\n{}'.format(rec_docs_splitted[3].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5509c-9c73-4663-bb42-4b45323d324b",
   "metadata": {},
   "source": [
    "### Prepare Vector Database\n",
    "---\n",
    "\n",
    "Once we have our chunk documents, next step, we will prepare vector database. In this example, we will utilize **Chroma database**. [**ChromaDB**](https://www.trychroma.com/) is an open-source vector database designed for building applications that require efficient semantic search and retrieval capabilities.\n",
    "\n",
    "But before creating ChromaDB, we will need to initialize the embedding model function. We can use [`BedrockEmbeddings` class](https://api.python.langchain.com/en/latest/embeddings/langchain_aws.embeddings.bedrock.BedrockEmbeddings.html) from **langchain_aws** to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "497d12ad-d4da-4930-b0d3-c59c981e7ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0635838583111763, 0.05780351161956787]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_aws\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "titan_model_id = 'amazon.titan-embed-text-v2:0'\n",
    "titan_embedding_fn = BedrockEmbeddings(\n",
    "    model_id=titan_model_id,\n",
    "    region_name=boto_session.region_name\n",
    ")\n",
    "titan_embedding_fn.embed_query('Hello')[: 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab603791-e6bf-4da4-9445-04b163a25588",
   "metadata": {},
   "source": [
    "Now with embedding function, we can specify `Chroma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9ffeca9-fd79-46b2-8cfd-3fb0b7ddc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db_dir = './_vector_db'\n",
    "chroma_collection_name = 'amazon-shareholder-letters'\n",
    "\n",
    "# Init from Chroma client\n",
    "vector_store = Chroma(\n",
    "    collection_name=chroma_collection_name,\n",
    "    embedding_function=titan_embedding_fn,\n",
    "    persist_directory=chroma_db_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343113e-951d-47cd-837f-837be9463a82",
   "metadata": {},
   "source": [
    "Load the documents to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8524059-bfb4-404e-ab5c-ae482c672419",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vector_store.get().get('ids')) == 0:\n",
    "    vector_store = Chroma.from_documents(\n",
    "        collection_name=chroma_collection_name,\n",
    "        documents=rec_docs_splitted,\n",
    "        persist_directory=chroma_db_dir,\n",
    "        embedding=titan_embedding_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d55e3-9931-4784-b76f-cf8e80e3ff32",
   "metadata": {},
   "source": [
    "### Test query our vector store\n",
    "---\n",
    "Now we have vector database with the data in it, let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c51d213-31b1-4c9f-9585-09b84407df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = '''\n",
    "Amazon discusses its investments and progress in various areas, such as Generative AI, logistics, and healthcare. \n",
    "How do these initiatives relate to the company's strategy of building \"primitives\" or foundational building blocks, \n",
    "and what potential customer experiences or business opportunities do they enable?'''\n",
    "\n",
    "search_result = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=sample_question.strip(),\n",
    "    k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7fc9fd-9be5-41f2-9018-eb80bc9d1e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'page': 5, 'source': '_raw_data/AMZN-2022-Shareholder-Letter.pdf'}, page_content='One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our\\nbusiness for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”)\\nand Generative AI . Machine learning has been a technology with high promise for several decades, but it’s'),\n",
       "  0.43749576860014605),\n",
       " (Document(metadata={'page': 3, 'source': '_raw_data/AMZN-2023-Shareholder-Letter.pdf'}, page_content='otherU.S. Intelligence agencies). But, one of the lesser-recognized beneficiaries was Amazon’s own consumerbusinesses, which innovated at dramatic speed across retail, advertising, devices (e.g. Alexa and FireTV),Prime Video and Music, Amazon Go, Drones, and many other endeavors by leveraging the speed with whichAWS let them build. Primitives, done well, rapidly accelerate builders’ ability to innovate .'),\n",
       "  0.419795440924723),\n",
       " (Document(metadata={'page': 4, 'source': '_raw_data/AMZN-2022-Shareholder-Letter.pdf'}, page_content='Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and\\nusing our unique assets to help merchants sell more effectively on their own websites are somewhat naturalextensions for us. There are also a few investments we’re making that are further from our core businesses, butwhere we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, AmazonHealthcare and Kuiper are potential analogues.'),\n",
       "  0.3646124035820153)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a05dda-d346-41b7-9827-4565f6fb8393",
   "metadata": {},
   "source": [
    "Now, we have establishing ChromaDB for our vector database, which will be used in the subseqent notebooks for RAG evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2efd2a-ff6e-40a8-9944-857e9d667e1b",
   "metadata": {},
   "source": [
    "## Synthetic Evaluation dataset\n",
    "\n",
    "In this section, we will generate the **golden** or **evaluation** dataset used to evaluate RAG application. We will utilize `DeepEval` library for this purpose.\n",
    "\n",
    "\n",
    "### Synthesizer\n",
    "---\n",
    "\n",
    "`DeepEval`'s **Synthesizer** offers a fast and easy to automatically get started with testing your LLM by generating high-quality evaluation datasets (inputs, expected outputs, and contexts) from scratch. The default of **Synthesizer** class will be using `OpenAI`, hence we will need to create two custom LLM handlers to use with our **Amazon Bedrock** model, one for embedding model, and one for language models.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Remark</b>: We will pass the LLMs in langchain form to DeepEval.\n",
    "</div>\n",
    "\n",
    "Please refer to [DeepEval's source code](https://github.com/confident-ai/deepeval/blob/main/deepeval/synthesizer/synthesizer.py) and [documentation](https://docs.confident-ai.com/docs/evaluation-datasets-synthetic-data) to help with adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e496ff4-db14-4951-83c5-7f565e2574f0",
   "metadata": {},
   "source": [
    "#### Custom Bedrock Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b4c526b-1b97-4b51-a54f-af044b41e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepeval\n",
    "from deepeval.synthesizer import Synthesizer\n",
    "from deepeval.models import DeepEvalBaseEmbeddingModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class BedrockEmbeddingDeepEval(DeepEvalBaseEmbeddingModel):\n",
    "    def __init__(self, model: langchain_aws.embeddings):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        embedding_model = self.load_model()\n",
    "        return embedding_model.embed_query(text)\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> List[List[float]]:\n",
    "        embedding_model = self.load_model()\n",
    "        return embedding_model.embed_documents(texts)\n",
    "\n",
    "    async def a_embed_text(self, text: str) -> List[float]:\n",
    "        embedding_model = self.load_model()\n",
    "        return await embedding_model.aembed_query(text)\n",
    "\n",
    "    async def a_embed_texts(self, texts: List[str]) -> List[List[float]]:\n",
    "        embedding_model = self.load_model()\n",
    "        return await embedding_model.aembed_documents(texts)\n",
    "\n",
    "    def get_model_name(self) -> str:\n",
    "        embedding_model = self.load_model()\n",
    "        return embedding_model.model_id\n",
    "\n",
    "    def get_provider(self) -> str:\n",
    "        model_id = self.get_model_name()\n",
    "        return model_id.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feace4bc-6635-4e66-84fe-41c8850ff807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0635838583111763, 0.05780351161956787]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titan_embedding_deepeval = BedrockEmbeddingDeepEval(model=titan_embedding_fn)\n",
    "titan_embedding_deepeval.embed_text('Hello')[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91edaf-2e70-4083-9c89-7f234029b136",
   "metadata": {},
   "source": [
    "#### Custom Bedrock LLM\n",
    "---\n",
    "For text generation model, we will use **Anthropic Claude 3 Sonnet on Amazon Bedrock**. However, please feel free to change to other LLMs like Llama 3.1 70B or 405B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f29f6d44-f96f-4a8e-b55b-3dd93409c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='In the context of LLM, the \\'L\\' stands for \"Large\":\\n\\nLLM = Large Language Model\\n\\nA large language model (LLM) is a type of artificial intelligence system that is trained on vast amounts of text data to understand and generate human-like language. These models have a very large number of parameters (the values that encode the model\\'s knowledge), often in the billions or trillions.\\n\\nSome key characteristics of LLMs:\\n\\n- Trained on massive text corpora crawled from the internet or other sources, allowing them to develop broad knowledge.\\n- Can understand and generate text on a wide range of topics in a contextual, semantically coherent way.\\n- Support natural language tasks like text generation, question answering, summarization, translation, etc.\\n- Models like GPT-3, PaLM, Jurassic-1, LaMDA fall under the LLM category.\\n\\nThe \"large\" component refers to these models\\' immense scale in terms of the amount of data used for training and the huge number of parameters they contain compared to traditional NLP models. This scale allows LLMs to exhibit advanced language understanding and generation capabilities.', additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 257, 'total_tokens': 272}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 257, 'total_tokens': 272}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-58cb3633-fead-406c-98d6-7d6fe77a2a42-0', usage_metadata={'input_tokens': 15, 'output_tokens': 257, 'total_tokens': 272})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_aws\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "claude3_sonnet_model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "llama3_1_70b_model_id = 'meta.llama3-1-70b-instruct-v1:0'\n",
    "\n",
    "claude_sonnet_langchain = ChatBedrock(\n",
    "    model_id=claude3_sonnet_model_id,\n",
    "    region_name=boto_session.region_name\n",
    ")\n",
    "claude_sonnet_langchain.invoke('What is L in LLM?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef54fb28-99f7-48dd-bf5b-28f675b97606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.models import DeepEvalBaseLLM\n",
    "\n",
    "\n",
    "class BedrockTextGenDeepEval(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: langchain_aws.chat_models\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        llm_model = self.load_model()\n",
    "        return llm_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        llm_model = self.load_model()\n",
    "        res = await llm_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        llm_model = self.load_model()\n",
    "        return llm_model.model_id\n",
    "\n",
    "    def get_provider(self):\n",
    "        model_id = self.get_model_name()\n",
    "        return model_id.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f4a42d4-7843-435d-a781-918b8537dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_sonnet_deepeval = BedrockTextGenDeepEval(model=claude_sonnet_langchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b5d90-d7d2-4ca1-a299-bd918d840be9",
   "metadata": {},
   "source": [
    "#### Initialize Synthesizer with custom LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e825807-57a1-4709-ba38-64c8497fcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_synthesizer = Synthesizer(\n",
    "    model=claude_sonnet_deepeval,\n",
    "    critic_model=claude_sonnet_deepeval,\n",
    "    embedder=titan_embedding_deepeval,\n",
    "    context_quality_threshold=.8,\n",
    "    context_similarity_threshold=.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc13aa88-5935-4e56-aa04-8bbd6494c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✨ 🚀 ✨ Loading Documents: 100%|██████████| 1/1 [00:00<00:00, 219.60it/s]\n",
      "✨ 🧩 ✨ Generating Contexts: 100%|██████████| 12/12 [00:04<00:00,  2.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Utilizing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span> chunks.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Utilizing \u001b[1;36m4\u001b[0m out of \u001b[1;36m112\u001b[0m chunks.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✨ Generating up to 8 goldens using DeepEval (using anthropic.claude-3-sonnet-20240229-v1:0 and amazon.titan-embed-text-v2:0, use case=QA, method=docs): 100%|██████████| 8/8 [00:47<00:00,  5.99s/it]\n"
     ]
    }
   ],
   "source": [
    "import time;time.sleep(60)\n",
    "_out = custom_synthesizer.generate_goldens_from_docs(\n",
    "    document_paths=[os.path.join(data_dir, 'AMZN-2023-Shareholder-Letter.pdf')],\n",
    "    include_expected_output=True,\n",
    "    max_contexts_per_document=4,\n",
    "    max_goldens_per_context=2,\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=102,\n",
    "    _send_data=False,\n",
    "    num_evolutions=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75106ac1-5b1f-42a0-9bfc-533eee4c5658",
   "metadata": {},
   "source": [
    "### Save evaluation to dataframe and file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c04e10-3bc4-47cf-aa6c-64d91cf30636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>actual_output</th>\n",
       "      <th>expected_output</th>\n",
       "      <th>context</th>\n",
       "      <th>retrieval_context</th>\n",
       "      <th>n_chunks_per_context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>evolutions</th>\n",
       "      <th>context_quality</th>\n",
       "      <th>synthetic_input_quality</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rewritten Input: Explain Amazon's core mission...</td>\n",
       "      <td>None</td>\n",
       "      <td>Amazon's core mission is to make customers' li...</td>\n",
       "      <td>[across Amazon. Y et, I think every one of us ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2361</td>\n",
       "      <td>[Reasoning]</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>./_raw_data/AMZN-2023-Shareholder-Letter.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compare Amazon's approach to empowering builde...</td>\n",
       "      <td>None</td>\n",
       "      <td>Amazon's approach to empowering builders and i...</td>\n",
       "      <td>[across Amazon. Y et, I think every one of us ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2361</td>\n",
       "      <td>[Comparative]</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>./_raw_data/AMZN-2023-Shareholder-Letter.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input actual_output  \\\n",
       "0  Rewritten Input: Explain Amazon's core mission...          None   \n",
       "1  Compare Amazon's approach to empowering builde...          None   \n",
       "\n",
       "                                     expected_output  \\\n",
       "0  Amazon's core mission is to make customers' li...   \n",
       "1  Amazon's approach to empowering builders and i...   \n",
       "\n",
       "                                             context retrieval_context  \\\n",
       "0  [across Amazon. Y et, I think every one of us ...              None   \n",
       "1  [across Amazon. Y et, I think every one of us ...              None   \n",
       "\n",
       "   n_chunks_per_context  context_length     evolutions  context_quality  \\\n",
       "0                     1            2361    [Reasoning]              0.8   \n",
       "1                     1            2361  [Comparative]              0.8   \n",
       "\n",
       "   synthetic_input_quality                                   source_file  \n",
       "0                      1.0  ./_raw_data/AMZN-2023-Shareholder-Letter.pdf  \n",
       "1                      0.6  ./_raw_data/AMZN-2023-Shareholder-Letter.pdf  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = custom_synthesizer.to_pandas()\n",
    "eval_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "577c3d24-1d04-4039-b527-8271362a3c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = './_eval_data'\n",
    "os.makedirs(eval_data_dir, exist_ok=True)\n",
    "eval_df.to_csv(os.path.join(eval_data_dir, 'eval_dataframe.csv'), index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
