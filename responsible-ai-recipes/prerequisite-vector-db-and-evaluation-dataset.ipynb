{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149cbb30-b95e-4dc8-b9ad-db8d4dea09cb",
   "metadata": {},
   "source": [
    "# Prerequisite Step: Set up vector database and evaluation dataset\n",
    "---\n",
    "\n",
    "This notebook is requisite step for all the RAG evaluation task in this repository. It covers the aspects of;\n",
    "- Download the sample dataset, we will utilize Amazon Shareholder letters as our data sources.\n",
    "- Set up **Chroma** database as our vector database.\n",
    "- Genreate a **synthetic dataset** for a QnA-RAG application using Meta Llama foundation model via the Bedrock API, Python and Langchain.\n",
    "\n",
    "\n",
    "You will need to have access to **Amazon Bedrock** foundation model for embedding the documents, please refer to the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html) for more details.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note</b>: We will be using <b>Amazon Titan Text Embedding v2 model</b> (<i>amazon.titan-embed-text-v2:0</i>). Please refer to its capability <a href='https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html'>here</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a88a1e-9c4b-443a-94cb-10756050052b",
   "metadata": {},
   "source": [
    "## Set up\n",
    "---\n",
    "\n",
    "Install the dependency libraries for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbba30a4-7906-496a-b191-6beef6bd4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b17c44-7867-4480-a387-085ebad2aef4",
   "metadata": {},
   "source": [
    "## Set up Vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e4393-a14b-4f35-823e-8b4a078d46d8",
   "metadata": {},
   "source": [
    "### Download the dataset\n",
    "---\n",
    "\n",
    "We will be using Amazon shareholder letter from 2021 to 2023 as our datasources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fafe11-3bf1-4ed0-a5e1-737ac9f7d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "url_file_map = {\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2024/ar/Amazon-com-Inc-2023-Shareholder-Letter.pdf': 'AMZN-2023-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf': 'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf': 'AMZN-2021-Shareholder-Letter.pdf',\n",
    "}\n",
    "data_dir = './_raw_data/'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "for _key in url_file_map.keys():\n",
    "    urlretrieve(_key, os.path.join(data_dir, url_file_map.get(_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ee8bd-9645-4598-9ef8-3a33c07e9c47",
   "metadata": {},
   "source": [
    "### Chunking strategy\n",
    "---\n",
    "\n",
    "**Chunking data** before loading it into a vector database is often necessary because vector databases are optimized for **efficient similarity search and retrieval operations on high-dimensional vector data**. These databases typically have limitations on the maximum size or dimensionality of vectors they can store and process efficiently. \n",
    "\n",
    "By chunking or splitting large datasets into smaller, manageable chunks, it becomes easier to load and index the data within the vector database's constraints. Chunking also facilitates parallel processing, allowing multiple chunks to be loaded concurrently, improving overall performance and scalability. Additionally, it provides a way to manage and update the data incrementally, as new chunks can be added or existing ones can be modified without requiring a complete reload of the entire dataset.\n",
    "\n",
    "There are multiple chunking strategy, however for simplicity, we will use [`RecursiveCharacterTextSplitter()` as our chunking strategy](https://python.langchain.com/docs/how_to/recursive_text_splitter/).\n",
    "\n",
    "\n",
    "There are a few parameters we can configure for our `RecursiveCharacterTextSplitter`:\n",
    "\n",
    "- `chunk_size`: The maximum size of a chunk, where size is determined by the length_function.\n",
    "- `chunk_overlap`: Target overlap between chunks. Overlapping chunks helps to mitigate loss of information when context is divided between chunks.\n",
    "- `length_function`: Function determining the chunk size.\n",
    "- `is_separator_regex`: Whether the separator list (defaulting to [\"\\n\\n\", \"\\n\", \" \", \"\"]) should be interpreted as regex.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note</b>: You must take the <b>chunk_size</b> into account as each embedding model will have limitation on the length of input token.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49e656e-a239-4688-8dba-242f8bd49249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total document pages: 48\n",
      "Sample data load: Dear Shareholders:\n",
      "Last year at this time, I shared my enthusiasm and optimism for Amazon’s future. \n",
      " ----- \n",
      "Total chunks: 322\n",
      "Sample chunk:\n",
      "available, tens of millions added last year alone, and several premium brands starting to list on Amazon\n",
      "(e.g. Coach, Victoria’s Secret, Pit Viper, Martha Stewart, Clinique, Lancôme, and Urban Decay).\n",
      "Being sharp on price is always important, but particularly in an uncertain economy, where customers are\n",
      "careful about how much they’re spending. As a result, in Q4 2023, we kicked off the holiday season with Prime\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = PyPDFDirectoryLoader(data_dir)\n",
    "pages = loader.load_and_split()\n",
    "print('Total document pages: {}'.format(len(pages)))\n",
    "print('Sample data load: {}'.format(pages[0].page_content[:100]))\n",
    "\n",
    "rec_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=102\n",
    ")\n",
    "rec_docs_splitted = rec_splitter.split_documents(pages)\n",
    "print(' ----- ')\n",
    "print('Total chunks: {}'.format(len(rec_docs_splitted)))\n",
    "print('Sample chunk:\\n{}'.format(rec_docs_splitted[3].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5509c-9c73-4663-bb42-4b45323d324b",
   "metadata": {},
   "source": [
    "### Prepare Vector Database\n",
    "---\n",
    "\n",
    "Once we have our chunk documents, next step, we will prepare vector database. In this example, we will utilize **Chroma database**. [**ChromaDB**](https://www.trychroma.com/) is an open-source vector database designed for building applications that require efficient semantic search and retrieval capabilities.\n",
    "\n",
    "But before creating ChromaDB, we will need to initialize the embedding model function. We can use [`BedrockEmbeddings` class](https://api.python.langchain.com/en/latest/embeddings/langchain_aws.embeddings.bedrock.BedrockEmbeddings.html) from **langchain_aws** to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497d12ad-d4da-4930-b0d3-c59c981e7ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0635838583111763, 0.05780351161956787]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_aws\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "titan_model_id = 'amazon.titan-embed-text-v2:0'\n",
    "titan_embedding_fn = BedrockEmbeddings(\n",
    "    model_id=titan_model_id,\n",
    "    region_name=boto_session.region_name\n",
    ")\n",
    "titan_embedding_fn.embed_query('Hello')[: 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab603791-e6bf-4da4-9445-04b163a25588",
   "metadata": {},
   "source": [
    "Now with embedding function, we can specify `Chroma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ffeca9-fd79-46b2-8cfd-3fb0b7ddc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db_dir = './vector_db'\n",
    "chroma_collection_name = 'amazon-shareholder-letters'\n",
    "\n",
    "# Init from Chroma client\n",
    "vector_store = Chroma(\n",
    "    collection_name=chroma_collection_name,\n",
    "    embedding_function=titan_embedding_fn,\n",
    "    persist_directory=chroma_db_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343113e-951d-47cd-837f-837be9463a82",
   "metadata": {},
   "source": [
    "Load the documents to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8524059-bfb4-404e-ab5c-ae482c672419",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vector_store.get().get('ids')) == 0:\n",
    "    vector_store = Chroma.from_documents(\n",
    "        collection_name=chroma_collection_name,\n",
    "        documents=rec_docs_splitted,\n",
    "        persist_directory=chroma_db_dir,\n",
    "        embedding=titan_embedding_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d55e3-9931-4784-b76f-cf8e80e3ff32",
   "metadata": {},
   "source": [
    "### Test query our vector store\n",
    "---\n",
    "Now we have vector database with the data in it, let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c51d213-31b1-4c9f-9585-09b84407df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = '''\n",
    "Amazon discusses its investments and progress in various areas, such as Generative AI, logistics, and healthcare. \n",
    "How do these initiatives relate to the company's strategy of building \"primitives\" or foundational building blocks, \n",
    "and what potential customer experiences or business opportunities do they enable?'''\n",
    "\n",
    "search_result = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=sample_question.strip(),\n",
    "    k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7fc9fd-9be5-41f2-9018-eb80bc9d1e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'page': 5, 'source': '_raw_data/AMZN-2022-Shareholder-Letter.pdf'}, page_content='the investment hypothesis to go after it.\\nOne final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our\\nbusiness for many decades to come, and where we’re investing heavily isLarge Language Models (“LLMs”)\\nand Generative AI. Machine learning has been a technology with high promise for several decades, but it’s\\nonly been the last five to ten years that it’s started to be used more pervasively by companies. This shift was'),\n",
       "  0.3977445048117627),\n",
       " (Document(metadata={'page': 5, 'source': '_raw_data/AMZN-2023-Shareholder-Letter.pdf'}, page_content='optimize the movement of our growing robotic fleet, and better manage the bottlenecks in our facilities.\\nSometimes, people ask us “what’s your next pillar? Y ou have Marketplace, Prime, and AWS, what’s next?”\\nThis, of course, is a thought-provoking question. However, a question people never ask, and might be even\\nmore interesting iswhat’s the next set of primitivesyou’re building that enables breakthrough customer\\nexperiences? If you asked me today, I’d lead with Generative AI (“GenAI”).'),\n",
       "  0.34463791625464135),\n",
       " (Document(metadata={'page': 8, 'source': '_raw_data/AMZN-2021-Shareholder-Letter.pdf'}, page_content='believe that other products may be prudent investments. We also believe there are significant opportunities to\\nbetter serve our customers overseas, such as reducing delivery times and better tailoring the customer experience.\\nTo be certain, a big part of the challenge for us will lie not in finding new ways to expand our business, but in\\nprioritizing our investments.\\nWe now know vastly more about online commerce than when Amazon.com was founded, but we still have'),\n",
       "  0.3406562947312334)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a05dda-d346-41b7-9827-4565f6fb8393",
   "metadata": {},
   "source": [
    "Now, we have establishing ChromaDB for our vector database, which will be used in the subseqent notebooks for RAG evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294dd129-d20b-4ad7-9007-00d19fef7984",
   "metadata": {},
   "source": [
    "## Synthetic Evaluation dataset\n",
    "---\n",
    "\n",
    "In this section, we will generate the **evaluation dataset** for QnA task. This output of this step will be reused in other RAG evaluation notebooks within this repository.\n",
    "\n",
    "**Synthetic dataset generation** provides a practical solution for generating datasets that mimic real human interactions, enabling efficient and scalable evaluation of RAG systems. By leveraging large language models and knowledge retrieval context, the proposed approach ensures that the synthetic datasets are diverse, realistic, and representative of real-world scenarios. \n",
    "\n",
    "This solution is relevant for developers and researchers working on RAG systems, as it streamlines the evaluation process and accelerates the iterative development cycle, ultimately leading to better-performing AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35400fe-2cd1-47d5-bd2d-6dc2e41cf43d",
   "metadata": {},
   "source": [
    "### Set up langchain\n",
    "---\n",
    "\n",
    "You can use various Llama model to test out, this section we will use **Llama 3.1 70B** as question generator LLM, and **Llama 3.1 405B** for evaluate the quality of questions.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note</b>: Feel free to adjust the foundation model here!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28e1aa5-fb29-40e8-a44a-7c6a2ad878a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_aws\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "\n",
    "llama3_1_70b_model_id = 'meta.llama3-1-70b-instruct-v1:0'\n",
    "llama3_1_405b_model_id = 'meta.llama3-1-405b-instruct-v1:0'\n",
    "\n",
    "llama3_1_70b_langchain = ChatBedrock(\n",
    "    model_id=llama3_1_70b_model_id,\n",
    "    region_name=boto_session.region_name,\n",
    "    model_kwargs={\n",
    "        'temperature': 0.1,\n",
    "        'max_gen_len': 4096,\n",
    "    }\n",
    ")\n",
    "llama3_1_405b_langchain = ChatBedrock(\n",
    "    model_id=llama3_1_405b_model_id,\n",
    "    region_name=boto_session.region_name,\n",
    "    model_kwargs={\n",
    "        'temperature': 0.1,\n",
    "        'max_gen_len': 4096,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553118a4-b855-4188-b78b-d8b3fd50aca1",
   "metadata": {},
   "source": [
    "### Initial question generation\n",
    "---\n",
    "\n",
    "As first step, we will generate sample questions, we use each of the generated chunks to generate synthetic questions that a real chatbot user may ask. We will prompt the LLM to analyze a chunk of the shareholder's letter and generate relevant question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a49021-fcdb-42ca-9760-d7ee471b8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core\n",
    "\n",
    "def llm_invoke(\n",
    "    llm: langchain_aws.chat_models,\n",
    "    _my_prompt_template: str,\n",
    "    max_retries: int = 3,\n",
    "    wait_in_seconds: int = 90\n",
    ") -> langchain_core.messages.ai.AIMessage:\n",
    "    '''Function to invoke langchain_aws chat models with back off mechanism\n",
    "    '''\n",
    "    attempt = 0\n",
    "    generated_content = None\n",
    "    assert max_retries > 0, 'Max retries needs to be more than 0'\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            generated_content = llm.invoke(_my_prompt_template)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            attempt += 1\n",
    "            time.sleep(wait_in_seconds)\n",
    "\n",
    "    if (attempt >= max_retries) & (generated_content is None):\n",
    "        print('-- Exceed attempt, no output is generated!')\n",
    "    return generated_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63188614-3205-49c9-886c-40167d43acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "initial_question_prompt_template = PromptTemplate(\n",
    "    input_variables=['context'],\n",
    "    template='''\n",
    "    <Instructions>\n",
    "    Here is the context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Your task is to generate 1 question that can be answered using the provided context, following these rules:\n",
    "\n",
    "    <rules>\n",
    "    1. The question should make sense to humans even when read without the given context.\n",
    "    2. The question should be fully answered from the given context.\n",
    "    3. The question should be framed from a part of context that contains important information. It can also be from tables, code, etc.\n",
    "    4. The answer to the question should not contain any links.\n",
    "    5. The question should be of moderate difficulty up to difficult.\n",
    "    6. The question must be reasonable and must be understood and responded by humans.\n",
    "    7. Do not use phrases like 'provided context', etc. in the question.\n",
    "    8. You can frame the questions using the word \"and\", \"or\" that can be decomposed into more than one question.\n",
    "    9. Your question should be able to be referenced in full sentence from the context.\n",
    "    10. Never create question that will refer back to the context.\n",
    "    </rules>\n",
    "\n",
    "    To generate the question, first identify the most important or relevant part of the context. \n",
    "    Then frame a question around that part that satisfies all the rules above.\n",
    "    Think step-by-step and follow the <rule>.\n",
    "\n",
    "    Output only the generated question with a \"?\" at the end, no other text or characters.\n",
    "    </Instructions>\n",
    "    ''')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81412286-3c98-4410-bd81-f419b8239097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the broadest retail selection offered by the company's Stores business?\n"
     ]
    }
   ],
   "source": [
    "question = llm_invoke(\n",
    "    llm=llama3_1_70b_langchain,\n",
    "    _my_prompt_template=initial_question_prompt_template.format(context=rec_docs_splitted[2].page_content)\n",
    ")\n",
    "print(question.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41666a-b473-4307-9a0e-5951d0f98e34",
   "metadata": {},
   "source": [
    "### Answer Generation\n",
    "---\n",
    "Next, we will use the generated question to generate a reference response for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90c092b-1681-429f-a769-0bb1e83d3ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company's Stores business offers the broadest retail selection, with hundreds of millions of products.\n"
     ]
    }
   ],
   "source": [
    "answer_prompt_template = PromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    template='''\n",
    "    <Instructions>\n",
    "    <role>You are an experienced QA Engineer for building large language model applications.</role>\n",
    "    <task>It is your task to generate an answer to the following question <question>{question}</question> only based on the <context>{context}</context></task>\n",
    "    The output should be only the answer generated from the context.\n",
    "\n",
    "    <rules>\n",
    "    1. Only use the given context as a source for generating the answer.\n",
    "    2. Be as precise as possible with answering the question.\n",
    "    3. Be concise in answering the question and only answer the question at hand rather than adding extra information.\n",
    "    </rules>\n",
    "\n",
    "    Only output the generated answer as a sentence. No extra characters.\n",
    "    </Task>\n",
    "    </Instructions>\n",
    "    ''')\n",
    "\n",
    "answer = llm_invoke(\n",
    "    llm=llama3_1_70b_langchain,\n",
    "    _my_prompt_template=answer_prompt_template.format(\n",
    "        context=rec_docs_splitted[2].page_content,\n",
    "        question=question.content\n",
    "    )\n",
    ")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a797713-eef6-41d4-83ff-d5d7234e87ca",
   "metadata": {},
   "source": [
    "### Extracting Relevant Context\n",
    "---\n",
    "\n",
    "To make the dataset verifiable you can use the following prompt to extract the relevant sentences from the given context to answer the generated question. Knowing the relevant sentences you can easily check whether the question and answer are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4caa69a-460c-4266-81cb-e5e1a17e6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our Stores business, customers have enthusiastically responded to our relentless focus on selection, price, and convenience.\n",
      "We continue to have the broadest retail selection, with hundreds of millions of products\n",
      " ---- \n",
      "in 2022 to $35.5B (up $48.3B).\n",
      "While we’ve made meaningful progress on our financial measures, what we’re most pleased about is the\n",
      "continued customer experience improvements across our businesses.\n",
      "In our Stores business, customers have enthusiastically responded to our relentless focus on selection, price,\n",
      "and convenience. We continue to have the broadest retail selection, with hundreds of millions of products\n"
     ]
    }
   ],
   "source": [
    "source_prompt_template = PromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    template='''\n",
    "    <Instructions>\n",
    "    Here is the context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Your task is to extract the relevant sentences from the given context that can potentially help answer the following question.\n",
    "    You are not allowed to make any changes to the sentences from the context.\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Output only the relevant sentences you found, one sentence per line, without any extra characters or explanations.\n",
    "    </Instructions>\n",
    "    ''')\n",
    "\n",
    "source_sentence = llm_invoke(\n",
    "    llm=llama3_1_70b_langchain,\n",
    "    _my_prompt_template=source_prompt_template.format(\n",
    "        context=rec_docs_splitted[2].page_content,\n",
    "        question=question.content\n",
    "    )\n",
    ")\n",
    "print(source_sentence.content)\n",
    "print(' ---- ')\n",
    "print(rec_docs_splitted[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4c33b-cb32-412f-a218-b19b08c2d441",
   "metadata": {},
   "source": [
    "### Evolving Questions to fit end-users behaviour\n",
    "---\n",
    "\n",
    "\n",
    "When generating question & answer pairs from the same prompt for the whole dataset it might appear that the questions are repetitive, similar in form and thus not mimic real enduser behavior. In this section you evolve the existing generated question to for example make it shorter and more precise. The prompt for generating questions that fit your use case heavily depend on your use case and thus your prompt must reflect your endusers by for instance setting the rules accordingly or by providing examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35349c02-a0f2-4eea-ad0e-164b03d01890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the Stores biz's most extensive retail assortment?\n"
     ]
    }
   ],
   "source": [
    "question_compress_ = PromptTemplate(\n",
    "    input_variables=['question'],\n",
    "    template='''\n",
    "    <Instructions>\n",
    "    <role>You are an experienced linguistics expert for building testsets for large language model applications.</role>\n",
    "\n",
    "    <task>It is your task to rewrite the following question in a more indirect and compressed form, following these rules:\n",
    "\n",
    "    <rules>\n",
    "    1. Make the question more indirect\n",
    "    2. Use abbreviations if applicable, but remain professional, and represent the same context.\n",
    "    </rules>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Your output should only be the rewritten question with a question mark \"?\" at the end. \n",
    "    Do not provide any other explanation or text.\n",
    "    </task>\n",
    "    </Instructions>\n",
    "    ''')\n",
    "\n",
    "\n",
    "compressed_question = llm_invoke(\n",
    "    llm=llama3_1_70b_langchain,\n",
    "    _my_prompt_template=question_compress_.format(\n",
    "        question=question.content\n",
    "    )\n",
    ")\n",
    "print(compressed_question.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b59ad-82ab-4ca4-a512-dd652b6f47e4",
   "metadata": {},
   "source": [
    "### Putting it all together to automate dataset generation\n",
    "---\n",
    "\n",
    "We will put everything together, and will output to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "490722fa-9da8-4091-9aab-35871a6dc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_doc(\n",
    "    doc: langchain_core.documents.base.Document,\n",
    "    llm: langchain_aws.chat_models,\n",
    "    verbose: bool = False\n",
    ") -> Tuple[str, str, str, str, list, Dict[str, str]]:\n",
    "    _reference_chunk = doc.page_content\n",
    "    _metadata = doc.metadata\n",
    "    _question = question = llm_invoke(\n",
    "        llm=llm,\n",
    "        _my_prompt_template=initial_question_prompt_template.format(context=_reference_chunk)\n",
    "    )\n",
    "    question = _question.content\n",
    "    _answer = llm_invoke(\n",
    "        llm=llm,\n",
    "        _my_prompt_template=answer_prompt_template.format(\n",
    "            context=_reference_chunk,\n",
    "            question=_question\n",
    "        )\n",
    "    )\n",
    "    answer = _answer.content\n",
    "\n",
    "    _source_sentence = llm_invoke(\n",
    "        llm=llm,\n",
    "        _my_prompt_template=source_prompt_template.format(\n",
    "            context=_reference_chunk,\n",
    "            question=question\n",
    "        )\n",
    "    )\n",
    "    source_sentence = _source_sentence.content\n",
    "\n",
    "    _compressed_question = llm_invoke(\n",
    "        llm=llm,\n",
    "        _my_prompt_template=question_compress_.format(\n",
    "            question=question\n",
    "        )\n",
    "    )\n",
    "    compressed_question = _compressed_question.content\n",
    "    if verbose:\n",
    "        print('Here is the generated question from {}'.format(llm.model_id))\n",
    "        print(' ------ ')\n",
    "        print('Question: {}'.format(question))\n",
    "        print('Compressed Question: {}'.format(compressed_question))\n",
    "        print('Answer: {}'.format(answer))\n",
    "        print('Source sentence: {}'.format(source_sentence))\n",
    "        print('Source chunk: {}'.format(_reference_chunk))\n",
    "        print('Metadata: {}'.format(_metadata))\n",
    "    return [question, compressed_question, answer, source_sentence, [_reference_chunk], _metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fdbf58-6a0a-4ff1-aa6c-4c227d391646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qna_dataframe(\n",
    "    docs: List[langchain_core.documents.base.Document], \n",
    "    llm: langchain_aws.chat_models,\n",
    "    verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    print('Generating {} questions ...'.format(len(docs)))\n",
    "    qna_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"question\", \"compressed_question\", \"ref_answer\", \"source_sentence\",\n",
    "            'source_chunk', 'source_document'\n",
    "        ]\n",
    "    )\n",
    "    for idx, doc in enumerate(docs):\n",
    "        _out_row = generate_qa_from_doc(\n",
    "            doc=doc,\n",
    "            llm=llm,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        qna_df.loc[len(qna_df)] = _out_row\n",
    "        if (idx+1) % 10 == 0:\n",
    "            print(' -- Generating {} QnA pairs...'.format(idx+1))\n",
    "\n",
    "    print('Generate completed!')\n",
    "    return qna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533bd7fb-0253-43c9-ac25-af50b72960a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 20 questions ...\n",
      " -- Generating 10 QnA pairs...\n",
      " -- Generating 20 QnA pairs...\n",
      "Generate completed!\n"
     ]
    }
   ],
   "source": [
    "qna_df = generate_qna_dataframe(\n",
    "    docs=random.sample(rec_docs_splitted, 20),\n",
    "    llm=llama3_1_70b_langchain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e81e1514-ae0e-4948-8342-c365ef4bfef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>compressed_question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>source_sentence</th>\n",
       "      <th>source_chunk</th>\n",
       "      <th>source_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the names of the chips that were anno...</td>\n",
       "      <td>Which 2nd-gen chipsets are being utilized by A...</td>\n",
       "      <td>Trainium and Inferentia.</td>\n",
       "      <td>announced second versions of our Trainium and ...</td>\n",
       "      <td>[announced second versions of our Trainium and...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the company's priorities in terms of ...</td>\n",
       "      <td>What are key spend &amp; cultural priorities for a...</td>\n",
       "      <td>The company's priorities in terms of spending ...</td>\n",
       "      <td>We will work hard to spend wisely and maintain...</td>\n",
       "      <td>[the present value of future cash flows, we’ll...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2021-Shareholder-Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the annual revenue run rate of AWS fi...</td>\n",
       "      <td>What was AWS' ARR 15 yrs post-investment decis...</td>\n",
       "      <td>AWS had an annual revenue run rate of $85B fif...</td>\n",
       "      <td>Fifteen years later, AWS is now an $85B annual...</td>\n",
       "      <td>[be investing so much in cloud computing. But,...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the year in which Amazon's original Sh...</td>\n",
       "      <td>When was Amazon's inaugural Shareholder Letter...</td>\n",
       "      <td>The year in which Amazon's original Shareholde...</td>\n",
       "      <td>P .S. As we have always done, our original 199...</td>\n",
       "      <td>[Amazon, all of which are still in their early...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the changes in Amazon.com's employee...</td>\n",
       "      <td>What shifts occurred in Amazon's workforce &amp; D...</td>\n",
       "      <td>Amazon.com's employee base grew from 158 to 61...</td>\n",
       "      <td>• Amazon.com’s employee base grew from 158 to ...</td>\n",
       "      <td>[Infrastructure\\nDuring 1997, we worked hard t...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the names of the chips that were anno...   \n",
       "1  What are the company's priorities in terms of ...   \n",
       "2  What was the annual revenue run rate of AWS fi...   \n",
       "3  What is the year in which Amazon's original Sh...   \n",
       "4  What were the changes in Amazon.com's employee...   \n",
       "\n",
       "                                 compressed_question  \\\n",
       "0  Which 2nd-gen chipsets are being utilized by A...   \n",
       "1  What are key spend & cultural priorities for a...   \n",
       "2  What was AWS' ARR 15 yrs post-investment decis...   \n",
       "3  When was Amazon's inaugural Shareholder Letter...   \n",
       "4  What shifts occurred in Amazon's workforce & D...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0                           Trainium and Inferentia.   \n",
       "1  The company's priorities in terms of spending ...   \n",
       "2  AWS had an annual revenue run rate of $85B fif...   \n",
       "3  The year in which Amazon's original Shareholde...   \n",
       "4  Amazon.com's employee base grew from 158 to 61...   \n",
       "\n",
       "                                     source_sentence  \\\n",
       "0  announced second versions of our Trainium and ...   \n",
       "1  We will work hard to spend wisely and maintain...   \n",
       "2  Fifteen years later, AWS is now an $85B annual...   \n",
       "3  P .S. As we have always done, our original 199...   \n",
       "4  • Amazon.com’s employee base grew from 158 to ...   \n",
       "\n",
       "                                        source_chunk  \\\n",
       "0  [announced second versions of our Trainium and...   \n",
       "1  [the present value of future cash flows, we’ll...   \n",
       "2  [be investing so much in cloud computing. But,...   \n",
       "3  [Amazon, all of which are still in their early...   \n",
       "4  [Infrastructure\\nDuring 1997, we worked hard t...   \n",
       "\n",
       "                                     source_document  \n",
       "0  {'source': '_raw_data/AMZN-2023-Shareholder-Le...  \n",
       "1  {'source': '_raw_data/AMZN-2021-Shareholder-Le...  \n",
       "2  {'source': '_raw_data/AMZN-2022-Shareholder-Le...  \n",
       "3  {'source': '_raw_data/AMZN-2022-Shareholder-Le...  \n",
       "4  {'source': '_raw_data/AMZN-2023-Shareholder-Le...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(qna_df.shape)\n",
    "qna_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30562d05-c8a6-4874-ba8a-aab06da0a0a1",
   "metadata": {},
   "source": [
    "## Assessing the questions quality using Critique Agents\n",
    "---\n",
    "\n",
    "Critique agents are a technique used in natural language processing (NLP) to evaluate the quality and suitability of questions in a dataset for a particular task or application. In this case, the critique agents are employed to assess whether the questions in a dataset are valid for a Retrieval-Augmented Generation (RAG) system, which is a type of language model that combines information retrieval and generation capabilities.\n",
    "\n",
    "The two main metrics evaluated by the critique agents are relevance and groundedness.\n",
    "\n",
    "### Relevance\n",
    "\n",
    "Relevance measures <u>how useful and applicable a question</u> is for a specific domain or context. In the context of business analysis, the relevance prompt evaluates questions based on the following criteria:\n",
    "\n",
    "- Is the question directly relevant to the work of financial and business analysts on Wall Street?\n",
    "- Does the question address a practical problem or use case that analysts might encounter?\n",
    "- Is the question clear and well-defined, avoiding ambiguity or vagueness?\n",
    "- Does the question require a substantive answer that demonstrates understanding of financial topics?\n",
    "- Would answering the question provide insights or knowledge that could be applied to real-world company evaluation tasks?\n",
    "\n",
    "The relevance score ranges from 1 to 5, with a higher score indicating greater relevance and usefulness for business analysts.\n",
    "\n",
    "\n",
    "### Groundedness\n",
    "\n",
    "Groundedness measures <u>how well a question can be answered based on the provided context</u> or information. The groundedness prompt evaluates questions based on the following criteria:\n",
    "\n",
    "- Can the question be answered using only the information provided in the given context?\n",
    "- Does the context provide little, some, substantial, or all the information needed to answer the question?\n",
    "\n",
    "The groundedness score also ranges from 1 to 5, with the following interpretations:\n",
    "- The question cannot be answered at all based on the given context.\n",
    "- The context provides very little relevant information to answer the question.\n",
    "- The context provides some relevant information to partially answer the question.\n",
    "- The context provides substantial information to answer most aspects of the question.\n",
    "- The context provides all the information needed to fully and unambiguously answer the question.\n",
    "\n",
    "\n",
    "By evaluating both relevance and groundedness, the critique agents can help identify questions in the dataset that are well-suited for the RAG system, as well as those that may need to be revised, removed, or supplemented with additional context or information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "208c1031-1052-452c-88a3-f094e02951c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundedness_check_prompt_template = PromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    template='''\n",
    "    <Instructions>\n",
    "    You will be given a context and a question related to that context.\n",
    "    Your task is to provide an evaluation of how well the given question can be answered using only the information provided in the context. Rate this on a scale from 1 to 5, where:\n",
    "\n",
    "    1 = The question cannot be answered at all based on the given context\n",
    "    2 = The context provides very little relevant information to answer the question\n",
    "    3 = The context provides some relevant information to partially answer the question \n",
    "    4 = The context provides substantial information to answer most aspects of the question\n",
    "    5 = The context provides all the information needed to fully and unambiguously answer the question\n",
    "\n",
    "    First, read through the provided context carefully:\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Then read the question:\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Evaluate how well you think the question can be answered using only the context information. Provide your reasoning first in an <evaluation> section, explaining what relevant or missing information from the context led you to your evaluation score in only one sentence.\n",
    "\n",
    "    Provide your evaluation in the following format:\n",
    "\n",
    "    <rating>(Your rating from 1 to 5)</rating>\n",
    "    <evaluation>(Your evaluation and reasoning for the rating)</evaluation>\n",
    "    </Instructions>\n",
    "    ''')\n",
    "\n",
    "relevance_check_prompt_template = PromptTemplate(\n",
    "    input_variables=['question'],\n",
    "    template='''\n",
    "    <Instructions>\n",
    "    You will be given a question related to Amazon Shareholder letters. Your task is to evaluate how useful this question would be for a business analyst working in WallStreet.\n",
    "\n",
    "    To evaluate the usefulness of the question, consider the following criteria:\n",
    "\n",
    "    1. Relevance: Is the question directly relevant to your work? Questions that are too broad or unrelated to this domain should receive a lower rating.\n",
    "    2. Practicality: Does the question address a practical problem or use case that analysts might encounter? Theoretical or overly academic questions may be less useful.\n",
    "    3. Clarity: Is the question clear and well-defined? Ambiguous or vague questions are less useful.\n",
    "    4. Depth: Does the question require a substantive answer that demonstrates understanding of financial topics? Surface-level questions may be less useful.\n",
    "    5. Applicability: Would answering this question provide insights or knowledge that could be applied to real-world company evaluation tasks? Questions with limited applicability should receive a lower rating.\n",
    "\n",
    "    Provide your evaluation in the following format:\n",
    "\n",
    "    <rating>(Your rating from 1 to 5)</rating>\n",
    "    <evaluation>(Your evaluation and reasoning for the rating)</evaluation>\n",
    "\n",
    "    Here is an example: \n",
    "    <evaluation>The question is very relevant to the persona because it asks about financial information of a company</evaluation>\n",
    "    <rating>5</rating>\n",
    "\n",
    "    Here is the question:\n",
    "    {question}\n",
    "    \n",
    "    </Instructions>\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28f12bb8-9df6-4efc-b4ea-fe5bc2f57a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(eval_str: str) -> Optional[str]:\n",
    "    pattern = r'<rating>(.*?)</rating>'\n",
    "    _match = re.search(pattern, eval_str)\n",
    "    if _match:\n",
    "        rating = _match.group(1)\n",
    "        return rating\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_evaluation_reasoning(eval_str: str) -> Optional[str]:\n",
    "    pattern = r'<evaluation>(.*?)</evaluation>'\n",
    "    _match = re.search(pattern, eval_str)\n",
    "    if _match:\n",
    "        reasoning = _match.group(1)\n",
    "        return reasoning\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c048c9-9eae-4999-ab5e-030b730ad03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rating_n_reasoning(\n",
    "    df: pd.DataFrame,\n",
    "    llm: langchain_aws.chat_models,\n",
    ") -> pd.DataFrame:\n",
    "    _df = df.copy()\n",
    "    for idx, row in _df.iterrows():\n",
    "        _question = row['question']\n",
    "        _context_chunk = row['source_chunk'][0]\n",
    "        _groundedness = llm_invoke(\n",
    "            llm=llm,\n",
    "            _my_prompt_template=groundedness_check_prompt_template.format(\n",
    "                question=_question,\n",
    "                context=_context_chunk\n",
    "            )\n",
    "        )\n",
    "        _relevancy = llm_invoke(\n",
    "            llm=llm,\n",
    "            _my_prompt_template=relevance_check_prompt_template.format(\n",
    "                question=_question,\n",
    "            )\n",
    "        )\n",
    "        groundedness_rating = get_rating(_groundedness.content)\n",
    "        groundedness_reason = get_evaluation_reasoning(_groundedness.content)\n",
    "        relevance_rating = get_rating(_relevancy.content)\n",
    "        relevance_reason = get_evaluation_reasoning(_relevancy.content)\n",
    "        _df.at[idx, 'groundedness_rating'] = int(groundedness_rating)\n",
    "        _df.at[idx, 'groundedness_reason'] = groundedness_reason\n",
    "        _df.at[idx, 'relevance_rating'] = int(relevance_rating)\n",
    "        _df.at[idx, 'relevance_reason'] = relevance_reason\n",
    "        if (idx+1) % 2 == 0:\n",
    "            print(' --- processing up to {} rows'.format(idx+1))\n",
    "\n",
    "    return _df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bbb6489-3bf7-4431-82c7-fb4c2e5f724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- processing up to 2 rows\n",
      " --- processing up to 4 rows\n",
      " --- processing up to 6 rows\n",
      " --- processing up to 8 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      " --- processing up to 10 rows\n",
      " --- processing up to 12 rows\n",
      " --- processing up to 14 rows\n",
      " --- processing up to 16 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      " --- processing up to 18 rows\n",
      " --- processing up to 20 rows\n"
     ]
    }
   ],
   "source": [
    "qna_with_assessment_df = append_rating_n_reasoning(\n",
    "    df=qna_df,\n",
    "    llm=llama3_1_405b_langchain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "542c3e82-18cc-4f23-846d-d680ed8e7eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>compressed_question</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>source_sentence</th>\n",
       "      <th>source_chunk</th>\n",
       "      <th>source_document</th>\n",
       "      <th>groundedness_rating</th>\n",
       "      <th>groundedness_reason</th>\n",
       "      <th>relevance_rating</th>\n",
       "      <th>relevance_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the names of the chips that were anno...</td>\n",
       "      <td>Which 2nd-gen chipsets are being utilized by A...</td>\n",
       "      <td>Trainium and Inferentia.</td>\n",
       "      <td>announced second versions of our Trainium and ...</td>\n",
       "      <td>[announced second versions of our Trainium and...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the necessary informa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The question is not relevant to a business ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the company's priorities in terms of ...</td>\n",
       "      <td>What are key spend &amp; cultural priorities for a...</td>\n",
       "      <td>The company's priorities in terms of spending ...</td>\n",
       "      <td>We will work hard to spend wisely and maintain...</td>\n",
       "      <td>[the present value of future cash flows, we’ll...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2021-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the necessary informa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The question is very relevant to a business an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the annual revenue run rate of AWS fi...</td>\n",
       "      <td>What was AWS' ARR 15 yrs post-investment decis...</td>\n",
       "      <td>AWS had an annual revenue run rate of $85B fif...</td>\n",
       "      <td>Fifteen years later, AWS is now an $85B annual...</td>\n",
       "      <td>[be investing so much in cloud computing. But,...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the necessary informa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This question is highly relevant to a business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the year in which Amazon's original Sh...</td>\n",
       "      <td>When was Amazon's inaugural Shareholder Letter...</td>\n",
       "      <td>The year in which Amazon's original Shareholde...</td>\n",
       "      <td>P .S. As we have always done, our original 199...</td>\n",
       "      <td>[Amazon, all of which are still in their early...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context explicitly mentions the year 1997 ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The question is somewhat relevant to a busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the changes in Amazon.com's employee...</td>\n",
       "      <td>What shifts occurred in Amazon's workforce &amp; D...</td>\n",
       "      <td>Amazon.com's employee base grew from 158 to 61...</td>\n",
       "      <td>• Amazon.com’s employee base grew from 158 to ...</td>\n",
       "      <td>[Infrastructure\\nDuring 1997, we worked hard t...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the necessary informa...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to a business analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are some examples of companies and indust...</td>\n",
       "      <td>Which entities (cos., sectors) have seen subst...</td>\n",
       "      <td>Examples of companies and industries significa...</td>\n",
       "      <td>whole companies sprang up quickly on top of AW...</td>\n",
       "      <td>[blocks over time (we now have over 240 at bui...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the information neede...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to a business analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What opportunity does Amazon.com have as large...</td>\n",
       "      <td>What prospects emerge for Amazon as major play...</td>\n",
       "      <td>Amazon.com has a window of opportunity as larg...</td>\n",
       "      <td>We have a window of opportunity as larger play...</td>\n",
       "      <td>[customers money and precious time. Tomorrow, ...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The context provides substantial information t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are some ways in which serendipitous inte...</td>\n",
       "      <td>How do chance encounters facilitate innovation?</td>\n",
       "      <td>Serendipitous interactions can help the proces...</td>\n",
       "      <td>moments from people staying behind after a mee...</td>\n",
       "      <td>[moments from people staying behind after a me...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The context provides substantial information t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The question is somewhat relevant to a busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What enhancements were made to the store in 1997?</td>\n",
       "      <td>What '97 upgrades did the store undergo?</td>\n",
       "      <td>In 1997, the store was substantially enhanced.</td>\n",
       "      <td>We maintained a dogged focus on improving the ...</td>\n",
       "      <td>[could not get any other way, and began servin...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The context provides very little relevant info...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The question is somewhat relevant to a busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the company's goal in the rapidly evol...</td>\n",
       "      <td>What strategic objectives is the co. pursuing ...</td>\n",
       "      <td>The company's goal is to solidify and extend i...</td>\n",
       "      <td>Our goal is to move quickly to solidify and ex...</td>\n",
       "      <td>[landscape has continued to evolve at a fast p...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2021-Shareholder-Le...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The context provides substantial information t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This question is highly relevant to a business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the fundamental measure of success tha...</td>\n",
       "      <td>What KPI will directly correlate with sustaini...</td>\n",
       "      <td>The fundamental measure of success will be the...</td>\n",
       "      <td>We believe that a fundamental measure of our s...</td>\n",
       "      <td>[risk: it requires serious investment and cris...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context explicitly states that \"a fundamen...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The question is very relevant to a business an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What are the company's goals and plans for gro...</td>\n",
       "      <td>What are the co.'s e-commerce &amp; merchandising ...</td>\n",
       "      <td>The company's goal is to solidify and extend i...</td>\n",
       "      <td>Our goal remains to continue to solidify and e...</td>\n",
       "      <td>[We are still in the early stages of learning ...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The context provides substantial information t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This question is highly relevant to a business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What improvements does AWS's Inferentia2 chip ...</td>\n",
       "      <td>What are the key upgrades in AWS's Inferentia2...</td>\n",
       "      <td>AWS's Inferentia2 chip offers up to four times...</td>\n",
       "      <td>Our Inferentia2 chip, which just launched, off...</td>\n",
       "      <td>[a hundred million dollars in capital expense ...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides explicit and specific inf...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to the domain of busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is necessary to build a sustainable, long...</td>\n",
       "      <td>What are the key factors for establishing a sc...</td>\n",
       "      <td>To build a sustainable, long-lasting, growing ...</td>\n",
       "      <td>While it’s tempting in turbulent times only to...</td>\n",
       "      <td>[live sports, audio, and grocery products. We’...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context directly answers the question by s...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to the persona becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How many new Availability Zones and geographic...</td>\n",
       "      <td>What's the update on AWS's infrastructure expa...</td>\n",
       "      <td>Six new Availability Zones and 33 geographic R...</td>\n",
       "      <td>We continued expanding our AWS infrastructure ...</td>\n",
       "      <td>[times more memory capacity than Trainium1. We...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The context provides substantial information t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to a business analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is the goal for Alexa and Alexa-related d...</td>\n",
       "      <td>What is the desired customer life impact (CLI)...</td>\n",
       "      <td>The goal for Alexa and Alexa-related devices i...</td>\n",
       "      <td>Our goal is for Alexa to be the world’s most h...</td>\n",
       "      <td>[quite early with respect to what Alexa and Al...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2021-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context explicitly states the goal for Ale...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to a business analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What metrics does the company use to measure i...</td>\n",
       "      <td>What KPIs indicate a co.'s market lead?</td>\n",
       "      <td>The company measures its market leadership thr...</td>\n",
       "      <td>We first measure ourselves in terms of the met...</td>\n",
       "      <td>[directly to higher revenue, higher profitabil...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2021-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context explicitly mentions the metrics us...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The question is very relevant to a business an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How many SKUs are housed in the new, same-day ...</td>\n",
       "      <td>What's the SKU capacity of new same-day fulfil...</td>\n",
       "      <td>The new, same-day fulfillment facilities in th...</td>\n",
       "      <td>They’re located in the largest metro areas aro...</td>\n",
       "      <td>[constrained by the primitives you’ve built an...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the information neede...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The question is relevant to a business analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What adjustments did Amazon make in their inve...</td>\n",
       "      <td>What tweaks did AMZN make to their investment ...</td>\n",
       "      <td>Amazon made adjustments in their investment de...</td>\n",
       "      <td>businesses to meaningfully improve customer ex...</td>\n",
       "      <td>[businesses to meaningfully improve customer e...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2022-Shareholder-Le...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The context provides some relevant information...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The question is very relevant to a business an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What were some positive trends observed by the...</td>\n",
       "      <td>What notable uptrends emerged by 2023's close ...</td>\n",
       "      <td>By the end of 2023, cost optimization efforts ...</td>\n",
       "      <td>By the end of 2023, we saw cost optimization a...</td>\n",
       "      <td>[in less expensive storage layers), and Saving...</td>\n",
       "      <td>{'source': '_raw_data/AMZN-2023-Shareholder-Le...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The context provides all the necessary informa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The question is very relevant to a business an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What are the names of the chips that were anno...   \n",
       "1   What are the company's priorities in terms of ...   \n",
       "2   What was the annual revenue run rate of AWS fi...   \n",
       "3   What is the year in which Amazon's original Sh...   \n",
       "4   What were the changes in Amazon.com's employee...   \n",
       "5   What are some examples of companies and indust...   \n",
       "6   What opportunity does Amazon.com have as large...   \n",
       "7   What are some ways in which serendipitous inte...   \n",
       "8   What enhancements were made to the store in 1997?   \n",
       "9   What is the company's goal in the rapidly evol...   \n",
       "10  What is the fundamental measure of success tha...   \n",
       "11  What are the company's goals and plans for gro...   \n",
       "12  What improvements does AWS's Inferentia2 chip ...   \n",
       "13  What is necessary to build a sustainable, long...   \n",
       "14  How many new Availability Zones and geographic...   \n",
       "15  What is the goal for Alexa and Alexa-related d...   \n",
       "16  What metrics does the company use to measure i...   \n",
       "17  How many SKUs are housed in the new, same-day ...   \n",
       "18  What adjustments did Amazon make in their inve...   \n",
       "19  What were some positive trends observed by the...   \n",
       "\n",
       "                                  compressed_question  \\\n",
       "0   Which 2nd-gen chipsets are being utilized by A...   \n",
       "1   What are key spend & cultural priorities for a...   \n",
       "2   What was AWS' ARR 15 yrs post-investment decis...   \n",
       "3   When was Amazon's inaugural Shareholder Letter...   \n",
       "4   What shifts occurred in Amazon's workforce & D...   \n",
       "5   Which entities (cos., sectors) have seen subst...   \n",
       "6   What prospects emerge for Amazon as major play...   \n",
       "7     How do chance encounters facilitate innovation?   \n",
       "8            What '97 upgrades did the store undergo?   \n",
       "9   What strategic objectives is the co. pursuing ...   \n",
       "10  What KPI will directly correlate with sustaini...   \n",
       "11  What are the co.'s e-commerce & merchandising ...   \n",
       "12  What are the key upgrades in AWS's Inferentia2...   \n",
       "13  What are the key factors for establishing a sc...   \n",
       "14  What's the update on AWS's infrastructure expa...   \n",
       "15  What is the desired customer life impact (CLI)...   \n",
       "16            What KPIs indicate a co.'s market lead?   \n",
       "17  What's the SKU capacity of new same-day fulfil...   \n",
       "18  What tweaks did AMZN make to their investment ...   \n",
       "19  What notable uptrends emerged by 2023's close ...   \n",
       "\n",
       "                                           ref_answer  \\\n",
       "0                            Trainium and Inferentia.   \n",
       "1   The company's priorities in terms of spending ...   \n",
       "2   AWS had an annual revenue run rate of $85B fif...   \n",
       "3   The year in which Amazon's original Shareholde...   \n",
       "4   Amazon.com's employee base grew from 158 to 61...   \n",
       "5   Examples of companies and industries significa...   \n",
       "6   Amazon.com has a window of opportunity as larg...   \n",
       "7   Serendipitous interactions can help the proces...   \n",
       "8      In 1997, the store was substantially enhanced.   \n",
       "9   The company's goal is to solidify and extend i...   \n",
       "10  The fundamental measure of success will be the...   \n",
       "11  The company's goal is to solidify and extend i...   \n",
       "12  AWS's Inferentia2 chip offers up to four times...   \n",
       "13  To build a sustainable, long-lasting, growing ...   \n",
       "14  Six new Availability Zones and 33 geographic R...   \n",
       "15  The goal for Alexa and Alexa-related devices i...   \n",
       "16  The company measures its market leadership thr...   \n",
       "17  The new, same-day fulfillment facilities in th...   \n",
       "18  Amazon made adjustments in their investment de...   \n",
       "19  By the end of 2023, cost optimization efforts ...   \n",
       "\n",
       "                                      source_sentence  \\\n",
       "0   announced second versions of our Trainium and ...   \n",
       "1   We will work hard to spend wisely and maintain...   \n",
       "2   Fifteen years later, AWS is now an $85B annual...   \n",
       "3   P .S. As we have always done, our original 199...   \n",
       "4   • Amazon.com’s employee base grew from 158 to ...   \n",
       "5   whole companies sprang up quickly on top of AW...   \n",
       "6   We have a window of opportunity as larger play...   \n",
       "7   moments from people staying behind after a mee...   \n",
       "8   We maintained a dogged focus on improving the ...   \n",
       "9   Our goal is to move quickly to solidify and ex...   \n",
       "10  We believe that a fundamental measure of our s...   \n",
       "11  Our goal remains to continue to solidify and e...   \n",
       "12  Our Inferentia2 chip, which just launched, off...   \n",
       "13  While it’s tempting in turbulent times only to...   \n",
       "14  We continued expanding our AWS infrastructure ...   \n",
       "15  Our goal is for Alexa to be the world’s most h...   \n",
       "16  We first measure ourselves in terms of the met...   \n",
       "17  They’re located in the largest metro areas aro...   \n",
       "18  businesses to meaningfully improve customer ex...   \n",
       "19  By the end of 2023, we saw cost optimization a...   \n",
       "\n",
       "                                         source_chunk  \\\n",
       "0   [announced second versions of our Trainium and...   \n",
       "1   [the present value of future cash flows, we’ll...   \n",
       "2   [be investing so much in cloud computing. But,...   \n",
       "3   [Amazon, all of which are still in their early...   \n",
       "4   [Infrastructure\\nDuring 1997, we worked hard t...   \n",
       "5   [blocks over time (we now have over 240 at bui...   \n",
       "6   [customers money and precious time. Tomorrow, ...   \n",
       "7   [moments from people staying behind after a me...   \n",
       "8   [could not get any other way, and began servin...   \n",
       "9   [landscape has continued to evolve at a fast p...   \n",
       "10  [risk: it requires serious investment and cris...   \n",
       "11  [We are still in the early stages of learning ...   \n",
       "12  [a hundred million dollars in capital expense ...   \n",
       "13  [live sports, audio, and grocery products. We’...   \n",
       "14  [times more memory capacity than Trainium1. We...   \n",
       "15  [quite early with respect to what Alexa and Al...   \n",
       "16  [directly to higher revenue, higher profitabil...   \n",
       "17  [constrained by the primitives you’ve built an...   \n",
       "18  [businesses to meaningfully improve customer e...   \n",
       "19  [in less expensive storage layers), and Saving...   \n",
       "\n",
       "                                      source_document  groundedness_rating  \\\n",
       "0   {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  5.0   \n",
       "1   {'source': '_raw_data/AMZN-2021-Shareholder-Le...                  5.0   \n",
       "2   {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  5.0   \n",
       "3   {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  5.0   \n",
       "4   {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  5.0   \n",
       "5   {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  5.0   \n",
       "6   {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  4.0   \n",
       "7   {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  4.0   \n",
       "8   {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  2.0   \n",
       "9   {'source': '_raw_data/AMZN-2021-Shareholder-Le...                  4.0   \n",
       "10  {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  5.0   \n",
       "11  {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  4.0   \n",
       "12  {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  5.0   \n",
       "13  {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  5.0   \n",
       "14  {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  4.0   \n",
       "15  {'source': '_raw_data/AMZN-2021-Shareholder-Le...                  5.0   \n",
       "16  {'source': '_raw_data/AMZN-2021-Shareholder-Le...                  5.0   \n",
       "17  {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  5.0   \n",
       "18  {'source': '_raw_data/AMZN-2022-Shareholder-Le...                  3.0   \n",
       "19  {'source': '_raw_data/AMZN-2023-Shareholder-Le...                  5.0   \n",
       "\n",
       "                                  groundedness_reason  relevance_rating  \\\n",
       "0   The context provides all the necessary informa...               1.0   \n",
       "1   The context provides all the necessary informa...               5.0   \n",
       "2   The context provides all the necessary informa...               5.0   \n",
       "3   The context explicitly mentions the year 1997 ...               2.0   \n",
       "4   The context provides all the necessary informa...               4.0   \n",
       "5   The context provides all the information neede...               4.0   \n",
       "6   The context provides substantial information t...               5.0   \n",
       "7   The context provides substantial information t...               2.0   \n",
       "8   The context provides very little relevant info...               2.0   \n",
       "9   The context provides substantial information t...               5.0   \n",
       "10  The context explicitly states that \"a fundamen...               5.0   \n",
       "11  The context provides substantial information t...               5.0   \n",
       "12  The context provides explicit and specific inf...               4.0   \n",
       "13  The context directly answers the question by s...               4.0   \n",
       "14  The context provides substantial information t...               4.0   \n",
       "15  The context explicitly states the goal for Ale...               4.0   \n",
       "16  The context explicitly mentions the metrics us...               5.0   \n",
       "17  The context provides all the information neede...               4.0   \n",
       "18  The context provides some relevant information...               5.0   \n",
       "19  The context provides all the necessary informa...               5.0   \n",
       "\n",
       "                                     relevance_reason  \n",
       "0   The question is not relevant to a business ana...  \n",
       "1   The question is very relevant to a business an...  \n",
       "2   This question is highly relevant to a business...  \n",
       "3   The question is somewhat relevant to a busines...  \n",
       "4   The question is relevant to a business analyst...  \n",
       "5   The question is relevant to a business analyst...  \n",
       "6                                                None  \n",
       "7   The question is somewhat relevant to a busines...  \n",
       "8   The question is somewhat relevant to a busines...  \n",
       "9   This question is highly relevant to a business...  \n",
       "10  The question is very relevant to a business an...  \n",
       "11  This question is highly relevant to a business...  \n",
       "12  The question is relevant to the domain of busi...  \n",
       "13  The question is relevant to the persona becaus...  \n",
       "14  The question is relevant to a business analyst...  \n",
       "15  The question is relevant to a business analyst...  \n",
       "16  The question is very relevant to a business an...  \n",
       "17  The question is relevant to a business analyst...  \n",
       "18  The question is very relevant to a business an...  \n",
       "19  The question is very relevant to a business an...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_with_assessment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7566942-4605-4203-bc4d-481d5766d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = './_eval_data'\n",
    "os.makedirs(eval_data_dir, exist_ok=True)\n",
    "qna_with_assessment_df.to_csv(os.path.join(eval_data_dir, 'eval_dataframe.csv'), index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ffdd5-41df-41a6-b2d5-32b17bde36bb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "\n",
    "This is the end of this prerequisite notebook, we have downloaded Amazon Shareholders and ingested them onto vector datastore (ChromaDB). We also use **Amazon Bedrock** to generate synthetic dataset. This technique can be powerful technique for evaluating retrieval augmented generation (RAG) workflow, specifically in the early development when real-world data is difficult to obtain. By leveraging large language models, this approach enables the creation of diverse, realistic, and representative dataset that mimic real human interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
