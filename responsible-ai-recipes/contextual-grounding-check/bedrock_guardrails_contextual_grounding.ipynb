{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1240ee56-c1af-4a0d-b06d-8142cc56b91c",
   "metadata": {},
   "source": [
    "# Implementing AI Safety: Exploring Contextual Grounding with Amazon Bedrock and Meta Llama Models\n",
    "\n",
    "\n",
    "## Introduction\n",
    "---\n",
    "[**Amazon Bedrock**](https://aws.amazon.com/bedrock/) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies through a single API. It provides a comprehensive set of capabilities to build generative AI applications with security, privacy, and responsible AI.\n",
    "\n",
    "Guardrails in Amazon Bedrock are a crucial feature that allows developers to implement safeguards and controls on language model outputs. These guardrails help ensure that AI-generated content aligns with business policies, maintains brand consistency, and adheres to ethical standards. For more information on Amazon Bedrock guardrails, please kindly refer to the [official AWS documentation on guardrails](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html).\n",
    "\n",
    "In this notebook, we will explore how to implement **AI safety guardrails**, specifically on <u>contextual grounding check</u> on RAG application, focusing on Meta Llama large language model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59f167-ba09-4bcf-ae42-5a8f5154c60d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484deca-33d5-4bfb-9fa7-e1a67bad0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89beb9-349f-473a-a9c8-11fb8e1b18e3",
   "metadata": {},
   "source": [
    "## Bedrock Guardrail for Contextual grounding\n",
    "\n",
    "### Create Bedrock Guardrails\n",
    "---\n",
    "\n",
    "To create Bedrock Guardrails, you can use `create_guardrail` API from **boto3** client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19ab82-1ca6-453a-bd75-7a491b83a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from typing import Tuple, Optional, List, Dict\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "region_name = boto_session.region_name\n",
    "bedrock_client = boto_session.client(\n",
    "    service_name='bedrock',\n",
    "    region_name=region_name,\n",
    ")\n",
    "bedrock_runtime_client = boto_session.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region_name,\n",
    ")\n",
    "guardrail_name = 'contextual_grounding_check'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3901f-3f06-41da-9244-95da858075c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existing_guardrail(\n",
    "    guardrail_name: str,\n",
    "    boto_session: boto3.session\n",
    ") -> Tuple[bool, str]:\n",
    "    bedrock_client = boto_session.client(\n",
    "        service_name='bedrock', \n",
    "        region_name=boto_session.region_name\n",
    "    )\n",
    "    resp = bedrock_client.list_guardrails()\n",
    "    for guardrail in resp.get('guardrails', []):\n",
    "        if guardrail.get('name', '') == guardrail_name:\n",
    "            print('Guardrail \"{}\" exists'.format(guardrail_name))\n",
    "            return True, guardrail.get('id')\n",
    "\n",
    "    return False, ''\n",
    "\n",
    "\n",
    "def check_to_delete_guardrail(\n",
    "    guardrail_name: str,\n",
    "    boto_session: boto3.session\n",
    ") -> None:\n",
    "    bedrock_client = boto_session.client(\n",
    "        service_name='bedrock', \n",
    "        region_name=boto_session.region_name\n",
    "    )\n",
    "    exist_ind, _id = check_existing_guardrail(guardrail_name, boto_session)\n",
    "    if exist_ind:\n",
    "        print('Deleting existing guardrail')\n",
    "        _ = bedrock_client.delete_guardrail(guardrailIdentifier=_id)\n",
    "        time.sleep(5)\n",
    "        print('Delete completed...')\n",
    "\n",
    "    else:\n",
    "        print('No guardrail name \"{}\" found'.format(guardrail_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4c64c-1fb2-4ea4-888c-f99f74960135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_grounding_guardrail(\n",
    "    guardrail_name: str,\n",
    "    guardrail_desc: str,\n",
    "    relevance_scor: float,\n",
    "    grounding_scor: float,\n",
    "    boto_session: boto3.session,\n",
    "    tag_list: Optional[List[Dict[str, str]]] = []\n",
    ") -> dict:\n",
    "    guardrail_config = {\n",
    "        'name': guardrail_name,\n",
    "        'description': guardrail_desc,\n",
    "        'blockedInputMessaging': 'I am sorry, but I cannot process that input request.',\n",
    "        'blockedOutputsMessaging': 'I apologize, but I cannot provide this information',\n",
    "        'contextualGroundingPolicyConfig': {\n",
    "            'filtersConfig': [{\n",
    "                'type': 'RELEVANCE',\n",
    "                'threshold': relevance_scor\n",
    "            }, {\n",
    "                'type': 'GROUNDING',\n",
    "                'threshold': grounding_scor\n",
    "            }]\n",
    "        },\n",
    "        'tags': tag_list\n",
    "    }\n",
    "    try:\n",
    "        bedrock_client = boto_session.client(\n",
    "            service_name='bedrock',\n",
    "            region_name=boto_session.region_name,\n",
    "        )\n",
    "        create_resp = bedrock_client.create_guardrail(**guardrail_config)\n",
    "        time.sleep(5)\n",
    "        print('Create guardrail \"{}\" completed'.format(guardrail_name))\n",
    "        return create_resp\n",
    "    except (ClientError, Exception) as e:\n",
    "        print('Error creating guardrail: {e}'.format(e=e))\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b0cca-7a1d-4c5e-b093-c4759fe66b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_to_delete_guardrail(guardrail_name, boto_session)\n",
    "create_guardrail_resp = create_contextual_grounding_guardrail(\n",
    "    guardrail_name=guardrail_name,\n",
    "    guardrail_desc='Guardrail to detect hallunication from RAG application',\n",
    "    relevance_scor=.85,\n",
    "    grounding_scor=.85,\n",
    "    boto_session=boto_session,\n",
    "    tag_list=[{\n",
    "        'key': 'guardrail-policy',\n",
    "        'value': 'contextual-grounding-check',\n",
    "    }],\n",
    ")\n",
    "guardrail_id = create_guardrail_resp.get('guardrailId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd0485-4ab2-4c04-b7b3-6f97debcd0be",
   "metadata": {},
   "source": [
    "### Create Guardrail version\n",
    "---\n",
    "Once we have defined the guardrail, you should use `create_guardrail_version` API to create a snapshot of the guardrail when you are satisfied with a configuration, testing, or you want to do A/B testing on each configuration with another version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c951ae4-a629-41e4-b3f4-29a05e79ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_version_guardrail(\n",
    "    guardrail_id: str,\n",
    "    version_desc: str,\n",
    "    boto_session: boto3.session,\n",
    "    request_token: str = str(uuid.uuid4())\n",
    ") -> dict:\n",
    "    bedrock_client = boto_session.client(\n",
    "        service_name='bedrock',\n",
    "        region_name=boto_session.region_name,\n",
    "    )\n",
    "    try:\n",
    "        create_version_resp = bedrock_client.create_guardrail_version(\n",
    "            guardrailIdentifier=guardrail_id,\n",
    "            description=version_desc,\n",
    "            clientRequestToken=request_token\n",
    "        )\n",
    "        time.sleep(3)\n",
    "        return create_version_resp\n",
    "    except (ClientError, Exception) as e:\n",
    "        print('Error creating guardrail version: {e}'.format(e=e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb64f3-394c-405f-be58-921c52f0da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_version_resp = create_version_guardrail(\n",
    "    guardrail_id=guardrail_id,\n",
    "    version_desc='Version 1 - contextual grounding check only!',\n",
    "    boto_session=boto_session,\n",
    ")\n",
    "guardrail_version_id = create_version_resp.get('version', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c080b-fc2d-4fae-bb62-a115d5707599",
   "metadata": {},
   "source": [
    "We need to take note of **guardrail_id** and **guardrail_version_id**, these two parameters are required when using guardrail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664bc5b-6b48-4320-a05d-342d67863995",
   "metadata": {},
   "source": [
    "## Apply to RAG application\n",
    "---\n",
    "\n",
    "To illustrate the contextual grounding check, we will use `apply_guardrail` API and separate each process for us.\n",
    "\n",
    "<img src='./img/Bedrock-guardrails_how-it-works.png' alt=\"how it works apply_guardrails\" style='width: 800px;'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5da9e4-ec7a-4118-a816-01921e56e878",
   "metadata": {},
   "source": [
    "### Connect to existing vector database\n",
    "---\n",
    "\n",
    "Connect to our existing vector DB, and create the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68e62a-04c6-47d1-8d00-5bb6185cd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "import langchain_aws\n",
    "import langchain_core\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "import chromadb\n",
    "\n",
    "chroma_db_dir = './../_vector_db'\n",
    "chroma_collection_name = 'amazon-shareholder-letters'\n",
    "titan_model_id = 'amazon.titan-embed-text-v2:0'\n",
    "titan_embedding_fn = BedrockEmbeddings(\n",
    "    model_id=titan_model_id,\n",
    "    region_name=boto_session.region_name\n",
    ")\n",
    "persistent_client = chromadb.PersistentClient(\n",
    "    path=chroma_db_dir,\n",
    ")\n",
    "vector_store = Chroma(\n",
    "    collection_name=chroma_collection_name,\n",
    "    embedding_function=titan_embedding_fn,\n",
    "    client=persistent_client,\n",
    ")\n",
    "chroma_retriver = vector_store.as_retriever(\n",
    "    search_kwargs={'k': 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fb30f-d594-4a36-85b7-7639e236ba22",
   "metadata": {},
   "source": [
    "Here, let's ask sample question and query the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1dee4-77ef-431e-bf45-15d02e3423b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = '''\n",
    "Amazon discusses its investments and progress in various areas, such as Generative AI, logistics, and healthcare. \n",
    "How do these initiatives relate to the company's strategy of building \"primitives\" or foundational building blocks, \n",
    "and what potential customer experiences or business opportunities do they enable?'''\n",
    "\n",
    "sources_ref_list = chroma_retriver.invoke(sample_question)\n",
    "print(sources_ref_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47ca4c-3a70-43b8-9205-6a247b806d30",
   "metadata": {},
   "source": [
    "### Define apply guardrail\n",
    "---\n",
    "\n",
    "The `apply_guardrail` API is available for us to use independently. By providing three main components to the API, it can evaluate based on **grounding** and **relevance** metric.\n",
    "1. **Query**: this is the input prompt or user input\n",
    "2. **Context (or grounding source)**: this is the retrieved context or chunks from vector store.\n",
    "3. **Model response (or guard content)**: this is the output from LLM response, the `apply_guardrail` API will determine if the response (or content) should be guard or not.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note</b>: The contextual grounding check is applied at the <b>OUTPUT</b> after the LLM response, not <b>INPUT</b> for the LLM. Hence, we need to specify <i>SOURCE='OUTPUT'</i> in the API call.\n",
    "</div>\n",
    "\n",
    "For more information on the API call, please refer to [boto3 documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/apply_guardrail.html#BedrockRuntime.Client.apply_guardrail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f93545-1c5c-481d-935b-c534429b2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_bedrock_llm(\n",
    "    input_prompt: str,\n",
    "    context_str: str,\n",
    "    bedrock_model_id: str,\n",
    "    boto_session: boto3.session,\n",
    "):\n",
    "    bedrock_runtime_client = boto_session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=boto_session.region_name,\n",
    "    )\n",
    "    messages = [{\n",
    "        'role': 'user',\n",
    "        'content': [{\n",
    "            'text': input_prompt\n",
    "        }],\n",
    "    }]\n",
    "\n",
    "    llm_converse_resp = bedrock_runtime_client.converse(\n",
    "        modelId=bedrock_model_id,\n",
    "        system=[{\n",
    "            'text': '''You are a helpful assistant. Here is the context\n",
    "            <context>\n",
    "            {}\n",
    "            </context>\n",
    "            '''.format(context_str)\n",
    "        }],\n",
    "        messages=messages,\n",
    "        inferenceConfig={\n",
    "            'maxTokens': 2048,\n",
    "            'temperature': 0.1,\n",
    "            'topP': .85\n",
    "        }\n",
    "    )\n",
    "    return llm_converse_resp\n",
    "\n",
    "\n",
    "def contextual_grounding_check(\n",
    "    guardrail_id: str,\n",
    "    guardrail_version: str,\n",
    "    bedrock_model_id: str,\n",
    "    input_prompt: str,\n",
    "    context_lists: List[langchain_core.documents],\n",
    "    boto_session: boto3.session,\n",
    "    verbose: bool = False\n",
    "):\n",
    "    context_str = '\\n---\\n'.join([doc.page_content for doc in context_lists])\n",
    "    _llm_resp = call_bedrock_llm(\n",
    "        input_prompt=input_prompt,\n",
    "        context_str=context_str,\n",
    "        bedrock_model_id=bedrock_model_id,\n",
    "        boto_session=boto_session\n",
    "    )\n",
    "    _llm_output = _llm_resp.get('output', {}).get('message', {})\\\n",
    "        .get('content', [])[0].get('text', 'NA').strip()\n",
    "    _bedrock_tokens_usg = _llm_resp.get('usage', {})\n",
    "    if verbose:\n",
    "        print('Here is token usage by {}'.format(bedrock_model_id))\n",
    "        print(json.dumps(_bedrock_tokens_usg, indent=2))\n",
    "\n",
    "    _guardrail_content_block = []\n",
    "    for doc in context_lists:\n",
    "        _ground = {\n",
    "            'text': {\n",
    "                'text': doc.page_content,\n",
    "                'qualifiers': [\n",
    "                    'grounding_source'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        _guardrail_content_block.append(_ground)\n",
    "\n",
    "    if input_prompt:\n",
    "        _query = {\n",
    "            'text': {\n",
    "                'text': input_prompt,\n",
    "                'qualifiers': [\n",
    "                    'query'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        _guardrail_content_block.append(_query)\n",
    "\n",
    "    if _llm_output:\n",
    "        _guard_content = {\n",
    "            'text': {\n",
    "                'text': _llm_output,\n",
    "                'qualifiers': [\n",
    "                    'guard_content'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        _guardrail_content_block.append(_guard_content)\n",
    "\n",
    "    bedrock_runtime_client = boto_session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=boto_session.region_name,\n",
    "    )\n",
    "    guardrail_resp = bedrock_runtime_client.apply_guardrail(\n",
    "        guardrailIdentifier=guardrail_id,\n",
    "        guardrailVersion=guardrail_version,\n",
    "        source='OUTPUT',\n",
    "        content=_guardrail_content_block\n",
    "    )\n",
    "    return guardrail_resp, _llm_resp\n",
    "\n",
    "\n",
    "def hallucination_detection(\n",
    "    guardrail_response: dict,\n",
    "    verbose: bool = False\n",
    ") -> None:\n",
    "    _guardrail_usg = guardrail_response.get('usage', {})\n",
    "    _guardrail_action = guardrail_response.get('action', '')\n",
    "    _guardrail_out = guardrail_response.get('outputs', [])[0].get('text')\\\n",
    "        if len(guardrail_response.get('outputs', [])) > 0 else ''\n",
    "\n",
    "    if verbose:\n",
    "        print('guardrail usage:\\n{}'.format(json.dumps(_guardrail_usg, indent=2)))\n",
    "    _assessments = guardrail_response.get('assessments', [])\n",
    "    for assessment in _assessments:\n",
    "        if assessment.get('contextualGroundingPolicy'):\n",
    "            for filter_result in assessment['contextualGroundingPolicy'].get('filters', []):\n",
    "                if filter_result['type'] == 'RELEVANCE':\n",
    "                    relevance = filter_result.get('score', 0)\n",
    "                    relevance_threshold = filter_result.get('threshold', 0)\n",
    "                elif filter_result['type'] == 'GROUNDING':\n",
    "                    grounding = filter_result.get('score', 0)\n",
    "                    grounding_threshold = filter_result.get('threshold', 0)\n",
    "\n",
    "            if relevance < relevance_threshold or grounding < grounding_threshold:\n",
    "                return True, relevance, grounding, relevance_threshold, grounding_threshold, _guardrail_action, _guardrail_out\n",
    "    \n",
    "    return False, relevance, grounding, relevance_threshold, grounding_threshold, _guardrail_action, _guardrail_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b54dc-62f7-4dd7-864c-672724fbc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_1_70b_model_id = 'meta.llama3-1-70b-instruct-v1:0'\n",
    "\n",
    "guardrail_resp, llm_resp = contextual_grounding_check(\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version_id,\n",
    "    bedrock_model_id=llama3_1_70b_model_id,\n",
    "    input_prompt=sample_question,\n",
    "    context_lists=sources_ref_list,\n",
    "    boto_session=boto_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2afec0-b4b2-4686-b753-46d43df673e0",
   "metadata": {},
   "source": [
    "### Example execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f0616-080b-4d0e-a6d0-f1a54f10b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_df = pd.read_csv('../_eval_data/eval_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d861a8-0c35-42e9-aafd-c6da451abb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "for _idx, row in eval_df.iterrows():\n",
    "    _question = row['input'].split(':')[1].strip() if len(row['input'].split(':')) > 1 else row['input']\n",
    "    sources_ref_list = chroma_retriver.invoke(_question)\n",
    "    guardrail_resp, llm_resp = contextual_grounding_check(\n",
    "        guardrail_id=guardrail_id,\n",
    "        guardrail_version=guardrail_version_id,\n",
    "        bedrock_model_id=llama3_1_70b_model_id,\n",
    "        input_prompt=_question,\n",
    "        context_lists=sources_ref_list,\n",
    "        boto_session=boto_session\n",
    "    )\n",
    "    _ind, rel_scor, ground_scor, rel_thre, ground_thre, _guardrail_action, \\\n",
    "        _guardrail_output = hallucination_detection(guardrail_resp)\n",
    "    display(Markdown(\"<font color='red'>Question: {}</font>\".format(_question)))\n",
    "    display(Markdown(\"<font color='blue'>LLM Response: {}</font>\".format(\n",
    "        llm_resp.get('output').get('message').get('content')[0].get('text')\n",
    "    )))\n",
    "    display(Markdown(\"<font color='green'>Guardrail Action: {}</font>\".format(_guardrail_action)))\n",
    "    display(Markdown(\"<font color='green'>Guardrail output: {}</font>\".format(_guardrail_output)))\n",
    "    display(Markdown(\n",
    "        \"<font color='green'>Relevance score ({rel_scor}) vs. threshold({rel_thre})</font>\"\\\n",
    "        .format(rel_scor=rel_scor, rel_thre=rel_thre)))\n",
    "    display(Markdown(\n",
    "        \"<font color='green'>Grounding score ({ground_scor}) vs. threshold({ground_thre})</font>\"\\\n",
    "        .format(ground_scor=ground_scor, ground_thre=ground_thre)))\n",
    "    display(Markdown(' --- '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd259efb-33bc-4e09-b707-07cf3cc396d0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "---\n",
    "\n",
    "In this notebook, we have demonstrated how to use **Bedrock guardrail** as independent guardrail for hallucination detection. The **contextual grounding feature** proved effective in identifying potential hallucinations by comparing model responses against reference information. Relevance and grounding scores provided quantitative measures to assess the accuracy of model outputs.\n",
    "\n",
    "- **Grounding Threshold**: This represents the minimum confidence score for a model response to be considered grounded. Responses with scores below this threshold are deemed to contain information not supported by the reference source.\n",
    "\n",
    "- **Relevance Threshold**: This is the minimum confidence score for a model response to be considered relevant to the user's query. Responses scoring below this threshold are considered off-topic or not addressing the user's question adequately.\n",
    "\n",
    "The `ApplyGuardrail` API demonstrated the ability to decouple guardrails from specific foundation models, allowing for more versatile and model-agnostic content moderation. This decoupling enables the application of consistent safety measures across different AI models, including custom or third-party foundation models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
