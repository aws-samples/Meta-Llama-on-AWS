{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a972332",
   "metadata": {},
   "source": [
    "# NXDI Deployment Patterns for Llama models\n",
    "\n",
    "This notebook demonstrates how to set up an environment for **Amazon EC2 Trn1** (Trainium) instances using the [AWS Neuron SDK](https://awsdocs-neuron.readthedocs-hosted.com/) and shows a small Llama-based example of compiling and running inference on a distributed model.\n",
    "\n",
    "## Overview\n",
    "1. **Check/Install Dependencies** for AWS Neuron (tools, vLLM fork, etc.).\n",
    "2. **Optional**: Install additional utilities (InfluxDB, `llmperf` for performance benchmarking, etc.).\n",
    "3. **Download** an example model (or place your own model in the correct path).\n",
    "4. **Run** a short Python script that:\n",
    "   - Loads a Llama model from a Hugging Face path.\n",
    "   - Compiles it for Trainium.\n",
    "   - Runs a few prompts.\n",
    "   - Demonstrates on-device sampling.\n",
    "\n",
    "### Prerequisites\n",
    "- **Amazon EC2 Trn1.2xlarge instance** with AWS Neuron drivers and recommended PyTorch environment.\n",
    "- **A Python virtual environment** (e.g., `aws_neuronx_venv_pytorch_2_5_nxd_inference`) is highly recommended.\n",
    "- **Neuron tools** (e.g., `neuron-ls`, `neuron-top`, `neuron-profile`) installed, along with the necessary apt repo definitions. (We show how to install these if needed.)\n",
    "\n",
    "For more details, see [Install Guide for AWS Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-install-guide/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f6786-8ed7-4036-9070-3d6669fcb92b",
   "metadata": {},
   "source": [
    "## Install and Set up Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652fc5a",
   "metadata": {},
   "source": [
    "### 1. Validate / Activate Python Environment\n",
    "\n",
    "Inside a Jupyter notebook, using `source myenv/bin/activate` directly will not persist the environment in subsequent cells, because source runs in a subshell. Please run the following in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa75aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python environment check:\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/bin/python\n",
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# (Optional) Uncomment or modify the following line to activate a custom environment.\n",
    "source /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/bin/activate\n",
    "\n",
    "echo 'Python environment check:'\n",
    "which python\n",
    "python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e657dec1-61fc-4cf7-bec8-48ecd1213c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "torch==2.5.1\n",
    "transformers==4.45.2\n",
    "huggingface_hub\n",
    "git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4844ef-f16c-4bda-bb05-62ca83a7d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33295cb",
   "metadata": {},
   "source": [
    "### 2. Install AWS Neuron Tools (If Needed)\n",
    "\n",
    "This cell installs the Neuron packages for profiling and other tooling. If already installed, the script checks and skips. For more information, see [Installing Neuron Tools](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-install-guide/install-aws-neuronx-tools.html).\n",
    "\n",
    "> **Note**: If you have your apt sources already configured and have installed the Neuron packages, you can skip this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743a0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ dpkg -s aws-neuronx-tools\n",
      "+ echo 'aws-neuronx-tools is already installed. Skipping.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-neuronx-tools is already installed. Skipping.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euxo pipefail\n",
    "\n",
    "# Check if aws-neuronx-tools is installed\n",
    "if dpkg -s aws-neuronx-tools > /dev/null 2>&1; then\n",
    "    echo \"aws-neuronx-tools is already installed. Skipping.\"\n",
    "else\n",
    "    echo \"Installing aws-neuronx-tools...\"\n",
    "    . /etc/os-release\n",
    "\n",
    "    sudo tee /etc/apt/sources.list.d/neuron.list > /dev/null <<EOF\n",
    "deb https://apt.repos.neuron.amazonaws.com ${VERSION_CODENAME} main\n",
    "EOF\n",
    "\n",
    "    wget -qO - https://apt.repos.neuron.amazonaws.com/GPG-PUB-KEY-AMAZON-AWS-NEURON.PUB | sudo apt-key add -\n",
    "    sudo apt-get update -y\n",
    "    sudo apt-get install -y aws-neuronx-runtime-lib aws-neuronx-dkms aws-neuronx-tools\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea6ed2",
   "metadata": {},
   "source": [
    "### 3. (Optional) Install Neuron vLLM Fork\n",
    "\n",
    "If you would like to serve your model via [vLLM](https://vllm.readthedocs.io/en/latest/) specialized for Neuron-based inference, you can install AWS Neuron's vLLM fork. NxD Inference integrates into vLLM by extending the model execution components responsible for loading and invoking models used in vLLM’s LLMEngine (see [link](https://docs.vllm.ai/en/latest/design/arch_overview.html#llm-engine) for more details on vLLM architecture). This means input processing, scheduling and output processing follow the default vLLM behavior.\n",
    "\n",
    "You enable the Neuron integration in vLLM by setting the device type used by `vLLM` to `neuron`.\n",
    "\n",
    "Currently, we support continuous batching and streaming generation in the NxD Inference vLLM integration. We are working with the vLLM community to enable support for other vLLM features like PagedAttention and Chunked Prefill on Neuron instances through NxD Inference in upcoming releases.\n",
    "\n",
    "\n",
    "Skip this step if you do not need the vLLM server. Cloning and installing vLLM takes 8-10 minutes to complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9c80f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ '[' -d /home/ubuntu/upstreaming-to-vllm ']'\n",
      "+ echo 'Cloning and installing AWS Neuron vLLM fork...'\n",
      "+ cd /home/ubuntu/\n",
      "+ git clone -b v0.6.x-neuron https://github.com/aws-neuron/upstreaming-to-vllm.git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning and installing AWS Neuron vLLM fork...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'upstreaming-to-vllm'...\n",
      "+ cd upstreaming-to-vllm\n",
      "+ pip install -r requirements-neuron.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Ignoring fastapi: markers 'python_version < \"3.9\"' don't match your environment\n",
      "Ignoring six: markers 'python_version > \"3.11\"' don't match your environment\n",
      "Ignoring setuptools: markers 'python_version > \"3.11\"' don't match your environment\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 1)) (6.1.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 3)) (1.25.2)\n",
      "Requirement already satisfied: requests in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 5)) (4.67.1)\n",
      "Collecting py-cpuinfo (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 6))\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.45.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 7)) (4.45.2)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 8)) (0.20.3)\n",
      "Requirement already satisfied: protobuf in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 9)) (5.29.3)\n",
      "Requirement already satisfied: fastapi>=0.114.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 11)) (0.115.6)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (3.11.11)\n",
      "Collecting openai>=1.40.0 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13))\n",
      "  Downloading openai-1.65.4-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 15)) (2.10.5)\n",
      "Requirement already satisfied: pillow in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 16)) (11.1.0)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 17)) (0.21.1)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 18))\n",
      "  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 19))\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer==0.10.6 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 20))\n",
      "  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting outlines<0.1,>=0.0.43 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 22)) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 23)) (3.16.1)\n",
      "Collecting partial-json-parser (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 24))\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 25)) (26.2.0)\n",
      "Collecting msgspec (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 26))\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf==0.10.0 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 27))\n",
      "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: importlib_metadata in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 28)) (8.5.0)\n",
      "Collecting mistral_common>=1.4.3 (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 29))\n",
      "  Downloading mistral_common-1.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 30)) (6.0.2)\n",
      "Collecting einops (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 33))\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: torch-neuronx>=2.1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r requirements-neuron.txt (line 4)) (2.5.1.2.4.0)\n",
      "Requirement already satisfied: neuronx-cc~=2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r requirements-neuron.txt (line 5)) (2.16.372.0+4a9b2326)\n",
      "Requirement already satisfied: torchvision in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from -r requirements-neuron.txt (line 6)) (0.20.1)\n",
      "Collecting uvicorn[standard] (from -r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14))\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 20))\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from lm-format-enforcer==0.10.6->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 20)) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 4)) (2024.12.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers>=4.45.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 7)) (0.29.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers>=4.45.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers>=4.45.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 7)) (0.5.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from fastapi>=0.114.1->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 11)) (0.41.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 12)) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13)) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13)) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13))\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14)) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14)) (0.14.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14))\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14))\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14))\n",
      "  Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 14))\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.9->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 15)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.9->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 15)) (2.27.2)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (3.1.5)\n",
      "Collecting lark (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nest-asyncio in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (3.1.1)\n",
      "Collecting diskcache (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numba in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (0.60.0)\n",
      "Requirement already satisfied: referencing in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (0.35.1)\n",
      "Requirement already satisfied: jsonschema in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (4.23.0)\n",
      "Collecting datasets (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pycountry (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyairports (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from importlib_metadata->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 28)) (3.21.0)\n",
      "Requirement already satisfied: torch==2.5.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.5.1)\n",
      "Requirement already satisfied: torch-xla==2.5.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.5.1)\n",
      "Requirement already satisfied: libneuronxla<2.2,>=2.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.1.714.0)\n",
      "Requirement already satisfied: setuptools<=69.5.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (69.5.1)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.8.8)\n",
      "Requirement already satisfied: fsspec in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-xla==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (1.11.2)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: islpy~=2023.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (2023.2.5)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13)) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.40.0->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 13)) (1.0.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (0.22.3)\n",
      "Requirement already satisfied: boto3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (1.35.98)\n",
      "Requirement already satisfied: botocore in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (1.35.98)\n",
      "Requirement already satisfied: lockfile>=0.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from python-daemon>=2.2.4->neuronx-cc~=2.0->-r requirements-neuron.txt (line 5)) (0.12.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (2.2.3)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting datasets (from outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.5.*->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4))\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jinja2->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (3.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from numba->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (0.43.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from boto3->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from boto3->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (0.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from botocore->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (2.9.0.post0)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21))\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->-r /home/ubuntu/upstreaming-to-vllm/requirements-common.txt (line 21)) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->-r requirements-neuron.txt (line 4)) (1.17.0)\n",
      "Downloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
      "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading openai-1.65.4-py3-none-any.whl (473 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m158.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: pyairports, py-cpuinfo, xxhash, websockets, uvloop, uvicorn, python-dotenv, pycountry, pyarrow-hotfix, pyarrow, partial-json-parser, msgspec, lark, jiter, interegular, httptools, gguf, fsspec, einops, distro, diskcache, dill, watchfiles, tiktoken, multiprocess, prometheus-fastapi-instrumentator, openai, lm-format-enforcer, mistral_common, datasets, outlines\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed datasets-2.19.1 dill-0.3.8 diskcache-5.6.3 distro-1.9.0 einops-0.8.1 fsspec-2024.3.1 gguf-0.10.0 httptools-0.6.4 interegular-0.3.3 jiter-0.8.2 lark-1.2.2 lm-format-enforcer-0.10.6 mistral_common-1.5.3 msgspec-0.19.0 multiprocess-0.70.16 openai-1.65.4 outlines-0.0.46 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.0.2 py-cpuinfo-9.0.0 pyairports-2.1.1 pyarrow-19.0.1 pyarrow-hotfix-0.6 pycountry-24.6.1 python-dotenv-1.0.1 tiktoken-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 websockets-15.0.1 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "+ VLLM_TARGET_DEVICE=neuron\n",
      "+ pip install -e .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Obtaining file:///home/ubuntu/upstreaming-to-vllm\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (6.1.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (1.25.2)\n",
      "Requirement already satisfied: requests in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (4.67.1)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.45.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (4.45.2)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.20.3)\n",
      "Requirement already satisfied: protobuf in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (5.29.3)\n",
      "Requirement already satisfied: fastapi>=0.114.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.115.6)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (3.11.11)\n",
      "Requirement already satisfied: openai>=1.40.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (1.65.4)\n",
      "Requirement already satisfied: uvicorn[standard] in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (2.10.5)\n",
      "Requirement already satisfied: pillow in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (11.1.0)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.21.1)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (7.0.2)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer==0.10.6 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.10.6)\n",
      "Requirement already satisfied: outlines<0.1,>=0.0.43 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.0.46)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (3.16.1)\n",
      "Requirement already satisfied: partial-json-parser in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (26.2.0)\n",
      "Requirement already satisfied: msgspec in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (8.5.0)\n",
      "Requirement already satisfied: mistral_common>=1.4.3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (1.5.3)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (6.0.2)\n",
      "Requirement already satisfied: einops in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.8.1)\n",
      "Requirement already satisfied: torch-neuronx>=2.1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (2.5.1.2.4.0)\n",
      "Requirement already satisfied: neuronx-cc~=2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (2.16.372.0+4a9b2326)\n",
      "Requirement already satisfied: torchvision in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from vllm==0.1.dev2830+g22c56ee.neuron216) (0.20.1)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from lm-format-enforcer==0.10.6->vllm==0.1.dev2830+g22c56ee.neuron216) (0.3.3)\n",
      "Requirement already satisfied: packaging in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from lm-format-enforcer==0.10.6->vllm==0.1.dev2830+g22c56ee.neuron216) (24.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from fastapi>=0.114.1->vllm==0.1.dev2830+g22c56ee.neuron216) (0.41.3)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from mistral_common>=1.4.3->vllm==0.1.dev2830+g22c56ee.neuron216) (4.23.0)\n",
      "Requirement already satisfied: networkx~=2.6 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (2.8.8)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (1.11.2)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (3.1.2)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.2.0)\n",
      "Requirement already satisfied: islpy~=2023.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (2023.2.5)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (2.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (1.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (3.1.5)\n",
      "Requirement already satisfied: lark in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (1.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (3.1.1)\n",
      "Requirement already satisfied: diskcache in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (5.6.3)\n",
      "Requirement already satisfied: numba in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (0.60.0)\n",
      "Requirement already satisfied: referencing in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (0.35.1)\n",
      "Requirement already satisfied: datasets in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (2.19.1)\n",
      "Requirement already satisfied: pycountry in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (2.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.9->vllm==0.1.dev2830+g22c56ee.neuron216) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.9->vllm==0.1.dev2830+g22c56ee.neuron216) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->vllm==0.1.dev2830+g22c56ee.neuron216) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->vllm==0.1.dev2830+g22c56ee.neuron216) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->vllm==0.1.dev2830+g22c56ee.neuron216) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->vllm==0.1.dev2830+g22c56ee.neuron216) (2024.12.14)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from tiktoken>=0.6.0->vllm==0.1.dev2830+g22c56ee.neuron216) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm==0.1.dev2830+g22c56ee.neuron216) (0.29.2)\n",
      "Requirement already satisfied: torch==2.5.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2.5.1)\n",
      "Requirement already satisfied: torch-xla==2.5.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2.5.1)\n",
      "Requirement already satisfied: libneuronxla<2.2,>=2.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2.1.714.0)\n",
      "Requirement already satisfied: setuptools<=69.5.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (69.5.1)\n",
      "Requirement already satisfied: fsspec in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (1.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from torch-xla==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.*->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers>=4.45.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.1.dev2830+g22c56ee.neuron216) (1.18.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from importlib_metadata->vllm==0.1.dev2830+g22c56ee.neuron216) (3.21.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.1.dev2830+g22c56ee.neuron216) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm==0.1.dev2830+g22c56ee.neuron216) (1.0.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.4.3->vllm==0.1.dev2830+g22c56ee.neuron216) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.4.3->vllm==0.1.dev2830+g22c56ee.neuron216) (0.22.3)\n",
      "Requirement already satisfied: boto3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (1.35.98)\n",
      "Requirement already satisfied: botocore in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (1.35.98)\n",
      "Requirement already satisfied: lockfile>=0.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from python-daemon>=2.2.4->neuronx-cc~=2.0->vllm==0.1.dev2830+g22c56ee.neuron216) (0.12.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (0.70.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jinja2->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (3.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (0.43.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from boto3->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from boto3->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (0.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from botocore->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.1.dev2830+g22c56ee.neuron216) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->libneuronxla<2.2,>=2.1->torch-neuronx>=2.1.2->vllm==0.1.dev2830+g22c56ee.neuron216) (1.17.0)\n",
      "Building wheels for collected packages: vllm\n",
      "  Building editable for vllm (pyproject.toml): started\n",
      "  Building editable for vllm (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for vllm: filename=vllm-0.1.dev2830+g22c56ee.neuron216-0.editable-py3-none-any.whl size=11425 sha256=a94a5945e453c76ee17dd975d31565e0eaa3d810f2d07a155fe135f0d75190a9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-am7vvlkq/wheels/0e/87/28/2fcad33f0d362bdbafff51fcffec3242a5d9bcabf04df9b94f\n",
      "Successfully built vllm\n",
      "Installing collected packages: vllm\n",
      "Successfully installed vllm-0.1.dev2830+g22c56ee.neuron216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euxo pipefail\n",
    "\n",
    "if [ -d \"/home/ubuntu/upstreaming-to-vllm\" ]; then\n",
    "    echo \"Neuron vLLM fork already cloned. Skipping.\"\n",
    "else\n",
    "    echo \"Cloning and installing AWS Neuron vLLM fork...\"\n",
    "    cd /home/ubuntu/\n",
    "    git clone -b v0.6.x-neuron https://github.com/aws-neuron/upstreaming-to-vllm.git\n",
    "    cd upstreaming-to-vllm\n",
    "    pip install -r requirements-neuron.txt\n",
    "\n",
    "    # Install in editable mode with device set to neuron\n",
    "    VLLM_TARGET_DEVICE=\"neuron\" pip install -e .\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb91034",
   "metadata": {},
   "source": [
    "### 4. (Optional) Install llmperf\n",
    "\n",
    "If you'd like to run benchmarks or load tests, you can install [llmperf](https://github.com/ray-project/llmperf). Skip if not needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba57d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing llmperf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'llmperf'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Obtaining file:///home/ubuntu/llmperf\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pydantic<2.5 (from LLMPerf==0.1.0)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "Collecting ray (from LLMPerf==0.1.0)\n",
      "  Downloading ray-2.43.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pytest>=6.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from LLMPerf==0.1.0) (8.3.4)\n",
      "Requirement already satisfied: seaborn>=0.11 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from LLMPerf==0.1.0) (0.13.2)\n",
      "Requirement already satisfied: awscli>=1.22 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from LLMPerf==0.1.0) (1.36.39)\n",
      "Collecting typer>=0.4 (from LLMPerf==0.1.0)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting litellm>=0.1.738 (from LLMPerf==0.1.0)\n",
      "  Downloading litellm-1.63.2-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting num2words (from LLMPerf==0.1.0)\n",
      "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from LLMPerf==0.1.0) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from LLMPerf==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: boto3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from LLMPerf==0.1.0) (1.35.98)\n",
      "Collecting google-cloud-aiplatform (from LLMPerf==0.1.0)\n",
      "  Downloading google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: botocore==1.35.98 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from awscli>=1.22->LLMPerf==0.1.0) (1.35.98)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from awscli>=1.22->LLMPerf==0.1.0) (0.16)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from awscli>=1.22->LLMPerf==0.1.0) (0.10.4)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from awscli>=1.22->LLMPerf==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from awscli>=1.22->LLMPerf==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from awscli>=1.22->LLMPerf==0.1.0) (4.7.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from botocore==1.35.98->awscli>=1.22->LLMPerf==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from botocore==1.35.98->awscli>=1.22->LLMPerf==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from botocore==1.35.98->awscli>=1.22->LLMPerf==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (3.11.11)\n",
      "Requirement already satisfied: click in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (8.1.8)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (3.1.5)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.61.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (1.65.4)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from litellm>=0.1.738->LLMPerf==0.1.0) (0.20.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pydantic<2.5->LLMPerf==0.1.0) (0.7.0)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<2.5->LLMPerf==0.1.0)\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pydantic<2.5->LLMPerf==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pytest>=6.0->LLMPerf==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: iniconfig in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pytest>=6.0->LLMPerf==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pytest>=6.0->LLMPerf==0.1.0) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pytest>=6.0->LLMPerf==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pytest>=6.0->LLMPerf==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from seaborn>=0.11->LLMPerf==0.1.0) (1.25.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from seaborn>=0.11->LLMPerf==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from seaborn>=0.11->LLMPerf==0.1.0) (3.10.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.4->LLMPerf==0.1.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from typer>=0.4->LLMPerf==0.1.0) (13.9.4)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from google-cloud-aiplatform->LLMPerf==0.1.0) (5.29.3)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_cloud_resource_manager-1.14.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading shapely-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docopt>=0.6.2 (from num2words->LLMPerf==0.1.0)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from ray->LLMPerf==0.1.0) (3.16.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray->LLMPerf==0.1.0)\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: aiosignal in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from ray->LLMPerf==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from ray->LLMPerf==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: requests in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from ray->LLMPerf==0.1.0) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers->LLMPerf==0.1.0) (0.29.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers->LLMPerf==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from transformers->LLMPerf==0.1.0) (0.5.2)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading googleapis_common_protos-1.69.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->LLMPerf==0.1.0) (0.4.1)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.14.0 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading grpc_google_iam_v1-0.14.1-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform->LLMPerf==0.1.0)\n",
      "  Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpx>=0.23.0->litellm>=0.1.738->LLMPerf==0.1.0) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpx>=0.23.0->litellm>=0.1.738->LLMPerf==0.1.0) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpx>=0.23.0->litellm>=0.1.738->LLMPerf==0.1.0) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpx>=0.23.0->litellm>=0.1.738->LLMPerf==0.1.0) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=0.1.738->LLMPerf==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->LLMPerf==0.1.0) (2024.3.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm>=0.1.738->LLMPerf==0.1.0) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=0.1.738->LLMPerf==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=0.1.738->LLMPerf==0.1.0) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=0.1.738->LLMPerf==0.1.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=0.1.738->LLMPerf==0.1.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=0.1.738->LLMPerf==0.1.0) (0.22.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11->LLMPerf==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11->LLMPerf==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11->LLMPerf==0.1.0) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11->LLMPerf==0.1.0) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11->LLMPerf==0.1.0) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11->LLMPerf==0.1.0) (3.2.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.61.0->litellm>=0.1.738->LLMPerf==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.61.0->litellm>=0.1.738->LLMPerf==0.1.0) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from openai>=1.61.0->litellm>=0.1.738->LLMPerf==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pandas>=1.2->seaborn>=0.11->LLMPerf==0.1.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from pandas>=1.2->seaborn>=0.11->LLMPerf==0.1.0) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from requests->ray->LLMPerf==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.4->LLMPerf==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.4->LLMPerf==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from rsa<4.8,>=3.1.2->awscli>=1.22->LLMPerf==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->litellm>=0.1.738->LLMPerf==0.1.0) (2.4.4)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->litellm>=0.1.738->LLMPerf==0.1.0) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->litellm>=0.1.738->LLMPerf==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->litellm>=0.1.738->LLMPerf==0.1.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from aiohttp->litellm>=0.1.738->LLMPerf==0.1.0) (1.18.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.4->LLMPerf==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.35.98->awscli>=1.22->LLMPerf==0.1.0) (1.17.0)\n",
      "Downloading litellm-1.63.2-py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m161.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m168.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "Downloading ray-2.43.0-cp310-cp310-manylinux2014_x86_64.whl (67.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 MB\u001b[0m \u001b[31m146.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl (247 kB)\n",
      "Downloading google_cloud_resource_manager-1.14.1-py2.py3-none-any.whl (392 kB)\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Downloading shapely-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m188.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Downloading googleapis_common_protos-1.69.0-py2.py3-none-any.whl (169 kB)\n",
      "Downloading grpc_google_iam_v1-0.14.1-py2.py3-none-any.whl (19 kB)\n",
      "Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m155.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: LLMPerf, docopt\n",
      "  Building editable for LLMPerf (pyproject.toml): started\n",
      "  Building editable for LLMPerf (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for LLMPerf: filename=llmperf-0.1.0-0.editable-py3-none-any.whl size=6120 sha256=e5601f44c5f0c2ab84e65e716bf40ffbf2bfb8c81477601945e9ec8bf971ff45\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cbkkd151/wheels/2a/ac/da/c25a40da1c51d262cbf0dde516656715f3f282e2eaad8f18c8\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=b910e16d6833182e57794a9ecb6dfc2620b924eb0374cb40bf0d09126f5afdd8\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built LLMPerf docopt\n",
      "Installing collected packages: docopt, shellingham, shapely, pydantic-core, proto-plus, num2words, msgpack, grpcio, googleapis-common-protos, google-crc32c, docstring-parser, cachetools, pydantic, grpcio-status, google-resumable-media, google-auth, typer, grpc-google-iam-v1, google-api-core, ray, litellm, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform, LLMPerf\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.5\n",
      "    Uninstalling pydantic-2.10.5:\n",
      "      Successfully uninstalled pydantic-2.10.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mistral-common 1.5.3 requires pydantic<3.0,>=2.7, but you have pydantic 2.4.2 which is incompatible.\n",
      "vllm 0.1.dev2830+g22c56ee.neuron216 requires pydantic>=2.9, but you have pydantic 2.4.2 which is incompatible.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed LLMPerf-0.1.0 cachetools-5.5.2 docopt-0.6.2 docstring-parser-0.16 google-api-core-2.24.1 google-auth-2.38.0 google-cloud-aiplatform-1.83.0 google-cloud-bigquery-3.30.0 google-cloud-core-2.4.2 google-cloud-resource-manager-1.14.1 google-cloud-storage-2.19.0 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.69.0 grpc-google-iam-v1-0.14.1 grpcio-1.70.0 grpcio-status-1.70.0 litellm-1.63.2 msgpack-1.1.0 num2words-0.5.14 proto-plus-1.26.0 pydantic-2.4.2 pydantic-core-2.10.1 ray-2.43.0 shapely-2.0.7 shellingham-1.5.4 typer-0.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if pip show llmperf > /dev/null 2>&1; then\n",
    "    echo \"llmperf is already installed. Skipping.\"\n",
    "else\n",
    "    echo \"Installing llmperf...\"\n",
    "    cd /home/ubuntu/\n",
    "    git clone https://github.com/ray-project/llmperf.git > /dev/null 2>&1\n",
    "    cd llmperf\n",
    "    pip install -e .\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec41f28",
   "metadata": {},
   "source": [
    "### 5. (Optional) Install InfluxDB 2.x\n",
    "\n",
    "Install InfluxDB if using the Neuron Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32cb9b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "influxdata-archive_compat.key: OK\n",
      "deb [signed-by=/etc/apt/trusted.gpg.d/influxdata-archive_compat.gpg] https://repos.influxdata.com/debian stable main\n",
      "Hit:1 http://us-west-2.ec2.archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:2 http://us-west-2.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:3 http://us-west-2.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:4 https://repos.influxdata.com/debian stable InRelease [6907 B]\n",
      "Hit:5 https://download.docker.com/linux/ubuntu jammy InRelease\n",
      "Get:6 https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64  InRelease [1484 B]\n",
      "Hit:7 https://nvidia.github.io/nvidia-container-runtime/stable/ubuntu18.04/amd64  InRelease\n",
      "Hit:8 https://apt.repos.neuron.amazonaws.com jammy InRelease\n",
      "Hit:9 https://nvidia.github.io/nvidia-docker/ubuntu18.04/amd64  InRelease\n",
      "Get:10 https://repos.influxdata.com/debian stable/main amd64 Packages [14.6 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Fetched 407 kB in 1s (519 kB/s)\n",
      "Reading package lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://nvidia.github.io/nvidia-container-runtime/stable/ubuntu18.04/amd64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://apt.repos.neuron.amazonaws.com/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://nvidia.github.io/nvidia-docker/ubuntu18.04/amd64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  influxdb2 influxdb2-cli\n",
      "0 upgraded, 2 newly installed, 0 to remove and 29 not upgraded.\n",
      "Need to get 61.3 MB of archives.\n",
      "After this operation, 147 MB of additional disk space will be used.\n",
      "Get:1 https://repos.influxdata.com/debian stable/main amd64 influxdb2 amd64 2.7.11-1 [49.6 MB]\n",
      "Get:2 https://repos.influxdata.com/debian stable/main amd64 influxdb2-cli amd64 2.7.5-1 [11.7 MB]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dpkg-preconfigure: unable to re-open stdin: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 61.3 MB in 0s (123 MB/s)\n",
      "Selecting previously unselected package influxdb2.\n",
      "(Reading database ... 124863 files and directories currently installed.)\n",
      "Preparing to unpack .../influxdb2_2.7.11-1_amd64.deb ...\n",
      "Unpacking influxdb2 (2.7.11-1) ...\n",
      "Selecting previously unselected package influxdb2-cli.\n",
      "Preparing to unpack .../influxdb2-cli_2.7.5-1_amd64.deb ...\n",
      "Unpacking influxdb2-cli (2.7.5-1) ...\n",
      "Setting up influxdb2 (2.7.11-1) ...\n",
      "Created symlink /etc/systemd/system/influxd.service → /lib/systemd/system/influxdb.service.\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/influxdb.service → /lib/systemd/system/influxdb.service.\n",
      "Setting up influxdb2-cli (2.7.5-1) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n",
      "Deep recursion on subroutine \"NeedRestart::Interp::Python::_scan\" at /usr/share/perl5/NeedRestart/Interp/Python.pm line 78.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running kernel seems to be up-to-date.\n",
      "\n",
      "Services to be restarted:\n",
      " systemctl restart acpid.service\n",
      " systemctl restart chrony.service\n",
      " systemctl restart containerd.service\n",
      " systemctl restart cron.service\n",
      " systemctl restart irqbalance.service\n",
      " systemctl restart multipathd.service\n",
      " systemctl restart packagekit.service\n",
      " systemctl restart polkit.service\n",
      " systemctl restart rpcbind.service\n",
      " systemctl restart rsyslog.service\n",
      " systemctl restart serial-getty@ttyS0.service\n",
      " systemctl restart ssh.service\n",
      " systemctl restart systemd-journald.service\n",
      " /etc/needrestart/restart.d/systemd-manager\n",
      " systemctl restart systemd-networkd.service\n",
      " systemctl restart systemd-resolved.service\n",
      " systemctl restart systemd-udevd.service\n",
      "\n",
      "Service restarts being deferred:\n",
      " /etc/needrestart/restart.d/dbus.service\n",
      " systemctl restart docker.service\n",
      " systemctl restart getty@tty1.service\n",
      " systemctl restart networkd-dispatcher.service\n",
      " systemctl restart systemd-logind.service\n",
      " systemctl restart unattended-upgrades.service\n",
      " systemctl restart user@1000.service\n",
      "\n",
      "No containers need to be restarted.\n",
      "\n",
      "No user sessions are running outdated binaries.\n",
      "\n",
      "No VM guests are running outdated hypervisor (qemu) binaries on this host.\n",
      "User\tOrganization\tBucket\n",
      "admin\tyourorg\t\tyourbucket\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if dpkg -s influxdb2 > /dev/null 2>&1; then\n",
    "    echo \"InfluxDB2 is already installed, skipping.\"\n",
    "    if systemctl is-active --quiet influxdb; then\n",
    "        echo \"InfluxDB is already running.\"\n",
    "    else\n",
    "        sudo systemctl start influxdb\n",
    "        echo \"Setting up InfluxDB ...\"\n",
    "        # influx setup\n",
    "    fi\n",
    "else\n",
    "    # Install InfluxDB\n",
    "    wget -q https://repos.influxdata.com/influxdata-archive_compat.key\n",
    "    echo '393e8779c89ac8d958f81f942f9ad7fb82a25e133faddaf92e15b16e6ac9ce4c influxdata-archive_compat.key' | sha256sum -c && \\\n",
    "      cat influxdata-archive_compat.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/influxdata-archive_compat.gpg > /dev/null\n",
    "    echo 'deb [signed-by=/etc/apt/trusted.gpg.d/influxdata-archive_compat.gpg] https://repos.influxdata.com/debian stable main' | sudo tee /etc/apt/sources.list.d/influxdata.list\n",
    "    \n",
    "    sudo apt-get update && sudo apt-get install influxdb2 influxdb2-cli -y\n",
    "    sudo systemctl start influxdb\n",
    "    \n",
    "    # Run non-interactive influx setup with all necessary flags\n",
    "    # replace the following flags below with the necessary credentials\n",
    "    influx setup \\\n",
    "      --username admin \\\n",
    "      --password testpassowrd \\\n",
    "      --org yourorg \\\n",
    "      --bucket yourbucket \\\n",
    "      --token yoursupersecrettoken \\\n",
    "      --force\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b95852-a69f-4c6a-bdcd-915bdaf6d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libneuronxla                      2.1.714.0\n",
      "neuronx-cc                        2.16.372.0+4a9b2326\n",
      "neuronx-distributed               0.10.1\n",
      "neuronx-distributed-inference     0.1.1\n",
      "torch-neuronx                     2.5.1.2.4.0\n",
      "vllm                              0.1.dev2830+g22c56ee.neuron216 /home/ubuntu/upstreaming-to-vllm\n"
     ]
    }
   ],
   "source": [
    "!pip list| grep neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1970fc",
   "metadata": {},
   "source": [
    "## 6. Download or Provide Your Model\n",
    "\n",
    "Below is a template for downloading a model if you have a pre-signed URL. You can skip or adjust if you already have a local model.\n",
    "\n",
    "For more information on model checkpoint usage, see the [Neuron Inference with Hugging Face-based models](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/pytorch/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff01a8-94f7-4d10-bdf7-71229ec19cb9",
   "metadata": {},
   "source": [
    "You will need to log in to huggingface from the commandline.  You will need your token from https://huggingface.co/settings/tokens Paste it to replace the MY_HUGGINGFACE_TOKEN_HERE text below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7186278-332e-4e07-87b8-fdf1a30f3335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5080e7c538c48a8ae0d9edecb219ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!git config --global credential.helper store\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b9863-fc7e-4752-ae55-8d4b89312d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run following in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b0c21-6486-4f04-9d46-cbf645161083",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get update\n",
    "sudo apt-get install git-lfs\n",
    "git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2bdbf-1af1-4a20-a255-7642b8da704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check git lfs is installed on path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c72f91e7-89ee-4b90-99f4-91239197ed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!git lfs version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125ce0d9-8438-4f85-808e-0dbfc91d0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git LFS initialized.\n",
      "Cloning into 'Llama-3.2-1B'...\n",
      "remote: Enumerating objects: 76, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 76 (delta 33), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (76/76), 2.27 MiB | 3.26 MiB/s, done.\n",
      "Filtering content: 100% (3/3), 4.60 GiB | 94.51 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/meta-llama/Llama-3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2784351-edb6-4528-95ec-5f2a14afebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if full model was downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98ed86a2-e71b-4a78-bcb9-30a20a67a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.3G\t/home/ubuntu/Llama-3.2-1B/\n"
     ]
    }
   ],
   "source": [
    "!du -sh /home/ubuntu/Llama-3.2-1B/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02214b8a",
   "metadata": {},
   "source": [
    "## 7. Llama Python Generation Demo\n",
    "\n",
    "Below is a Python script that uses **Amazon Neuron** libraries to:\n",
    "- Import libraries including `torch`, `transformers`, and specialized Neuron classes.\n",
    "- Load a **Llama** model from a local Hugging Face directory.\n",
    "- Compile and store the traced model to a specified location.\n",
    "- Reload from the compiled artifacts.\n",
    "- Generate text based on a couple of example prompts.\n",
    "\n",
    "This process illustrates how [NeuronX Distributed Inference](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/pytorch/torch-neuronx-distributed-inference/index.html) compiles a model for **TP Degree** = 32 or 2 or any other (depending on your system resources), and allows sampling within hardware constraints.\n",
    "\n",
    "> **Important**: Ensure the `tp_degree` in `NeuronConfig` matches the number of Neuron Cores (or a multiple) available, or that you have enough parallel resources to accommodate your chosen partitioning.\n",
    "\n",
    "Once you run this code cell, it will:\n",
    "- Set a random seed.\n",
    "- Compile the Llama model and store the compiled artifacts in `traced_model_path`.\n",
    "- Reload the compiled checkpoint.\n",
    "- Generate text from the prompts.\n",
    "\n",
    "If you would like to modify the prompts, simply edit them in the `prompts` list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a7a179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Generating HLOs for the following models: ['context_encoding_model', 'token_generation_model']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling and saving model...\n",
      "[2025-03-06 19:03:24.043: I neuronx_distributed/parallel_layers/parallel_state.py:518] > initializing tensor model parallel with size 2\n",
      "[2025-03-06 19:03:24.043: I neuronx_distributed/parallel_layers/parallel_state.py:519] > initializing pipeline model parallel with size 1\n",
      "[2025-03-06 19:03:24.044: I neuronx_distributed/parallel_layers/parallel_state.py:520] > initializing data parallel with size 1\n",
      "[2025-03-06 19:03:24.044: I neuronx_distributed/parallel_layers/parallel_state.py:521] > initializing world size to 2\n",
      "[2025-03-06 19:03:24.046: I neuronx_distributed/parallel_layers/parallel_state.py:307] [rank_0_pp-1_tp-1_dp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7f17f4b24d30>, 'Ascending Ring PG Group')>\n",
      "[2025-03-06 19:03:24.047: I neuronx_distributed/parallel_layers/parallel_state.py:557] [rank_0_pp-1_tp-1_dp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-03-06 19:03:24.047: I neuronx_distributed/parallel_layers/parallel_state.py:558] [rank_0_pp-1_tp-1_dp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-03-06 19:03:24.048: I neuronx_distributed/parallel_layers/parallel_state.py:559] [rank_0_pp-1_tp-1_dp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-03-06 19:03:24.048: I neuronx_distributed/parallel_layers/parallel_state.py:560] [rank_0_pp-1_tp-1_dp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-03-06 19:03:24.049: I neuronx_distributed/parallel_layers/parallel_state.py:561] [rank_0_pp-1_tp-1_dp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Generating 1 hlos for key: context_encoding_model\n",
      "INFO:Neuron:Started loading module context_encoding_model\n",
      "INFO:Neuron:Finished loading module context_encoding_model in 0.07097268104553223 seconds\n",
      "INFO:Neuron:generating HLO: context_encoding_model, input example shape = torch.Size([2, 32])\n",
      "INFO:Neuron:Generating 1 hlos for key: token_generation_model\n",
      "INFO:Neuron:Started loading module token_generation_model\n",
      "INFO:Neuron:Finished loading module token_generation_model in 0.05785727500915527 seconds\n",
      "INFO:Neuron:generating HLO: token_generation_model, input example shape = torch.Size([2, 1])\n",
      "INFO:Neuron:Started compilation for all HLOs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Done compilation for the priority HLO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Updating the hlo module with optimized layout\n",
      "INFO:Neuron:Done optimizing weight layout for all HLOs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Finished Compilation for all HLOs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Done preparing weight layout transformation\n",
      "INFO:Neuron:Sharding Weights for ranks: 0...1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiler status PASS\n",
      "[2025-03-06 19:04:48.577: I neuronx_distributed/parallel_layers/parallel_state.py:518] > initializing tensor model parallel with size 2\n",
      "[2025-03-06 19:04:48.577: I neuronx_distributed/parallel_layers/parallel_state.py:519] > initializing pipeline model parallel with size 1\n",
      "[2025-03-06 19:04:48.578: I neuronx_distributed/parallel_layers/parallel_state.py:520] > initializing data parallel with size 1\n",
      "[2025-03-06 19:04:48.578: I neuronx_distributed/parallel_layers/parallel_state.py:521] > initializing world size to 2\n",
      "[2025-03-06 19:04:48.580: I neuronx_distributed/parallel_layers/parallel_state.py:307] [rank_0_pp-1_tp-1_dp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7f17f4b24d30>, 'Ascending Ring PG Group')>\n",
      "[2025-03-06 19:04:48.580: I neuronx_distributed/parallel_layers/parallel_state.py:557] [rank_0_pp-1_tp-1_dp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-03-06 19:04:48.581: I neuronx_distributed/parallel_layers/parallel_state.py:558] [rank_0_pp-1_tp-1_dp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-03-06 19:04:48.581: I neuronx_distributed/parallel_layers/parallel_state.py:559] [rank_0_pp-1_tp-1_dp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-03-06 19:04:48.581: I neuronx_distributed/parallel_layers/parallel_state.py:560] [rank_0_pp-1_tp-1_dp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-03-06 19:04:48.582: I neuronx_distributed/parallel_layers/parallel_state.py:561] [rank_0_pp-1_tp-1_dp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: embed_tokens.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.0.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.1.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.10.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.11.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.12.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.13.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.14.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.15.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.2.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.3.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.4.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.5.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.6.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.7.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.8.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.input_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.mlp.down_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.mlp.gate_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.mlp.up_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.post_attention_layernorm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.self_attn.k_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.self_attn.o_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.self_attn.q_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: layers.9.self_attn.v_proj.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: norm.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:255: UserWarning: Found float32 weights in quantized checkpoint: lm_head.weight. Will convert to bfloat16\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-06 19:04:50.449: I neuronx_distributed/parallel_layers/parallel_state.py:518] > initializing tensor model parallel with size 2\n",
      "[2025-03-06 19:04:50.450: I neuronx_distributed/parallel_layers/parallel_state.py:519] > initializing pipeline model parallel with size 1\n",
      "[2025-03-06 19:04:50.450: I neuronx_distributed/parallel_layers/parallel_state.py:520] > initializing data parallel with size 1\n",
      "[2025-03-06 19:04:50.451: I neuronx_distributed/parallel_layers/parallel_state.py:521] > initializing world size to 2\n",
      "[2025-03-06 19:04:50.453: I neuronx_distributed/parallel_layers/parallel_state.py:307] [rank_0_pp-1_tp-1_dp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7f17f4b24d30>, 'Ascending Ring PG Group')>\n",
      "[2025-03-06 19:04:50.453: I neuronx_distributed/parallel_layers/parallel_state.py:557] [rank_0_pp-1_tp-1_dp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-03-06 19:04:50.453: I neuronx_distributed/parallel_layers/parallel_state.py:558] [rank_0_pp-1_tp-1_dp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-03-06 19:04:50.454: I neuronx_distributed/parallel_layers/parallel_state.py:559] [rank_0_pp-1_tp-1_dp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-03-06 19:04:50.454: I neuronx_distributed/parallel_layers/parallel_state.py:560] [rank_0_pp-1_tp-1_dp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-03-06 19:04:50.454: I neuronx_distributed/parallel_layers/parallel_state.py:561] [rank_0_pp-1_tp-1_dp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Done Sharding weights\n",
      "WARNING:root:NeuronConfig init: Unexpected keyword arguments: {'async_mode': False, 'kv_cache_tiling': False, 'weights_to_skip_layout_optimization': []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model from compiled checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating outputs...\n",
      "Prompts: ['I believe the meaning of life is', 'The color of the sky is']\n",
      "2025-Mar-06 19:05:13.0730 21230:26358 [0] nccl_net_ofi_rdma_init:7734 CCOM WARN NET/OFI OFI fi_getinfo() call failed: No data available\n",
      "2025-Mar-06 19:05:13.0740 21230:26358 [0] nccl_net_ofi_create_plugin:251 CCOM WARN NET/OFI Unable to find a protocol that worked.  Failing initialization.\n",
      "2025-Mar-06 19:05:13.0745 21230:26358 [0] nccl_net_ofi_create_plugin:316 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Mar-06 19:05:13.0750 21230:26358 [0] nccl_net_ofi_init:139 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Mar-06 19:05:13.0754 21230:26358 [0] net_plugin.cc:94 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "Generated outputs:\n",
      "Output 0: I believe the meaning of life is to find your passion and to live it. I believe that the best way to do that is to find your purpose. I believe that the best way to find your purpose is to find your passion. I believe that the best way to find your passion is to find your purpose.\n",
      "Output 1: The color of the sky is blue, the color of the water is green, the color of the grass is yellow, the color of the trees is red, the color of the flowers is white, the color of the clouds is black, the color of the sun is yellow, the color of the moon is\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GenerationConfig\n",
    "\n",
    "from neuronx_distributed_inference.models.config import NeuronConfig, OnDeviceSamplingConfig\n",
    "from neuronx_distributed_inference.models.llama.modeling_llama import LlamaInferenceConfig, NeuronLlamaForCausalLM\n",
    "from neuronx_distributed_inference.utils.hf_adapter import HuggingFaceGenerationAdapter, load_pretrained_config\n",
    "from neuronx_distributed_inference.modules.generation.sampling import prepare_sampling_params\n",
    "\n",
    "# Modify these paths as needed:Llama-3.2-1B\n",
    "model_path = \"/home/ubuntu/Llama-3.2-1B/\"       # The original HF directory for your Llama model\n",
    "traced_model_path = \"/home/ubuntu/traced_model/Llama-3.2-1B/\"  # Where to store the compiled artifacts\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def run_llama_generate():\n",
    "    # Initialize configs and tokenizer.\n",
    "    generation_config = GenerationConfig.from_pretrained(model_path)\n",
    "    # Some sample overrides for generation\n",
    "    generation_config_kwargs = {\n",
    "        \"do_sample\": True,\n",
    "        \"top_k\": 1,\n",
    "        \"pad_token_id\": generation_config.eos_token_id,\n",
    "    }\n",
    "    generation_config.update(**generation_config_kwargs)\n",
    "\n",
    "    # Set up the Neuron config (tensor parallel = 32, batch = 2, etc.)\n",
    "    neuron_config = NeuronConfig(\n",
    "        tp_degree=2,\n",
    "        batch_size=2,\n",
    "        max_context_length=32,\n",
    "        seq_len=64,\n",
    "        on_device_sampling_config=OnDeviceSamplingConfig(top_k=1),\n",
    "        enable_bucketing=True,\n",
    "        flash_decoding_enabled=False\n",
    "    )\n",
    "\n",
    "    # Build the Llama Inference config\n",
    "    config = LlamaInferenceConfig(\n",
    "        neuron_config,\n",
    "        load_config=load_pretrained_config(model_path),\n",
    "    )\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, padding_side=\"right\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Compile and save model.\n",
    "    print(\"\\nCompiling and saving model...\")\n",
    "    model = NeuronLlamaForCausalLM(model_path, config)\n",
    "    model.compile(traced_model_path)\n",
    "    tokenizer.save_pretrained(traced_model_path)\n",
    "\n",
    "    # Load from compiled checkpoint.\n",
    "    print(\"\\nLoading model from compiled checkpoint...\")\n",
    "    model = NeuronLlamaForCausalLM(traced_model_path)\n",
    "    model.load(traced_model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(traced_model_path)\n",
    "\n",
    "    # Generate outputs.\n",
    "    print(\"\\nGenerating outputs...\")\n",
    "    prompts = [\"I believe the meaning of life is\", \"The color of the sky is\"]\n",
    "\n",
    "    # Example: parameter sweeps for sampling\n",
    "    sampling_params = prepare_sampling_params(batch_size=neuron_config.batch_size,\n",
    "                                             top_k=[10, 5],\n",
    "                                             top_p=[0.5, 0.9],\n",
    "                                             temperature=[0.9, 0.5])\n",
    "\n",
    "    print(f\"Prompts: {prompts}\")\n",
    "    inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")\n",
    "    generation_model = HuggingFaceGenerationAdapter(model)\n",
    "    outputs = generation_model.generate(\n",
    "        inputs.input_ids,\n",
    "        generation_config=generation_config,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=model.config.neuron_config.max_length,\n",
    "        sampling_params=sampling_params,\n",
    "    )\n",
    "    output_tokens = tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    print(\"Generated outputs:\")\n",
    "    for i, output_token in enumerate(output_tokens):\n",
    "        print(f\"Output {i}: {output_token}\")\n",
    "\n",
    "# Run example if you wish.\n",
    "if __name__ == \"__main__\":\n",
    "    run_llama_generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba472f1",
   "metadata": {},
   "source": [
    "## 8. Running the Llama Example\n",
    "If you haven’t already, **run the cell above**. It will compile and generate sample text. The code cell is configured to run by default in the last line (`if __name__ == \"__main__\": ...`).\n",
    "\n",
    "After the model is compiled, you should see logs similar to:\n",
    "\n",
    "```\n",
    "Generating outputs...\n",
    "Prompts: ['I believe the meaning of life is', 'The color of the sky is']\n",
    "2025-Mar-06 19:05:13.0730 21230:26358 [0] nccl_net_ofi_rdma_init:7734 CCOM WARN NET/OFI OFI fi_getinfo() call failed: No data available\n",
    "2025-Mar-06 19:05:13.0740 21230:26358 [0] nccl_net_ofi_create_plugin:251 CCOM WARN NET/OFI Unable to find a protocol that worked.  Failing initialization.\n",
    "2025-Mar-06 19:05:13.0745 21230:26358 [0] nccl_net_ofi_create_plugin:316 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
    "2025-Mar-06 19:05:13.0750 21230:26358 [0] nccl_net_ofi_init:139 CCOM WARN NET/OFI Initializing plugin failed\n",
    "2025-Mar-06 19:05:13.0754 21230:26358 [0] net_plugin.cc:94 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
    "Generated outputs:\n",
    "Output 0: I believe the meaning of life is to find your passion and to live it. I believe that the best way to do that is to find your purpose. I believe that the best way to find your purpose is to find your passion. I believe that the best way to find your passion is to find your purpose.\n",
    "Output 1: The color of the sky is blue, the color of the water is green, the color of the grass is yellow, the color of the trees is red, the color of the flowers is white, the color of the clouds is black, the color of the sun is yellow, the color of the moon is\n",
    "```\n",
    "\n",
    "That’s it! You have successfully compiled a Llama model for inference with AWS Neuron.\n",
    "\n",
    "Feel free to edit **`tp_degree`**, **`batch_size`**, **`seq_len`**, or the **prompts** to reflect your needs. For more advanced usage, see the [AWS Neuron Distributed Inference Documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/pytorch/torch-neuronx-distributed-inference/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "391e6950-29b4-4855-beb2-19653bc41154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/bin/python3\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_nxd_inference/bin/pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vllm                              0.1.dev2830+g22c56ee.neuron216 /home/ubuntu/upstreaming-to-vllm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!which pip\n",
    "!pip list | grep vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ba793-3901-4620-b4b0-5150325a005a",
   "metadata": {},
   "source": [
    "## 9. vLLM demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9425cb-9354-4f0a-8375-900961ff54af",
   "metadata": {},
   "source": [
    "### 9.1 Offline Inference Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58b2a2-8475-4599-8750-24253c3c9c29",
   "metadata": {},
   "source": [
    "Here is an example for running offline inference. Bucketing is only disabled to demonstrate how to override Neuron configuration values. Keeping it enabled generally delivers better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c866cb-9ace-4fae-a940-8776c4e41ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libneuronxla                      2.1.714.0\n",
      "neuronx-cc                        2.16.372.0+4a9b2326\n",
      "neuronx-distributed               0.10.1\n",
      "neuronx-distributed-inference     0.1.1\n",
      "torch-neuronx                     2.5.1.2.4.0\n",
      "vllm                              0.1.dev2830+g22c56ee.neuron216 /home/ubuntu/upstreaming-to-vllm\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71eca15-f02f-4493-b3ec-02e8e07931f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-06 19:47:42 config.py:901] Defaulting to use mp for distributed inference\n",
      "WARNING 03-06 19:47:42 config.py:376] Async output processing is only supported for CUDA or TPU. Disabling it for other platforms.\n",
      "INFO 03-06 19:47:42 llm_engine.py:226] Initializing an LLM engine (v0.1.dev2830+g22c56ee) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={'enable_bucketing': False}, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 03-06 19:47:43 neuron_model_runner.py:102] On-device sampling is turned on in Neuron by default, only top_k, top_p, and temperature are current supported sampling parameters. To turn off the on-device sampling, please set the environment variable NEURON_ON_DEVICE_SAMPLING_DISABLED=1.\n",
      "INFO 03-06 19:47:43 neuronx_distributed.py:419] Initializing OnDeviceSampling config with global_topk=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:NeuronConfig init: Unexpected keyword arguments: {'async_mode': False, 'kv_cache_tiling': False, 'weights_to_skip_layout_optimization': []}\n",
      "Processed prompts: 100%|██████████████████████████████████████████████| 3/3 [00:02<00:00,  1.44it/s, est. speed input: 9.59 toks/s, output: 23.01 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'The president of the United States is', Generated text: ' the head of state of the United States of America. The president is the commander'\n",
      "Prompt: 'The capital of France is', Generated text: ' Paris. The city is located in the north of the country. The city is'\n",
      "Prompt: 'The future of AI is', Generated text: ' here. It’s not just a buzzword anymore. It’s a reality that'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['VLLM_NEURON_FRAMEWORK'] = \"neuronx-distributed-inference\"\n",
    "# Point to the directory of your already-compiled artifacts:\n",
    "os.environ['NEURON_COMPILED_ARTIFACTS'] = \"/home/ubuntu/traced_model/Llama-3.2-1B/\"\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Sample prompts.\n",
    "prompts = [\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "# Create a sampling params object.\n",
    "sampling_params = SamplingParams(top_k=1)\n",
    "\n",
    "# Create an LLM.\n",
    "llm = LLM(\n",
    "    model=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    max_num_seqs=1,\n",
    "    max_model_len=32,\n",
    "    override_neuron_config={\n",
    "        \"enable_bucketing\":False,\n",
    "    },\n",
    "    device=\"neuron\",\n",
    "    tensor_parallel_size=2)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9c4bad-6cb2-43d6-86db-d2011f1bdaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance-type: trn1.2xlarge\n",
      "instance-id: i-06f522ff86769dc0f\n",
      "+--------+--------+--------+---------+\n",
      "| NEURON | NEURON | NEURON |   PCI   |\n",
      "| DEVICE | CORES  | MEMORY |   BDF   |\n",
      "+--------+--------+--------+---------+\n",
      "| 0      | 2      | 32 GB  | 00:1e.0 |\n",
      "+--------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "!neuron-ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d5e8d-0c16-4061-b22f-c558ba1d5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo kill #PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35153e8-8b5f-451d-ba5d-65001a936b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in terminal\n",
    "# set env var again for compiled artifacts since "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078339c-4cb4-4386-b6a7-c6d9d9b12cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%\n",
    "\n",
    "VLLM_NEURON_FRAMEWORK='neuronx-distributed-inference' python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model=\"meta-llama/Llama-3.2-1B\" \\\n",
    "    --max-num-seqs=1 \\\n",
    "    --max-model-len=32 \\\n",
    "    --tensor-parallel-size=2 \\\n",
    "    --port=8888 \\\n",
    "    --device \"neuron\" \\\n",
    "    --override-neuron-config \"{\\\"enable_bucketing\\\":false}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e26228-62ce-4a2e-9972-d2b673011284",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1018308174.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    export OPENAI_API_BASE=\"http://0.0.0.0:8888\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "# This should be the same path to which the model was downloaded (also used in the above steps).\n",
    "MODEL_PATH=\"/home/ubuntu/models/Llama-3.2-1B-Instruct/\"\n",
    "# This is the name of directory where the test results will be saved.\n",
    "OUTPUT_PATH=llmperf-results-sonnets\n",
    "\n",
    "export OPENAI_API_BASE=\"http://0.0.0.0:8888\"\n",
    "export OPENAI_API_KEY=\"mock_key\"\n",
    "\n",
    "python token_benchmark_ray.py \\\n",
    "    --model $MODEL_PATH \\\n",
    "    --mean-input-tokens 32 \\\n",
    "    --stddev-input-tokens 0 \\\n",
    "    --mean-output-tokens 32 \\\n",
    "    --stddev-output-tokens 0 \\\n",
    "    --num-concurrent-requests 1\\\n",
    "    --timeout 3600 \\\n",
    "    --max-num-completed-requests 50 \\\n",
    "    --tokenizer $MODEL_PATH \\\n",
    "    --additional-sampling-params '{}' \\\n",
    "    --results-dir $OUTPUT_PATH \\\n",
    "    --llm-api \"openai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98a0d4",
   "metadata": {},
   "source": [
    "# Notebook Wrap-Up\n",
    "You now have:\n",
    "1. Installed the core AWS Neuron tools and optional packages (`vLLM`, `llmperf`, `InfluxDB`).\n",
    "2. Optionally downloaded or placed your Llama model in a local directory.\n",
    "3. Compiled and run a short demonstration of Llama-based text generation on Trainium.\n",
    "\n",
    "For more advanced topics:\n",
    "- **Profiling**: See [Neuron Profiling Tools](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/tools/neuron-profile/index.html).\n",
    "- **Distributed Serving**: Explore vLLM or other serving frameworks.\n",
    "- **Performance Benchmarking**: Use `llmperf` or custom scripts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
